{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f02255e1",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57f3bb81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T10:31:32.700982Z",
     "start_time": "2022-03-10T10:31:26.444325Z"
    }
   },
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor as vif\n",
    "from bitcoin_deep_learning.call_api import ApiCall\n",
    "from bitcoin_deep_learning.model import RnnDlModel, LinearRegressionBaselineModel, DummyModel, RandomForestReg, RnnDlModel_test \n",
    "from bitcoin_deep_learning.trainer import train, read_result\n",
    "from bitcoin_deep_learning.cross_val import get_cross_XY\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from random import random\n",
    "import joblib\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a506365e",
   "metadata": {},
   "source": [
    "## Getting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e05f6324",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T10:32:25.246157Z",
     "start_time": "2022-03-10T10:31:49.100259Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [00:35<00:00,  1.30s/it]\n"
     ]
    }
   ],
   "source": [
    "train_df = ApiCall().get_raw_glassnode_data()\n",
    "#read_local(data='train')#.drop(columns = '[%]_Bitcoin_growth_rate_on_Horizon=7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b76e46a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T10:32:45.131493Z",
     "start_time": "2022-03-10T10:32:45.023157Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>[AVG]_[NH]_mean_hash_rate</th>\n",
       "      <th>[+]_[NH]_Days_Till_Halving</th>\n",
       "      <th>[//]_[AV]_Stock-to-Flow_Ratio</th>\n",
       "      <th>[+]_[NH]_Circulating_Supply</th>\n",
       "      <th>[+]_[NH]_Issuance</th>\n",
       "      <th>[+]_[NH]_Number_of_Active_Addresses</th>\n",
       "      <th>[+]_[NH]_Mean_Block_Interval</th>\n",
       "      <th>[+]_[NH]_Number_of_Transactions</th>\n",
       "      <th>[+]_[NH]_Number_of_Addresses_with_a_Non-Zero_Balance</th>\n",
       "      <th>...</th>\n",
       "      <th>[$]_[BSB]_Exchange_Net_Position_Change_-_All_Exchanges</th>\n",
       "      <th>[//]_[BSB]_Realized_Profit/Loss_Ratio</th>\n",
       "      <th>[$]_[BSB]_Net_Unrealized_Profit/Loss_(NUPL)</th>\n",
       "      <th>[$]_[BSB]_Realized_Price</th>\n",
       "      <th>[%]_[BSB]_Price_Drawdown_from_ATH</th>\n",
       "      <th>[//]_[AV]_Market_Value_to_Realized_Value_Ratio_(MVRV)</th>\n",
       "      <th>[//]_[AV]_Puell_Multiple</th>\n",
       "      <th>[//]_[AV]_Realized_Profits-to-Value_(RPV)_Ratio</th>\n",
       "      <th>[+]_[T]_Bitcoin_Price</th>\n",
       "      <th>[%]_Bitcoin_growth_rate_on_Horizon=7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-09-16</td>\n",
       "      <td>1.036434e+13</td>\n",
       "      <td>439</td>\n",
       "      <td>1.418819</td>\n",
       "      <td>7282650.0</td>\n",
       "      <td>5950.0</td>\n",
       "      <td>14298</td>\n",
       "      <td>508</td>\n",
       "      <td>6090</td>\n",
       "      <td>494042</td>\n",
       "      <td>...</td>\n",
       "      <td>74.789093</td>\n",
       "      <td>0.130762</td>\n",
       "      <td>-112113.115163</td>\n",
       "      <td>6.124551</td>\n",
       "      <td>-0.849159</td>\n",
       "      <td>0.785527</td>\n",
       "      <td>0.683785</td>\n",
       "      <td>0.000378</td>\n",
       "      <td>4.811000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-09-17</td>\n",
       "      <td>1.161376e+13</td>\n",
       "      <td>438</td>\n",
       "      <td>1.429329</td>\n",
       "      <td>7289350.0</td>\n",
       "      <td>6700.0</td>\n",
       "      <td>12877</td>\n",
       "      <td>455</td>\n",
       "      <td>5320</td>\n",
       "      <td>494415</td>\n",
       "      <td>...</td>\n",
       "      <td>69.740065</td>\n",
       "      <td>0.173719</td>\n",
       "      <td>-42045.963095</td>\n",
       "      <td>6.118551</td>\n",
       "      <td>-0.850611</td>\n",
       "      <td>0.778730</td>\n",
       "      <td>0.766186</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>4.764700</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-09-18</td>\n",
       "      <td>1.363396e+13</td>\n",
       "      <td>437</td>\n",
       "      <td>1.441211</td>\n",
       "      <td>7297250.0</td>\n",
       "      <td>7900.0</td>\n",
       "      <td>14074</td>\n",
       "      <td>349</td>\n",
       "      <td>5828</td>\n",
       "      <td>494962</td>\n",
       "      <td>...</td>\n",
       "      <td>30.148647</td>\n",
       "      <td>0.387620</td>\n",
       "      <td>-26346.007227</td>\n",
       "      <td>6.113585</td>\n",
       "      <td>-0.835764</td>\n",
       "      <td>0.856819</td>\n",
       "      <td>0.913495</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>5.238233</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-09-19</td>\n",
       "      <td>1.113934e+13</td>\n",
       "      <td>436</td>\n",
       "      <td>1.452215</td>\n",
       "      <td>7303600.0</td>\n",
       "      <td>6350.0</td>\n",
       "      <td>15826</td>\n",
       "      <td>454</td>\n",
       "      <td>6526</td>\n",
       "      <td>495218</td>\n",
       "      <td>...</td>\n",
       "      <td>38.196675</td>\n",
       "      <td>0.293976</td>\n",
       "      <td>-54997.251969</td>\n",
       "      <td>6.105355</td>\n",
       "      <td>-0.828724</td>\n",
       "      <td>0.894751</td>\n",
       "      <td>0.782018</td>\n",
       "      <td>0.000514</td>\n",
       "      <td>5.462771</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-09-20</td>\n",
       "      <td>1.214578e+13</td>\n",
       "      <td>435</td>\n",
       "      <td>1.462380</td>\n",
       "      <td>7310600.0</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>21668</td>\n",
       "      <td>422</td>\n",
       "      <td>8005</td>\n",
       "      <td>499994</td>\n",
       "      <td>...</td>\n",
       "      <td>36.377675</td>\n",
       "      <td>0.853582</td>\n",
       "      <td>-11317.089254</td>\n",
       "      <td>6.104715</td>\n",
       "      <td>-0.808281</td>\n",
       "      <td>1.001652</td>\n",
       "      <td>0.981353</td>\n",
       "      <td>0.001478</td>\n",
       "      <td>6.114797</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  [AVG]_[NH]_mean_hash_rate  [+]_[NH]_Days_Till_Halving  \\\n",
       "0 2011-09-16               1.036434e+13                         439   \n",
       "1 2011-09-17               1.161376e+13                         438   \n",
       "2 2011-09-18               1.363396e+13                         437   \n",
       "3 2011-09-19               1.113934e+13                         436   \n",
       "4 2011-09-20               1.214578e+13                         435   \n",
       "\n",
       "   [//]_[AV]_Stock-to-Flow_Ratio  [+]_[NH]_Circulating_Supply  \\\n",
       "0                       1.418819                    7282650.0   \n",
       "1                       1.429329                    7289350.0   \n",
       "2                       1.441211                    7297250.0   \n",
       "3                       1.452215                    7303600.0   \n",
       "4                       1.462380                    7310600.0   \n",
       "\n",
       "   [+]_[NH]_Issuance  [+]_[NH]_Number_of_Active_Addresses  \\\n",
       "0             5950.0                                14298   \n",
       "1             6700.0                                12877   \n",
       "2             7900.0                                14074   \n",
       "3             6350.0                                15826   \n",
       "4             7000.0                                21668   \n",
       "\n",
       "   [+]_[NH]_Mean_Block_Interval  [+]_[NH]_Number_of_Transactions  \\\n",
       "0                           508                             6090   \n",
       "1                           455                             5320   \n",
       "2                           349                             5828   \n",
       "3                           454                             6526   \n",
       "4                           422                             8005   \n",
       "\n",
       "   [+]_[NH]_Number_of_Addresses_with_a_Non-Zero_Balance  ...  \\\n",
       "0                                             494042     ...   \n",
       "1                                             494415     ...   \n",
       "2                                             494962     ...   \n",
       "3                                             495218     ...   \n",
       "4                                             499994     ...   \n",
       "\n",
       "   [$]_[BSB]_Exchange_Net_Position_Change_-_All_Exchanges  \\\n",
       "0                                          74.789093        \n",
       "1                                          69.740065        \n",
       "2                                          30.148647        \n",
       "3                                          38.196675        \n",
       "4                                          36.377675        \n",
       "\n",
       "   [//]_[BSB]_Realized_Profit/Loss_Ratio  \\\n",
       "0                               0.130762   \n",
       "1                               0.173719   \n",
       "2                               0.387620   \n",
       "3                               0.293976   \n",
       "4                               0.853582   \n",
       "\n",
       "   [$]_[BSB]_Net_Unrealized_Profit/Loss_(NUPL)  [$]_[BSB]_Realized_Price  \\\n",
       "0                               -112113.115163                  6.124551   \n",
       "1                                -42045.963095                  6.118551   \n",
       "2                                -26346.007227                  6.113585   \n",
       "3                                -54997.251969                  6.105355   \n",
       "4                                -11317.089254                  6.104715   \n",
       "\n",
       "   [%]_[BSB]_Price_Drawdown_from_ATH  \\\n",
       "0                          -0.849159   \n",
       "1                          -0.850611   \n",
       "2                          -0.835764   \n",
       "3                          -0.828724   \n",
       "4                          -0.808281   \n",
       "\n",
       "   [//]_[AV]_Market_Value_to_Realized_Value_Ratio_(MVRV)  \\\n",
       "0                                           0.785527       \n",
       "1                                           0.778730       \n",
       "2                                           0.856819       \n",
       "3                                           0.894751       \n",
       "4                                           1.001652       \n",
       "\n",
       "   [//]_[AV]_Puell_Multiple  [//]_[AV]_Realized_Profits-to-Value_(RPV)_Ratio  \\\n",
       "0                  0.683785                                         0.000378   \n",
       "1                  0.766186                                         0.000198   \n",
       "2                  0.913495                                         0.000374   \n",
       "3                  0.782018                                         0.000514   \n",
       "4                  0.981353                                         0.001478   \n",
       "\n",
       "   [+]_[T]_Bitcoin_Price  [%]_Bitcoin_growth_rate_on_Horizon=7  \n",
       "0               4.811000                                   NaN  \n",
       "1               4.764700                                   NaN  \n",
       "2               5.238233                                   NaN  \n",
       "3               5.462771                                   NaN  \n",
       "4               6.114797                                   NaN  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c31f9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop(columns = '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8e282da3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T17:17:44.488722Z",
     "start_time": "2022-03-09T17:17:43.152274Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_list, Y_train_list, X_test_list,Y_test_list = get_cross_XY(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "44084488",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T17:17:45.347423Z",
     "start_time": "2022-03-09T17:17:45.148414Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 263, 90, 32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(X_train_list).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e2c3dffd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T16:47:45.288290Z",
     "start_time": "2022-03-09T16:47:45.227421Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 90)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(Y_test_list).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d9c90c86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T17:03:28.386819Z",
     "start_time": "2022-03-09T17:03:28.216805Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>[AVG]_[NH]_mean_hash_rate</th>\n",
       "      <th>[+]_[NH]_Days_Till_Halving</th>\n",
       "      <th>[//]_[AV]_Stock-to-Flow_Ratio</th>\n",
       "      <th>[+]_[NH]_Circulating_Supply</th>\n",
       "      <th>[+]_[NH]_Issuance</th>\n",
       "      <th>[+]_[NH]_Number_of_Active_Addresses</th>\n",
       "      <th>[+]_[NH]_Mean_Block_Interval</th>\n",
       "      <th>[+]_[NH]_Number_of_Transactions</th>\n",
       "      <th>[+]_[NH]_Number_of_Addresses_with_a_Non-Zero_Balance</th>\n",
       "      <th>...</th>\n",
       "      <th>[//]_[AV]_Realized_Profits-to-Value_(RPV)_Ratio</th>\n",
       "      <th>fear_greed_value</th>\n",
       "      <th>[+]_[NH]_Number_of_Addresses_with_Balance_0.01 - 0.1</th>\n",
       "      <th>[+]_[NH]_Number_of_Addresses_with_Balance_0.1 - 1</th>\n",
       "      <th>[+]_[NH]_Number_of_Addresses_with_Balance_1 - 10</th>\n",
       "      <th>[+]_[NH]_Number_of_Addresses_with_Balance_10 - 100</th>\n",
       "      <th>[+]_[NH]_Number_of_Addresses_with_Balance_100 - 1k</th>\n",
       "      <th>[+]_[NH]_Number_of_Addresses_with_Balance_1k - 10k</th>\n",
       "      <th>[+]_[T]_Bitcoin_Price</th>\n",
       "      <th>[%]_Bitcoin_growth_rate_on_Horizon=7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>2.054109e+19</td>\n",
       "      <td>830</td>\n",
       "      <td>5642.903220</td>\n",
       "      <td>16839700.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>842398</td>\n",
       "      <td>377</td>\n",
       "      <td>257504</td>\n",
       "      <td>27026398</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003691</td>\n",
       "      <td>30</td>\n",
       "      <td>4226306</td>\n",
       "      <td>1722331</td>\n",
       "      <td>544769</td>\n",
       "      <td>132314</td>\n",
       "      <td>15779</td>\n",
       "      <td>1529</td>\n",
       "      <td>9014.026207</td>\n",
       "      <td>-0.235616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-02-02</td>\n",
       "      <td>2.170824e+19</td>\n",
       "      <td>829</td>\n",
       "      <td>5641.695528</td>\n",
       "      <td>16841800.0</td>\n",
       "      <td>2100.0</td>\n",
       "      <td>854253</td>\n",
       "      <td>385</td>\n",
       "      <td>235750</td>\n",
       "      <td>26955617</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002557</td>\n",
       "      <td>15</td>\n",
       "      <td>4198274</td>\n",
       "      <td>1704275</td>\n",
       "      <td>543489</td>\n",
       "      <td>132213</td>\n",
       "      <td>15815</td>\n",
       "      <td>1521</td>\n",
       "      <td>8799.121911</td>\n",
       "      <td>-0.260491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-02-03</td>\n",
       "      <td>2.073919e+19</td>\n",
       "      <td>828</td>\n",
       "      <td>5641.015128</td>\n",
       "      <td>16843775.0</td>\n",
       "      <td>1975.0</td>\n",
       "      <td>714655</td>\n",
       "      <td>384</td>\n",
       "      <td>194733</td>\n",
       "      <td>26886977</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001970</td>\n",
       "      <td>40</td>\n",
       "      <td>4173275</td>\n",
       "      <td>1692828</td>\n",
       "      <td>542447</td>\n",
       "      <td>132021</td>\n",
       "      <td>15812</td>\n",
       "      <td>1523</td>\n",
       "      <td>9208.459919</td>\n",
       "      <td>-0.230759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  [AVG]_[NH]_mean_hash_rate  [+]_[NH]_Days_Till_Halving  \\\n",
       "0  2018-02-01               2.054109e+19                         830   \n",
       "1  2018-02-02               2.170824e+19                         829   \n",
       "2  2018-02-03               2.073919e+19                         828   \n",
       "\n",
       "   [//]_[AV]_Stock-to-Flow_Ratio  [+]_[NH]_Circulating_Supply  \\\n",
       "0                    5642.903220                   16839700.0   \n",
       "1                    5641.695528                   16841800.0   \n",
       "2                    5641.015128                   16843775.0   \n",
       "\n",
       "   [+]_[NH]_Issuance  [+]_[NH]_Number_of_Active_Addresses  \\\n",
       "0             2000.0                               842398   \n",
       "1             2100.0                               854253   \n",
       "2             1975.0                               714655   \n",
       "\n",
       "   [+]_[NH]_Mean_Block_Interval  [+]_[NH]_Number_of_Transactions  \\\n",
       "0                           377                           257504   \n",
       "1                           385                           235750   \n",
       "2                           384                           194733   \n",
       "\n",
       "   [+]_[NH]_Number_of_Addresses_with_a_Non-Zero_Balance  ...  \\\n",
       "0                                           27026398     ...   \n",
       "1                                           26955617     ...   \n",
       "2                                           26886977     ...   \n",
       "\n",
       "   [//]_[AV]_Realized_Profits-to-Value_(RPV)_Ratio  fear_greed_value  \\\n",
       "0                                         0.003691                30   \n",
       "1                                         0.002557                15   \n",
       "2                                         0.001970                40   \n",
       "\n",
       "   [+]_[NH]_Number_of_Addresses_with_Balance_0.01 - 0.1  \\\n",
       "0                                            4226306      \n",
       "1                                            4198274      \n",
       "2                                            4173275      \n",
       "\n",
       "   [+]_[NH]_Number_of_Addresses_with_Balance_0.1 - 1  \\\n",
       "0                                            1722331   \n",
       "1                                            1704275   \n",
       "2                                            1692828   \n",
       "\n",
       "   [+]_[NH]_Number_of_Addresses_with_Balance_1 - 10  \\\n",
       "0                                            544769   \n",
       "1                                            543489   \n",
       "2                                            542447   \n",
       "\n",
       "   [+]_[NH]_Number_of_Addresses_with_Balance_10 - 100  \\\n",
       "0                                             132314    \n",
       "1                                             132213    \n",
       "2                                             132021    \n",
       "\n",
       "   [+]_[NH]_Number_of_Addresses_with_Balance_100 - 1k  \\\n",
       "0                                              15779    \n",
       "1                                              15815    \n",
       "2                                              15812    \n",
       "\n",
       "   [+]_[NH]_Number_of_Addresses_with_Balance_1k - 10k  [+]_[T]_Bitcoin_Price  \\\n",
       "0                                               1529             9014.026207   \n",
       "1                                               1521             8799.121911   \n",
       "2                                               1523             9208.459919   \n",
       "\n",
       "   [%]_Bitcoin_growth_rate_on_Horizon=7  \n",
       "0                             -0.235616  \n",
       "1                             -0.260491  \n",
       "2                             -0.230759  \n",
       "\n",
       "[3 rows x 33 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cfd699",
   "metadata": {},
   "source": [
    "## Ploting models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3e9cbc",
   "metadata": {},
   "source": [
    "### Plotting prediction per folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "207fc3bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T10:22:40.504698Z",
     "start_time": "2022-03-10T10:22:38.985837Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_predictions_models_all_folds(X_train_list, Y_train_list, X_test_list, Y_test_list, model):\n",
    "    fig, axs = plt.subplots(nrows = len(X_train_list), ncols = 4, figsize = (25,200))\n",
    "    scores = []\n",
    "    for k in range(len(X_train_list)): #range(5):#\n",
    "        X_train, y_train, X_test, y_test = X_train_list[k], Y_train_list[k], X_test_list[k], Y_test_list[k]\n",
    "        #intuition too much regularization on the lasso\n",
    "        model.set_model()\n",
    "        y_pred = model.run(X_test, X_train, y_train)\n",
    "        score = mean_absolute_error(y_test, y_pred)\n",
    "        scores.append(score)\n",
    "        axs[k, 0].plot(y_test, label = 'test')\n",
    "        axs[k, 0].plot(y_pred, color = 'r', label = 'pred')\n",
    "        axs[k, 0].set_title('Fitting of y_test, y_pred')\n",
    "        axs[k, 0].set_ylabel('Price growth rate 7 days')\n",
    "        axs[k, 0].set_xlabel('Fold sequence length in days')\n",
    "        axs[k, 0].legend(loc='upper right')\n",
    "        axs[k, 1].plot(y_train, label = 'train', color = 'g')\n",
    "        axs[k, 1].set_title('Evolution of the y_train')\n",
    "        axs[k, 1].set_ylabel('Price growth rate 7 days')\n",
    "        axs[k, 1].set_xlabel('Fold sequence length in days')\n",
    "        axs[k, 1].legend(loc='upper right');\n",
    "        axs[k, 2].plot(model.history.history['mae'], color = 'y', label = 'mae')\n",
    "        axs[k, 2].plot(model.history.history['val_mae'], color = 'b', label = 'val_mae')\n",
    "        axs[k, 2].set_title('model mae')\n",
    "        axs[k, 2].set_ylabel('mae')\n",
    "        axs[k, 2].set_xlabel('epoch')\n",
    "        axs[k, 2].legend(['train', 'test'], loc='upper right')\n",
    "        axs[k, 3].plot(model.history.history['loss'], color = 'y', label = 'mae')\n",
    "        axs[k, 3].plot(model.history.history['val_loss'], color = 'b', label = 'val_mae')\n",
    "        axs[k, 3].set_title('model train vs validation loss')\n",
    "        axs[k, 3].set_ylabel('loss')\n",
    "        axs[k, 3].set_xlabel('epoch')\n",
    "        axs[k, 3].legend(['train', 'validation'], loc='upper right')\n",
    "        if k == 1:\n",
    "            print(model.model.summary())\n",
    "        print(f'############### next fold => number {k} ########## ')\n",
    "    print(\"Mean absolute error - mean\") \n",
    "    print(np.array(scores).mean())\n",
    "    print(\"Mean absolute error - std\") \n",
    "    print(np.array(scores).std())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bebcf4b",
   "metadata": {},
   "source": [
    "### RNN Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2885b3e",
   "metadata": {},
   "source": [
    "#### Tuning RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac1053d",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-03-10T10:22:43.540Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "4/4 [==============================] - 3s 196ms/step - loss: 0.1381 - mae: 0.1288 - val_loss: 0.0618 - val_mae: 0.0768\n",
      "Epoch 2/250\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 0.0573 - mae: 0.0767 - val_loss: 0.0449 - val_mae: 0.0751\n",
      "Epoch 3/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0549 - mae: 0.0732 - val_loss: 0.0467 - val_mae: 0.0771\n",
      "Epoch 4/250\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.0482 - mae: 0.0753 - val_loss: 0.0577 - val_mae: 0.0881\n",
      "Epoch 5/250\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.0504 - mae: 0.0779 - val_loss: 0.0459 - val_mae: 0.0774\n",
      "Epoch 6/250\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.0506 - mae: 0.0771 - val_loss: 0.0434 - val_mae: 0.0738\n",
      "Epoch 7/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0485 - mae: 0.0737 - val_loss: 0.0433 - val_mae: 0.0736\n",
      "Epoch 8/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0492 - mae: 0.0733 - val_loss: 0.0428 - val_mae: 0.0731\n",
      "Epoch 9/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0478 - mae: 0.0730 - val_loss: 0.0431 - val_mae: 0.0737\n",
      "Epoch 10/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0483 - mae: 0.0752 - val_loss: 0.0439 - val_mae: 0.0744\n",
      "Epoch 11/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0489 - mae: 0.0763 - val_loss: 0.0465 - val_mae: 0.0783\n",
      "Epoch 12/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0520 - mae: 0.0802 - val_loss: 0.0436 - val_mae: 0.0744\n",
      "Epoch 13/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0484 - mae: 0.0748 - val_loss: 0.0534 - val_mae: 0.0827\n",
      "Epoch 14/250\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.0524 - mae: 0.0801 - val_loss: 0.0742 - val_mae: 0.1022\n",
      "Epoch 15/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0487 - mae: 0.0785 - val_loss: 0.0429 - val_mae: 0.0744\n",
      "Epoch 16/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0449 - mae: 0.0732 - val_loss: 0.0632 - val_mae: 0.0942\n",
      "Epoch 17/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0541 - mae: 0.0828 - val_loss: 0.0431 - val_mae: 0.0742\n",
      "Epoch 18/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0478 - mae: 0.0738 - val_loss: 0.0451 - val_mae: 0.0773\n",
      "Epoch 19/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0428 - mae: 0.0715 - val_loss: 0.0585 - val_mae: 0.0940\n",
      "Epoch 20/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0501 - mae: 0.0796 - val_loss: 0.0455 - val_mae: 0.0781\n",
      "Epoch 21/250\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 0.0439 - mae: 0.0718 - val_loss: 0.0630 - val_mae: 0.0941\n",
      "Epoch 22/250\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 0.0343 - mae: 0.0657 - val_loss: 0.1857 - val_mae: 0.1803\n",
      "Epoch 23/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0500 - mae: 0.0743 - val_loss: 0.0428 - val_mae: 0.0734\n",
      "############### next fold => number 0 ########## \n",
      "Epoch 1/250\n",
      "4/4 [==============================] - 3s 192ms/step - loss: 0.1195 - mae: 0.1077 - val_loss: 0.0153 - val_mae: 0.0420\n",
      "Epoch 2/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0768 - mae: 0.0894 - val_loss: 0.0223 - val_mae: 0.0531\n",
      "Epoch 3/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0595 - mae: 0.0843 - val_loss: 0.0152 - val_mae: 0.0420\n",
      "Epoch 4/250\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.0578 - mae: 0.0793 - val_loss: 0.0216 - val_mae: 0.0519\n",
      "Epoch 5/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0545 - mae: 0.0815 - val_loss: 0.0209 - val_mae: 0.0507\n",
      "Epoch 6/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0551 - mae: 0.0825 - val_loss: 0.0271 - val_mae: 0.0606\n",
      "Epoch 7/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0566 - mae: 0.0817 - val_loss: 0.0162 - val_mae: 0.0420\n",
      "Epoch 8/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0532 - mae: 0.0799 - val_loss: 0.0371 - val_mae: 0.0748\n",
      "Epoch 9/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0560 - mae: 0.0840 - val_loss: 0.1270 - val_mae: 0.1495\n",
      "Epoch 10/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0872 - mae: 0.1004 - val_loss: 0.0203 - val_mae: 0.0496\n",
      "Epoch 11/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0552 - mae: 0.0799 - val_loss: 0.0218 - val_mae: 0.0518\n",
      "Epoch 12/250\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.0503 - mae: 0.0788 - val_loss: 0.0150 - val_mae: 0.0419\n",
      "Epoch 13/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0534 - mae: 0.0775 - val_loss: 0.0251 - val_mae: 0.0525\n",
      "Epoch 14/250\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.0641 - mae: 0.0795 - val_loss: 0.0166 - val_mae: 0.0440\n",
      "Epoch 15/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0466 - mae: 0.0733 - val_loss: 0.0143 - val_mae: 0.0422\n",
      "Epoch 16/250\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.0519 - mae: 0.0770 - val_loss: 0.0178 - val_mae: 0.0430\n",
      "Epoch 17/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0600 - mae: 0.0764 - val_loss: 0.0150 - val_mae: 0.0417\n",
      "Epoch 18/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0486 - mae: 0.0753 - val_loss: 0.0173 - val_mae: 0.0451\n",
      "Epoch 19/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0425 - mae: 0.0749 - val_loss: 0.0181 - val_mae: 0.0446\n",
      "Epoch 20/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0482 - mae: 0.0747 - val_loss: 0.0183 - val_mae: 0.0446\n",
      "Epoch 21/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0353 - mae: 0.0708 - val_loss: 0.0219 - val_mae: 0.0517\n",
      "Epoch 22/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0519 - mae: 0.0774 - val_loss: 0.0157 - val_mae: 0.0420\n",
      "Epoch 23/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0415 - mae: 0.0715 - val_loss: 0.0199 - val_mae: 0.0467\n",
      "Epoch 24/250\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.0431 - mae: 0.0735 - val_loss: 0.0153 - val_mae: 0.0425\n",
      "Epoch 25/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0413 - mae: 0.0710 - val_loss: 0.0195 - val_mae: 0.0462\n",
      "Epoch 26/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0346 - mae: 0.0665 - val_loss: 0.0204 - val_mae: 0.0527\n",
      "Epoch 27/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0274 - mae: 0.0631 - val_loss: 0.1033 - val_mae: 0.1195\n",
      "Epoch 28/250\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.0300 - mae: 0.0659 - val_loss: 0.0154 - val_mae: 0.0492\n",
      "Epoch 29/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0474 - mae: 0.0804 - val_loss: 0.0129 - val_mae: 0.0433\n",
      "Epoch 30/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0405 - mae: 0.0689 - val_loss: 0.0189 - val_mae: 0.0441\n",
      "Epoch 31/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0261 - mae: 0.0603 - val_loss: 0.0452 - val_mae: 0.0730\n",
      "Epoch 32/250\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.0298 - mae: 0.0672 - val_loss: 0.0212 - val_mae: 0.0483\n",
      "Epoch 33/250\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.0273 - mae: 0.0638 - val_loss: 0.0149 - val_mae: 0.0460\n",
      "Epoch 34/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0475 - mae: 0.0720 - val_loss: 0.0346 - val_mae: 0.0622\n",
      "Epoch 35/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0306 - mae: 0.0613 - val_loss: 0.0161 - val_mae: 0.0431\n",
      "Epoch 36/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0348 - mae: 0.0646 - val_loss: 0.0164 - val_mae: 0.0432\n",
      "Epoch 37/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0384 - mae: 0.0687 - val_loss: 0.0158 - val_mae: 0.0433\n",
      "Epoch 38/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0293 - mae: 0.0614 - val_loss: 0.0370 - val_mae: 0.0649\n",
      "Epoch 39/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0385 - mae: 0.0666 - val_loss: 0.0300 - val_mae: 0.0622\n",
      "Epoch 40/250\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.0342 - mae: 0.0745 - val_loss: 0.0146 - val_mae: 0.0426\n",
      "Epoch 41/250\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.0220 - mae: 0.0557 - val_loss: 0.0154 - val_mae: 0.0445\n",
      "Epoch 42/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0363 - mae: 0.0675 - val_loss: 0.0263 - val_mae: 0.0577\n",
      "Epoch 43/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0259 - mae: 0.0581 - val_loss: 0.0182 - val_mae: 0.0455\n",
      "Epoch 44/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0249 - mae: 0.0591 - val_loss: 0.1272 - val_mae: 0.1418\n",
      "Model: \"sequential_1193\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_3619 (GRU)               (None, 90, 64)            18816     \n",
      "_________________________________________________________________\n",
      "dropout_1461 (Dropout)       (None, 90, 64)            0         \n",
      "_________________________________________________________________\n",
      "gru_3620 (GRU)               (None, 90, 32)            9408      \n",
      "_________________________________________________________________\n",
      "gru_3621 (GRU)               (None, 16)                2400      \n",
      "_________________________________________________________________\n",
      "dense_4560 (Dense)           (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_4561 (Dense)           (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_4562 (Dense)           (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_4563 (Dense)           (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 31,841\n",
      "Trainable params: 31,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "############### next fold => number 1 ########## \n",
      "Epoch 1/250\n",
      "4/4 [==============================] - 3s 198ms/step - loss: 1.3777 - mae: 0.3339 - val_loss: 0.0070 - val_mae: 0.0334\n",
      "Epoch 2/250\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.0707 - mae: 0.0848 - val_loss: 0.0350 - val_mae: 0.0592\n",
      "Epoch 3/250\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.0530 - mae: 0.0738 - val_loss: 0.0284 - val_mae: 0.0520\n",
      "Epoch 4/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0490 - mae: 0.0761 - val_loss: 0.0207 - val_mae: 0.0421\n",
      "Epoch 5/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0452 - mae: 0.0712 - val_loss: 0.0319 - val_mae: 0.0558\n",
      "Epoch 6/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0471 - mae: 0.0718 - val_loss: 0.0307 - val_mae: 0.0536\n",
      "Epoch 7/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0456 - mae: 0.0745 - val_loss: 0.0617 - val_mae: 0.0855\n",
      "Epoch 8/250\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.0501 - mae: 0.0775 - val_loss: 0.0079 - val_mae: 0.0315\n",
      "Epoch 9/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0497 - mae: 0.0731 - val_loss: 0.1141 - val_mae: 0.1224\n",
      "Epoch 10/250\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.0564 - mae: 0.0867 - val_loss: 0.0571 - val_mae: 0.0814\n",
      "Epoch 11/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0601 - mae: 0.0828 - val_loss: 0.0465 - val_mae: 0.0730\n",
      "Epoch 12/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0501 - mae: 0.0776 - val_loss: 0.0391 - val_mae: 0.0658\n",
      "Epoch 13/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0449 - mae: 0.0749 - val_loss: 0.0074 - val_mae: 0.0318\n",
      "Epoch 14/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0508 - mae: 0.0716 - val_loss: 0.0221 - val_mae: 0.0448\n",
      "Epoch 15/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0533 - mae: 0.0726 - val_loss: 0.0369 - val_mae: 0.0628\n",
      "Epoch 16/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0509 - mae: 0.0806 - val_loss: 0.0058 - val_mae: 0.0300\n",
      "Epoch 17/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0440 - mae: 0.0731 - val_loss: 0.0964 - val_mae: 0.1111\n",
      "Epoch 18/250\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.0426 - mae: 0.0701 - val_loss: 0.0375 - val_mae: 0.0636\n",
      "Epoch 19/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0395 - mae: 0.0697 - val_loss: 0.0547 - val_mae: 0.0804\n",
      "Epoch 20/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0461 - mae: 0.0737 - val_loss: 0.3901 - val_mae: 0.2340\n",
      "Epoch 21/250\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.0744 - mae: 0.1009 - val_loss: 0.0057 - val_mae: 0.0306\n",
      "Epoch 22/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0418 - mae: 0.0684 - val_loss: 0.0276 - val_mae: 0.0522\n",
      "Epoch 23/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0375 - mae: 0.0661 - val_loss: 0.0144 - val_mae: 0.0372\n",
      "Epoch 24/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0370 - mae: 0.0677 - val_loss: 0.0770 - val_mae: 0.0981\n",
      "Epoch 25/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0703 - mae: 0.0881 - val_loss: 0.0064 - val_mae: 0.0304\n",
      "Epoch 26/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0434 - mae: 0.0713 - val_loss: 0.0065 - val_mae: 0.0312\n",
      "Epoch 27/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0436 - mae: 0.0723 - val_loss: 0.1251 - val_mae: 0.1256\n",
      "Epoch 28/250\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.0489 - mae: 0.0739 - val_loss: 0.0420 - val_mae: 0.0677\n",
      "Epoch 29/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0539 - mae: 0.0800 - val_loss: 0.0070 - val_mae: 0.0339\n",
      "Epoch 30/250\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.0383 - mae: 0.0694 - val_loss: 0.0307 - val_mae: 0.0561\n",
      "Epoch 31/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0231 - mae: 0.0563 - val_loss: 0.0266 - val_mae: 0.0509\n",
      "Epoch 32/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0423 - mae: 0.0715 - val_loss: 0.0094 - val_mae: 0.0324\n",
      "Epoch 33/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0450 - mae: 0.0705 - val_loss: 0.0158 - val_mae: 0.0366\n",
      "Epoch 34/250\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.0268 - mae: 0.0619 - val_loss: 0.0061 - val_mae: 0.0306\n",
      "Epoch 35/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0292 - mae: 0.0613 - val_loss: 0.0227 - val_mae: 0.0466\n",
      "Epoch 36/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0356 - mae: 0.0654 - val_loss: 0.0116 - val_mae: 0.0327\n",
      "############### next fold => number 2 ########## \n",
      "Epoch 1/250\n",
      "4/4 [==============================] - 3s 194ms/step - loss: 0.0704 - mae: 0.0946 - val_loss: 0.0586 - val_mae: 0.0558\n",
      "Epoch 2/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0459 - mae: 0.0677 - val_loss: 0.0756 - val_mae: 0.0707\n",
      "Epoch 3/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0444 - mae: 0.0671 - val_loss: 0.0109 - val_mae: 0.0392\n",
      "Epoch 4/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0669 - mae: 0.0838 - val_loss: 0.1716 - val_mae: 0.1275\n",
      "Epoch 5/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0536 - mae: 0.0740 - val_loss: 0.0712 - val_mae: 0.0673\n",
      "Epoch 6/250\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 0.0474 - mae: 0.0670 - val_loss: 0.0554 - val_mae: 0.0532\n",
      "Epoch 7/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0459 - mae: 0.0673 - val_loss: 0.0540 - val_mae: 0.0518\n",
      "Epoch 8/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0451 - mae: 0.0657 - val_loss: 0.0125 - val_mae: 0.0410\n",
      "Epoch 9/250\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.0414 - mae: 0.0640 - val_loss: 0.0131 - val_mae: 0.0427\n",
      "Epoch 10/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0527 - mae: 0.0686 - val_loss: 0.0338 - val_mae: 0.0461\n",
      "Epoch 11/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0421 - mae: 0.0651 - val_loss: 0.0130 - val_mae: 0.0424\n",
      "Epoch 12/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0500 - mae: 0.0682 - val_loss: 0.0124 - val_mae: 0.0408\n",
      "Epoch 13/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0409 - mae: 0.0640 - val_loss: 0.0132 - val_mae: 0.0430\n",
      "Epoch 14/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0407 - mae: 0.0634 - val_loss: 0.1099 - val_mae: 0.0936\n",
      "Epoch 15/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0411 - mae: 0.0661 - val_loss: 0.0658 - val_mae: 0.0620\n",
      "Epoch 16/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0348 - mae: 0.0634 - val_loss: 0.0126 - val_mae: 0.0414\n",
      "Epoch 17/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0439 - mae: 0.0637 - val_loss: 0.0324 - val_mae: 0.0554\n",
      "Epoch 18/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0350 - mae: 0.0626 - val_loss: 0.0398 - val_mae: 0.0464\n",
      "############### next fold => number 3 ########## \n",
      "Epoch 1/250\n",
      "4/4 [==============================] - 3s 188ms/step - loss: 0.2734 - mae: 0.1720 - val_loss: 0.1221 - val_mae: 0.0953\n",
      "Epoch 2/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0526 - mae: 0.0707 - val_loss: 0.1130 - val_mae: 0.0902\n",
      "Epoch 3/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0459 - mae: 0.0591 - val_loss: 0.1199 - val_mae: 0.0940\n",
      "Epoch 4/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0457 - mae: 0.0592 - val_loss: 0.1141 - val_mae: 0.0908\n",
      "Epoch 5/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0448 - mae: 0.0598 - val_loss: 0.0400 - val_mae: 0.0824\n",
      "Epoch 6/250\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 0.0435 - mae: 0.0588 - val_loss: 0.1050 - val_mae: 0.0862\n",
      "Epoch 7/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0426 - mae: 0.0602 - val_loss: 0.0979 - val_mae: 0.0850\n",
      "Epoch 8/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0418 - mae: 0.0590 - val_loss: 0.0463 - val_mae: 0.0825\n",
      "Epoch 9/250\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.0407 - mae: 0.0597 - val_loss: 0.0369 - val_mae: 0.0793\n",
      "Epoch 10/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0370 - mae: 0.0597 - val_loss: 0.0286 - val_mae: 0.0712\n",
      "Epoch 11/250\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.0430 - mae: 0.0618 - val_loss: 0.1242 - val_mae: 0.0966\n",
      "Epoch 12/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0380 - mae: 0.0618 - val_loss: 0.0327 - val_mae: 0.0752\n",
      "Epoch 13/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0353 - mae: 0.0621 - val_loss: 0.0245 - val_mae: 0.0727\n",
      "Epoch 14/250\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.0527 - mae: 0.0750 - val_loss: 0.1049 - val_mae: 0.0866\n",
      "Epoch 15/250\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 0.0357 - mae: 0.0613 - val_loss: 0.1496 - val_mae: 0.1108\n",
      "Epoch 16/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0356 - mae: 0.0603 - val_loss: 0.0349 - val_mae: 0.0726\n",
      "Epoch 17/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0426 - mae: 0.0672 - val_loss: 0.0408 - val_mae: 0.0792\n",
      "Epoch 18/250\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.0341 - mae: 0.0603 - val_loss: 0.0384 - val_mae: 0.0789\n",
      "Epoch 19/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0346 - mae: 0.0618 - val_loss: 0.0841 - val_mae: 0.0867\n",
      "Epoch 20/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0352 - mae: 0.0619 - val_loss: 0.0557 - val_mae: 0.0860\n",
      "Epoch 21/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0343 - mae: 0.0622 - val_loss: 0.0263 - val_mae: 0.0694\n",
      "Epoch 22/250\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.0321 - mae: 0.0620 - val_loss: 0.0249 - val_mae: 0.0685\n",
      "Epoch 23/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0441 - mae: 0.0683 - val_loss: 0.0482 - val_mae: 0.0832\n",
      "Epoch 24/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0303 - mae: 0.0607 - val_loss: 0.0321 - val_mae: 0.0702\n",
      "Epoch 25/250\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 0.0335 - mae: 0.0629 - val_loss: 0.0892 - val_mae: 0.0885\n",
      "Epoch 26/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0313 - mae: 0.0607 - val_loss: 0.0257 - val_mae: 0.0690\n",
      "Epoch 27/250\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 0.0381 - mae: 0.0648 - val_loss: 0.2187 - val_mae: 0.1445\n",
      "Epoch 28/250\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 0.0443 - mae: 0.0651 - val_loss: 0.0353 - val_mae: 0.0742\n",
      "############### next fold => number 4 ########## \n",
      "Epoch 1/250\n",
      "4/4 [==============================] - 3s 201ms/step - loss: 0.0973 - mae: 0.1013 - val_loss: 0.4465 - val_mae: 0.3816\n",
      "Epoch 2/250\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.4620 - mae: 0.2203 - val_loss: 0.1684 - val_mae: 0.1247\n",
      "Epoch 3/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0527 - mae: 0.0648 - val_loss: 0.1308 - val_mae: 0.1085\n",
      "Epoch 4/250\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.0459 - mae: 0.0609 - val_loss: 0.0348 - val_mae: 0.0928\n",
      "Epoch 5/250\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.0417 - mae: 0.0642 - val_loss: 0.1540 - val_mae: 0.1192\n",
      "Epoch 6/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0419 - mae: 0.0656 - val_loss: 0.2638 - val_mae: 0.1582\n",
      "Epoch 7/250\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.0574 - mae: 0.0749 - val_loss: 0.0379 - val_mae: 0.0976\n",
      "Epoch 8/250\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 0.0316 - mae: 0.0617 - val_loss: 0.1393 - val_mae: 0.1127\n",
      "Epoch 9/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0465 - mae: 0.0660 - val_loss: 0.2649 - val_mae: 0.1591\n",
      "Epoch 10/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0380 - mae: 0.0671 - val_loss: 0.0344 - val_mae: 0.0928\n",
      "Epoch 11/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0303 - mae: 0.0619 - val_loss: 0.0302 - val_mae: 0.0773\n",
      "Epoch 12/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0641 - mae: 0.0820 - val_loss: 0.0297 - val_mae: 0.0845\n",
      "Epoch 13/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0299 - mae: 0.0602 - val_loss: 0.0343 - val_mae: 0.0929\n",
      "Epoch 14/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0302 - mae: 0.0607 - val_loss: 0.1739 - val_mae: 0.1274\n",
      "Epoch 15/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0465 - mae: 0.0695 - val_loss: 0.0334 - val_mae: 0.0909\n",
      "Epoch 16/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0272 - mae: 0.0574 - val_loss: 0.0290 - val_mae: 0.0814\n",
      "Epoch 17/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0425 - mae: 0.0630 - val_loss: 0.0348 - val_mae: 0.0937\n",
      "Epoch 18/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0287 - mae: 0.0576 - val_loss: 0.0314 - val_mae: 0.0876\n",
      "Epoch 19/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0341 - mae: 0.0642 - val_loss: 0.0357 - val_mae: 0.0946\n",
      "Epoch 20/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0286 - mae: 0.0580 - val_loss: 0.0339 - val_mae: 0.0909\n",
      "Epoch 21/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0450 - mae: 0.0642 - val_loss: 0.1853 - val_mae: 0.1301\n",
      "Epoch 22/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0542 - mae: 0.0695 - val_loss: 0.0401 - val_mae: 0.1006\n",
      "Epoch 23/250\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.0268 - mae: 0.0557 - val_loss: 0.0376 - val_mae: 0.0969\n",
      "Epoch 24/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0265 - mae: 0.0562 - val_loss: 0.0345 - val_mae: 0.0920\n",
      "Epoch 25/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0345 - mae: 0.0594 - val_loss: 0.1474 - val_mae: 0.1180\n",
      "Epoch 26/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0303 - mae: 0.0621 - val_loss: 0.0391 - val_mae: 0.0988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0302 - mae: 0.0574 - val_loss: 0.0363 - val_mae: 0.0948\n",
      "Epoch 28/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0281 - mae: 0.0547 - val_loss: 0.0393 - val_mae: 0.0991\n",
      "Epoch 29/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0281 - mae: 0.0567 - val_loss: 0.0372 - val_mae: 0.0963\n",
      "Epoch 30/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0267 - mae: 0.0564 - val_loss: 0.0314 - val_mae: 0.0869\n",
      "Epoch 31/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0330 - mae: 0.0640 - val_loss: 0.0379 - val_mae: 0.0972\n",
      "############### next fold => number 5 ########## \n",
      "Epoch 1/250\n",
      "4/4 [==============================] - 4s 195ms/step - loss: 0.0887 - mae: 0.0962 - val_loss: 0.1465 - val_mae: 0.1379\n",
      "Epoch 2/250\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.0771 - mae: 0.0896 - val_loss: 0.0923 - val_mae: 0.1029\n",
      "Epoch 3/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0467 - mae: 0.0723 - val_loss: 0.1047 - val_mae: 0.1195\n",
      "Epoch 4/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0606 - mae: 0.0769 - val_loss: 0.0821 - val_mae: 0.1066\n",
      "Epoch 5/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0360 - mae: 0.0663 - val_loss: 0.0889 - val_mae: 0.1107\n",
      "Epoch 6/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0336 - mae: 0.0680 - val_loss: 0.0963 - val_mae: 0.1040\n",
      "Epoch 7/250\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.0434 - mae: 0.0688 - val_loss: 0.0922 - val_mae: 0.1125\n",
      "Epoch 8/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0435 - mae: 0.0701 - val_loss: 0.0929 - val_mae: 0.1027\n",
      "Epoch 9/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0472 - mae: 0.0711 - val_loss: 0.0790 - val_mae: 0.1045\n",
      "Epoch 10/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0311 - mae: 0.0630 - val_loss: 0.0963 - val_mae: 0.1150\n",
      "Epoch 11/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0313 - mae: 0.0653 - val_loss: 0.1193 - val_mae: 0.1256\n",
      "Epoch 12/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0336 - mae: 0.0679 - val_loss: 0.0738 - val_mae: 0.1012\n",
      "Epoch 13/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0529 - mae: 0.0755 - val_loss: 0.0964 - val_mae: 0.1149\n",
      "Epoch 14/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0306 - mae: 0.0657 - val_loss: 0.1118 - val_mae: 0.1221\n",
      "Epoch 15/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0310 - mae: 0.0654 - val_loss: 0.0728 - val_mae: 0.1003\n",
      "Epoch 16/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0371 - mae: 0.0672 - val_loss: 0.1133 - val_mae: 0.1228\n",
      "Epoch 17/250\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 0.0277 - mae: 0.0629 - val_loss: 0.0888 - val_mae: 0.1102\n",
      "Epoch 18/250\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 0.0321 - mae: 0.0670 - val_loss: 0.0922 - val_mae: 0.1128\n",
      "Epoch 19/250\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.0367 - mae: 0.0656 - val_loss: 0.0818 - val_mae: 0.1060\n",
      "Epoch 20/250\n",
      "4/4 [==============================] - 0s 95ms/step - loss: 0.0257 - mae: 0.0611 - val_loss: 0.0750 - val_mae: 0.1016\n",
      "Epoch 21/250\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 0.0342 - mae: 0.0647 - val_loss: 0.1876 - val_mae: 0.1496\n",
      "Epoch 22/250\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.0855 - mae: 0.0977 - val_loss: 0.0856 - val_mae: 0.1087\n",
      "Epoch 23/250\n",
      "4/4 [==============================] - 0s 90ms/step - loss: 0.0302 - mae: 0.0641 - val_loss: 0.0745 - val_mae: 0.1013\n",
      "Epoch 24/250\n",
      "4/4 [==============================] - 0s 117ms/step - loss: 0.0287 - mae: 0.0611 - val_loss: 0.0797 - val_mae: 0.1047\n",
      "Epoch 25/250\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 0.0243 - mae: 0.0596 - val_loss: 0.1498 - val_mae: 0.1389\n",
      "Epoch 26/250\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.0283 - mae: 0.0652 - val_loss: 0.1110 - val_mae: 0.1219\n",
      "Epoch 27/250\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.0248 - mae: 0.0620 - val_loss: 0.0842 - val_mae: 0.1076\n",
      "Epoch 28/250\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.0271 - mae: 0.0611 - val_loss: 0.0943 - val_mae: 0.1135\n",
      "Epoch 29/250\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 0.0233 - mae: 0.0589 - val_loss: 0.0953 - val_mae: 0.1131\n",
      "Epoch 30/250\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 0.0230 - mae: 0.0609 - val_loss: 0.0887 - val_mae: 0.1105\n",
      "############### next fold => number 6 ########## \n",
      "Epoch 1/250\n",
      "4/4 [==============================] - 3s 199ms/step - loss: 0.1807 - mae: 0.1308 - val_loss: 0.0748 - val_mae: 0.0901\n",
      "Epoch 2/250\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.0363 - mae: 0.0681 - val_loss: 0.0781 - val_mae: 0.0924\n",
      "Epoch 3/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0352 - mae: 0.0683 - val_loss: 0.0792 - val_mae: 0.0931\n",
      "Epoch 4/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0332 - mae: 0.0675 - val_loss: 0.0797 - val_mae: 0.0934\n",
      "Epoch 5/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0373 - mae: 0.0700 - val_loss: 0.6560 - val_mae: 0.3201\n",
      "Epoch 6/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0893 - mae: 0.1107 - val_loss: 0.0812 - val_mae: 0.0943\n",
      "Epoch 7/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0351 - mae: 0.0680 - val_loss: 0.0809 - val_mae: 0.0941\n",
      "Epoch 8/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0330 - mae: 0.0667 - val_loss: 0.0751 - val_mae: 0.0906\n",
      "Epoch 9/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0278 - mae: 0.0630 - val_loss: 0.0789 - val_mae: 0.0931\n",
      "Epoch 10/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0287 - mae: 0.0643 - val_loss: 0.0819 - val_mae: 0.0948\n",
      "Epoch 11/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0302 - mae: 0.0659 - val_loss: 0.0831 - val_mae: 0.0956\n",
      "Epoch 12/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0268 - mae: 0.0634 - val_loss: 0.0835 - val_mae: 0.0958\n",
      "Epoch 13/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0293 - mae: 0.0656 - val_loss: 0.0876 - val_mae: 0.0983\n",
      "Epoch 14/250\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 0.0293 - mae: 0.0636 - val_loss: 0.0895 - val_mae: 0.0995\n",
      "Epoch 15/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0274 - mae: 0.0642 - val_loss: 0.0869 - val_mae: 0.0979\n",
      "Epoch 16/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0276 - mae: 0.0637 - val_loss: 0.0874 - val_mae: 0.0981\n",
      "############### next fold => number 7 ########## \n",
      "Epoch 1/250\n",
      "4/4 [==============================] - 3s 196ms/step - loss: 1.2530 - mae: 0.3422 - val_loss: 0.1423 - val_mae: 0.1589\n",
      "Epoch 2/250\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 0.0983 - mae: 0.1007 - val_loss: 0.0312 - val_mae: 0.0607\n",
      "Epoch 3/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0444 - mae: 0.0684 - val_loss: 0.0421 - val_mae: 0.0640\n",
      "Epoch 4/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0351 - mae: 0.0670 - val_loss: 0.0412 - val_mae: 0.0622\n",
      "Epoch 5/250\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 0.0363 - mae: 0.0661 - val_loss: 0.0420 - val_mae: 0.0638\n",
      "Epoch 6/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0365 - mae: 0.0663 - val_loss: 0.0421 - val_mae: 0.0640\n",
      "Epoch 7/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0356 - mae: 0.0660 - val_loss: 0.0428 - val_mae: 0.0662\n",
      "Epoch 8/250\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 0.0351 - mae: 0.0668 - val_loss: 0.0487 - val_mae: 0.0734\n",
      "Epoch 9/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0409 - mae: 0.0700 - val_loss: 0.0443 - val_mae: 0.0686\n",
      "Epoch 10/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0371 - mae: 0.0671 - val_loss: 0.0420 - val_mae: 0.0636\n",
      "Epoch 11/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0351 - mae: 0.0660 - val_loss: 0.0418 - val_mae: 0.0629\n",
      "Epoch 12/250\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.0382 - mae: 0.0683 - val_loss: 0.0327 - val_mae: 0.0623\n",
      "Epoch 13/250\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 0.0387 - mae: 0.0663 - val_loss: 0.0510 - val_mae: 0.0754\n",
      "Epoch 14/250\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.0365 - mae: 0.0668 - val_loss: 0.0450 - val_mae: 0.0695\n",
      "Epoch 15/250\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 0.0357 - mae: 0.0660 - val_loss: 0.0509 - val_mae: 0.0753\n",
      "Epoch 16/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0356 - mae: 0.0672 - val_loss: 0.0422 - val_mae: 0.0643\n",
      "Epoch 17/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0368 - mae: 0.0665 - val_loss: 0.0436 - val_mae: 0.0674\n",
      "############### next fold => number 8 ########## \n",
      "Epoch 1/250\n",
      "4/4 [==============================] - 4s 193ms/step - loss: 0.0872 - mae: 0.1084 - val_loss: 0.3199 - val_mae: 0.1923\n",
      "Epoch 2/250\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.0561 - mae: 0.0906 - val_loss: 0.0277 - val_mae: 0.0535\n",
      "Epoch 3/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0488 - mae: 0.0727 - val_loss: 0.0249 - val_mae: 0.0542\n",
      "Epoch 4/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0555 - mae: 0.0745 - val_loss: 0.0890 - val_mae: 0.0813\n",
      "Epoch 5/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0381 - mae: 0.0724 - val_loss: 0.0279 - val_mae: 0.0537\n",
      "Epoch 6/250\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.0483 - mae: 0.0748 - val_loss: 0.0265 - val_mae: 0.0661\n",
      "Epoch 7/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0667 - mae: 0.0801 - val_loss: 0.0732 - val_mae: 0.0693\n",
      "Epoch 8/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0395 - mae: 0.0718 - val_loss: 0.1331 - val_mae: 0.1091\n",
      "Epoch 9/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0408 - mae: 0.0710 - val_loss: 0.0815 - val_mae: 0.0763\n",
      "Epoch 10/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0461 - mae: 0.0723 - val_loss: 0.0714 - val_mae: 0.0679\n",
      "Epoch 11/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0356 - mae: 0.0706 - val_loss: 0.0631 - val_mae: 0.0611\n",
      "Epoch 12/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0445 - mae: 0.0760 - val_loss: 0.0740 - val_mae: 0.0701\n",
      "Epoch 13/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0377 - mae: 0.0714 - val_loss: 0.0642 - val_mae: 0.0619\n",
      "Epoch 14/250\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.0521 - mae: 0.0847 - val_loss: 0.0576 - val_mae: 0.0563\n",
      "Epoch 15/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0407 - mae: 0.0716 - val_loss: 0.0724 - val_mae: 0.0688\n",
      "Epoch 16/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0384 - mae: 0.0710 - val_loss: 0.0798 - val_mae: 0.0747\n",
      "Epoch 17/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0364 - mae: 0.0723 - val_loss: 0.0675 - val_mae: 0.0642\n",
      "Epoch 18/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0359 - mae: 0.0717 - val_loss: 0.0621 - val_mae: 0.0603\n",
      "############### next fold => number 9 ########## \n",
      "Epoch 1/250\n",
      "4/4 [==============================] - 3s 192ms/step - loss: 0.3931 - mae: 0.2179 - val_loss: 0.0218 - val_mae: 0.0530\n",
      "Epoch 2/250\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.0611 - mae: 0.0785 - val_loss: 0.0361 - val_mae: 0.0560\n",
      "Epoch 3/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0524 - mae: 0.0779 - val_loss: 0.0359 - val_mae: 0.0557\n",
      "Epoch 4/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0481 - mae: 0.0761 - val_loss: 0.0353 - val_mae: 0.0541\n",
      "Epoch 5/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0465 - mae: 0.0759 - val_loss: 0.0432 - val_mae: 0.0664\n",
      "Epoch 6/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0470 - mae: 0.0767 - val_loss: 0.0419 - val_mae: 0.0648\n",
      "Epoch 7/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0440 - mae: 0.0768 - val_loss: 0.0246 - val_mae: 0.0537\n",
      "Epoch 8/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0614 - mae: 0.0827 - val_loss: 0.0362 - val_mae: 0.0560\n",
      "Epoch 9/250\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.0500 - mae: 0.0773 - val_loss: 0.0375 - val_mae: 0.0581\n",
      "Epoch 10/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0784 - mae: 0.0990 - val_loss: 0.0217 - val_mae: 0.0527\n",
      "Epoch 11/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0700 - mae: 0.0814 - val_loss: 0.0747 - val_mae: 0.0945\n",
      "Epoch 12/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0520 - mae: 0.0839 - val_loss: 0.0516 - val_mae: 0.0759\n",
      "Epoch 13/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0494 - mae: 0.0785 - val_loss: 0.0382 - val_mae: 0.0589\n",
      "Epoch 14/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0490 - mae: 0.0769 - val_loss: 0.0450 - val_mae: 0.0687\n",
      "Epoch 15/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0463 - mae: 0.0762 - val_loss: 0.0359 - val_mae: 0.0555\n",
      "Epoch 16/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0441 - mae: 0.0747 - val_loss: 0.0219 - val_mae: 0.0529\n",
      "Epoch 17/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0375 - mae: 0.0748 - val_loss: 0.0223 - val_mae: 0.0518\n",
      "Epoch 18/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0529 - mae: 0.0759 - val_loss: 0.0519 - val_mae: 0.0760\n",
      "Epoch 19/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0405 - mae: 0.0776 - val_loss: 0.0223 - val_mae: 0.0517\n",
      "Epoch 20/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0470 - mae: 0.0793 - val_loss: 0.0250 - val_mae: 0.0541\n",
      "Epoch 21/250\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.0349 - mae: 0.0754 - val_loss: 0.0225 - val_mae: 0.0521\n",
      "Epoch 22/250\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.0434 - mae: 0.0772 - val_loss: 0.0226 - val_mae: 0.0522\n",
      "Epoch 23/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0378 - mae: 0.0746 - val_loss: 0.0219 - val_mae: 0.0514\n",
      "Epoch 24/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0545 - mae: 0.0800 - val_loss: 0.0394 - val_mae: 0.0640\n",
      "Epoch 25/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0388 - mae: 0.0746 - val_loss: 0.0213 - val_mae: 0.0563\n",
      "Epoch 26/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0328 - mae: 0.0752 - val_loss: 0.0235 - val_mae: 0.0534\n",
      "Epoch 27/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0505 - mae: 0.0773 - val_loss: 0.0258 - val_mae: 0.0560\n",
      "Epoch 28/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0328 - mae: 0.0721 - val_loss: 0.0215 - val_mae: 0.0513\n",
      "Epoch 29/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0429 - mae: 0.0793 - val_loss: 0.1068 - val_mae: 0.1154\n",
      "Epoch 30/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0610 - mae: 0.0853 - val_loss: 0.0424 - val_mae: 0.0659\n",
      "Epoch 31/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0444 - mae: 0.0762 - val_loss: 0.0239 - val_mae: 0.0540\n",
      "Epoch 32/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0351 - mae: 0.0734 - val_loss: 0.0388 - val_mae: 0.0620\n",
      "Epoch 33/250\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.0378 - mae: 0.0742 - val_loss: 0.0242 - val_mae: 0.0540\n",
      "Epoch 34/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0319 - mae: 0.0730 - val_loss: 0.0275 - val_mae: 0.0577\n",
      "Epoch 35/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0431 - mae: 0.0768 - val_loss: 0.0244 - val_mae: 0.0543\n",
      "Epoch 36/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0301 - mae: 0.0726 - val_loss: 0.0168 - val_mae: 0.0518\n",
      "Epoch 37/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0394 - mae: 0.0758 - val_loss: 0.0249 - val_mae: 0.0548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0314 - mae: 0.0723 - val_loss: 0.0267 - val_mae: 0.0561\n",
      "Epoch 39/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0385 - mae: 0.0774 - val_loss: 0.0317 - val_mae: 0.0562\n",
      "Epoch 40/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0323 - mae: 0.0715 - val_loss: 0.0868 - val_mae: 0.1027\n",
      "Epoch 41/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0573 - mae: 0.0835 - val_loss: 0.0327 - val_mae: 0.0538\n",
      "Epoch 42/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0313 - mae: 0.0724 - val_loss: 0.0398 - val_mae: 0.0635\n",
      "Epoch 43/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0398 - mae: 0.0777 - val_loss: 0.0143 - val_mae: 0.0517\n",
      "Epoch 44/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0309 - mae: 0.0715 - val_loss: 0.0258 - val_mae: 0.0561\n",
      "Epoch 45/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0310 - mae: 0.0718 - val_loss: 0.0244 - val_mae: 0.0547\n",
      "Epoch 46/250\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.0308 - mae: 0.0725 - val_loss: 0.0296 - val_mae: 0.0605\n",
      "Epoch 47/250\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 0.0393 - mae: 0.0778 - val_loss: 0.0222 - val_mae: 0.0518\n",
      "Epoch 48/250\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.0305 - mae: 0.0719 - val_loss: 0.0224 - val_mae: 0.0522\n",
      "Epoch 49/250\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.0311 - mae: 0.0700 - val_loss: 0.0319 - val_mae: 0.0631\n",
      "Epoch 50/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0329 - mae: 0.0732 - val_loss: 0.0222 - val_mae: 0.0520\n",
      "Epoch 51/250\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.0293 - mae: 0.0699 - val_loss: 0.0218 - val_mae: 0.0518\n",
      "Epoch 52/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0411 - mae: 0.0788 - val_loss: 0.0266 - val_mae: 0.0571\n",
      "Epoch 53/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0287 - mae: 0.0702 - val_loss: 0.0253 - val_mae: 0.0557\n",
      "Epoch 54/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0335 - mae: 0.0726 - val_loss: 0.0242 - val_mae: 0.0546\n",
      "Epoch 55/250\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 0.0310 - mae: 0.0711 - val_loss: 0.0294 - val_mae: 0.0605\n",
      "Epoch 56/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0386 - mae: 0.0754 - val_loss: 0.0354 - val_mae: 0.0675\n",
      "Epoch 57/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0312 - mae: 0.0726 - val_loss: 0.0215 - val_mae: 0.0517\n",
      "Epoch 58/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0308 - mae: 0.0709 - val_loss: 0.0214 - val_mae: 0.0520\n",
      "############### next fold => number 10 ########## \n",
      "Epoch 1/250\n",
      "4/4 [==============================] - 3s 198ms/step - loss: 0.1615 - mae: 0.1426 - val_loss: 0.0534 - val_mae: 0.0646\n",
      "Epoch 2/250\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.1093 - mae: 0.1127 - val_loss: 0.0165 - val_mae: 0.0494\n",
      "Epoch 3/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0779 - mae: 0.0882 - val_loss: 0.0180 - val_mae: 0.0509\n",
      "Epoch 4/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0782 - mae: 0.0849 - val_loss: 0.0193 - val_mae: 0.0521\n",
      "Epoch 5/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0590 - mae: 0.0808 - val_loss: 0.0405 - val_mae: 0.0543\n",
      "Epoch 6/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0558 - mae: 0.0805 - val_loss: 0.0428 - val_mae: 0.0561\n",
      "Epoch 7/250\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.0555 - mae: 0.0794 - val_loss: 0.0540 - val_mae: 0.0665\n",
      "Epoch 8/250\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 0.0571 - mae: 0.0795 - val_loss: 0.0187 - val_mae: 0.0514\n",
      "Epoch 9/250\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 0.0433 - mae: 0.0760 - val_loss: 0.0190 - val_mae: 0.0519\n",
      "Epoch 10/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0386 - mae: 0.0775 - val_loss: 0.0167 - val_mae: 0.0497\n",
      "Epoch 11/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0373 - mae: 0.0751 - val_loss: 0.0173 - val_mae: 0.0494\n",
      "Epoch 12/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0385 - mae: 0.0757 - val_loss: 0.0179 - val_mae: 0.0502\n",
      "Epoch 13/250\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.0373 - mae: 0.0731 - val_loss: 0.0173 - val_mae: 0.0498\n",
      "Epoch 14/250\n",
      "4/4 [==============================] - 0s 100ms/step - loss: 0.0581 - mae: 0.0816 - val_loss: 0.0164 - val_mae: 0.0478\n",
      "Epoch 15/250\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.0349 - mae: 0.0744 - val_loss: 0.0462 - val_mae: 0.0598\n",
      "Epoch 16/250\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.0569 - mae: 0.0823 - val_loss: 0.0731 - val_mae: 0.0837\n",
      "Epoch 17/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0401 - mae: 0.0758 - val_loss: 0.0161 - val_mae: 0.0465\n",
      "Epoch 18/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0579 - mae: 0.0815 - val_loss: 0.0796 - val_mae: 0.0877\n",
      "Epoch 19/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0563 - mae: 0.0846 - val_loss: 0.0425 - val_mae: 0.0560\n",
      "Epoch 20/250\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 0.0437 - mae: 0.0757 - val_loss: 0.0479 - val_mae: 0.0616\n",
      "Epoch 21/250\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 0.0400 - mae: 0.0760 - val_loss: 0.0461 - val_mae: 0.0603\n",
      "Epoch 22/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0366 - mae: 0.0738 - val_loss: 0.0546 - val_mae: 0.0691\n",
      "Epoch 23/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0390 - mae: 0.0752 - val_loss: 0.0260 - val_mae: 0.0558\n",
      "Epoch 24/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0382 - mae: 0.0752 - val_loss: 0.0157 - val_mae: 0.0470\n",
      "Epoch 25/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0423 - mae: 0.0752 - val_loss: 0.0546 - val_mae: 0.0684\n",
      "Epoch 26/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0345 - mae: 0.0730 - val_loss: 0.1709 - val_mae: 0.1415\n",
      "Epoch 27/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0692 - mae: 0.0894 - val_loss: 0.0190 - val_mae: 0.0494\n",
      "Epoch 28/250\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 0.0360 - mae: 0.0750 - val_loss: 0.1075 - val_mae: 0.1077\n",
      "Epoch 29/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0717 - mae: 0.0913 - val_loss: 0.0537 - val_mae: 0.0664\n",
      "Epoch 30/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0440 - mae: 0.0768 - val_loss: 0.0569 - val_mae: 0.0720\n",
      "Epoch 31/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0447 - mae: 0.0806 - val_loss: 0.0220 - val_mae: 0.0515\n",
      "Epoch 32/250\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.0358 - mae: 0.0748 - val_loss: 0.0306 - val_mae: 0.0584\n",
      "Epoch 33/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0351 - mae: 0.0720 - val_loss: 0.0149 - val_mae: 0.0479\n",
      "Epoch 34/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0350 - mae: 0.0743 - val_loss: 0.1619 - val_mae: 0.1371\n",
      "Epoch 35/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0537 - mae: 0.0828 - val_loss: 0.0583 - val_mae: 0.0728\n",
      "Epoch 36/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0354 - mae: 0.0721 - val_loss: 0.0172 - val_mae: 0.0493\n",
      "Epoch 37/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0327 - mae: 0.0731 - val_loss: 0.1076 - val_mae: 0.1073\n",
      "Epoch 38/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0525 - mae: 0.0812 - val_loss: 0.0286 - val_mae: 0.0586\n",
      "Epoch 39/250\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.0376 - mae: 0.0742 - val_loss: 0.0160 - val_mae: 0.0473\n",
      "Epoch 40/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0494 - mae: 0.0776 - val_loss: 0.0233 - val_mae: 0.0511\n",
      "Epoch 41/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0316 - mae: 0.0718 - val_loss: 0.0564 - val_mae: 0.0704\n",
      "Epoch 42/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0320 - mae: 0.0714 - val_loss: 0.0598 - val_mae: 0.0747\n",
      "Epoch 43/250\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.0352 - mae: 0.0736 - val_loss: 0.0199 - val_mae: 0.0504\n",
      "Epoch 44/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0310 - mae: 0.0712 - val_loss: 0.0306 - val_mae: 0.0548\n",
      "Epoch 45/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0314 - mae: 0.0733 - val_loss: 0.0165 - val_mae: 0.0501\n",
      "Epoch 46/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0441 - mae: 0.0789 - val_loss: 0.0986 - val_mae: 0.1011\n",
      "Epoch 47/250\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.0334 - mae: 0.0713 - val_loss: 0.0575 - val_mae: 0.0725\n",
      "Epoch 48/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0306 - mae: 0.0705 - val_loss: 0.0739 - val_mae: 0.0866\n",
      "############### next fold => number 11 ########## \n",
      "Epoch 1/250\n",
      "4/4 [==============================] - 4s 194ms/step - loss: 0.1502 - mae: 0.1350 - val_loss: 0.3362 - val_mae: 0.2218\n",
      "Epoch 2/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.5096 - mae: 0.2515 - val_loss: 0.0131 - val_mae: 0.0412\n",
      "Epoch 3/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0642 - mae: 0.0838 - val_loss: 0.0125 - val_mae: 0.0451\n",
      "Epoch 4/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0656 - mae: 0.0854 - val_loss: 0.0311 - val_mae: 0.0555\n",
      "Epoch 5/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0642 - mae: 0.0841 - val_loss: 0.0128 - val_mae: 0.0409\n",
      "Epoch 6/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0610 - mae: 0.0826 - val_loss: 0.0112 - val_mae: 0.0416\n",
      "Epoch 7/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0705 - mae: 0.0862 - val_loss: 0.0140 - val_mae: 0.0482\n",
      "Epoch 8/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0698 - mae: 0.0888 - val_loss: 0.0304 - val_mae: 0.0548\n",
      "Epoch 9/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0596 - mae: 0.0812 - val_loss: 0.0734 - val_mae: 0.0953\n",
      "Epoch 10/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0691 - mae: 0.0876 - val_loss: 0.0151 - val_mae: 0.0422\n",
      "Epoch 11/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0523 - mae: 0.0808 - val_loss: 0.0156 - val_mae: 0.0494\n",
      "Epoch 12/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0745 - mae: 0.0935 - val_loss: 0.1556 - val_mae: 0.1777\n",
      "Epoch 13/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.1463 - mae: 0.1298 - val_loss: 0.0283 - val_mae: 0.0523\n",
      "Epoch 14/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0450 - mae: 0.0807 - val_loss: 0.0216 - val_mae: 0.0439\n",
      "Epoch 15/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0381 - mae: 0.0782 - val_loss: 0.0210 - val_mae: 0.0432\n",
      "Epoch 16/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0384 - mae: 0.0759 - val_loss: 0.0300 - val_mae: 0.0543\n",
      "Epoch 17/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0414 - mae: 0.0765 - val_loss: 0.0319 - val_mae: 0.0564\n",
      "Epoch 18/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0457 - mae: 0.0787 - val_loss: 0.0331 - val_mae: 0.0579\n",
      "Epoch 19/250\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.0393 - mae: 0.0763 - val_loss: 0.0270 - val_mae: 0.0501\n",
      "Epoch 20/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0362 - mae: 0.0731 - val_loss: 0.0437 - val_mae: 0.0687\n",
      "Epoch 21/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0443 - mae: 0.0766 - val_loss: 0.0094 - val_mae: 0.0431\n",
      "Epoch 22/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0684 - mae: 0.0951 - val_loss: 0.0345 - val_mae: 0.0596\n",
      "Epoch 23/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0595 - mae: 0.0838 - val_loss: 0.0134 - val_mae: 0.0470\n",
      "Epoch 24/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0709 - mae: 0.0878 - val_loss: 0.0206 - val_mae: 0.0427\n",
      "Epoch 25/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0409 - mae: 0.0760 - val_loss: 0.0328 - val_mae: 0.0575\n",
      "Epoch 26/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0544 - mae: 0.0829 - val_loss: 0.0229 - val_mae: 0.0454\n",
      "Epoch 27/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0490 - mae: 0.0777 - val_loss: 0.0365 - val_mae: 0.0613\n",
      "Epoch 28/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0439 - mae: 0.0746 - val_loss: 0.0234 - val_mae: 0.0462\n",
      "Epoch 29/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0352 - mae: 0.0710 - val_loss: 0.0269 - val_mae: 0.0503\n",
      "Epoch 30/250\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.0375 - mae: 0.0735 - val_loss: 0.0112 - val_mae: 0.0412\n",
      "Epoch 31/250\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.0321 - mae: 0.0698 - val_loss: 0.0149 - val_mae: 0.0490\n",
      "Epoch 32/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0829 - mae: 0.0951 - val_loss: 0.0367 - val_mae: 0.0618\n",
      "Epoch 33/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0359 - mae: 0.0740 - val_loss: 0.0282 - val_mae: 0.0519\n",
      "Epoch 34/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0355 - mae: 0.0725 - val_loss: 0.0546 - val_mae: 0.0957\n",
      "Epoch 35/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0899 - mae: 0.0962 - val_loss: 0.0138 - val_mae: 0.0418\n",
      "Epoch 36/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0475 - mae: 0.0777 - val_loss: 0.0117 - val_mae: 0.0414\n",
      "############### next fold => number 12 ########## \n",
      "Epoch 1/250\n",
      "4/4 [==============================] - 3s 195ms/step - loss: 0.1448 - mae: 0.1304 - val_loss: 0.0953 - val_mae: 0.1032\n",
      "Epoch 2/250\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 0.0606 - mae: 0.0793 - val_loss: 0.0319 - val_mae: 0.0563\n",
      "Epoch 3/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0455 - mae: 0.0720 - val_loss: 0.0353 - val_mae: 0.0586\n",
      "Epoch 4/250\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.0447 - mae: 0.0716 - val_loss: 0.0318 - val_mae: 0.0562\n",
      "Epoch 5/250\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.0449 - mae: 0.0716 - val_loss: 0.0380 - val_mae: 0.0606\n",
      "Epoch 6/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0434 - mae: 0.0712 - val_loss: 0.0157 - val_mae: 0.0541\n",
      "Epoch 7/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0491 - mae: 0.0726 - val_loss: 0.0140 - val_mae: 0.0520\n",
      "Epoch 8/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0514 - mae: 0.0723 - val_loss: 0.0145 - val_mae: 0.0525\n",
      "Epoch 9/250\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.0492 - mae: 0.0717 - val_loss: 0.0473 - val_mae: 0.0688\n",
      "Epoch 10/250\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.0463 - mae: 0.0725 - val_loss: 0.0359 - val_mae: 0.0591\n",
      "Epoch 11/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0499 - mae: 0.0718 - val_loss: 0.0419 - val_mae: 0.0639\n",
      "Epoch 12/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0482 - mae: 0.0719 - val_loss: 0.0337 - val_mae: 0.0574\n",
      "Epoch 13/250\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 0.0632 - mae: 0.0790 - val_loss: 0.0128 - val_mae: 0.0502\n",
      "Epoch 14/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0529 - mae: 0.0731 - val_loss: 0.0371 - val_mae: 0.0599\n",
      "Epoch 15/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0441 - mae: 0.0711 - val_loss: 0.0343 - val_mae: 0.0579\n",
      "Epoch 16/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0445 - mae: 0.0712 - val_loss: 0.0327 - val_mae: 0.0568\n",
      "Epoch 17/250\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.0461 - mae: 0.0715 - val_loss: 0.0605 - val_mae: 0.0793\n",
      "Epoch 18/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0450 - mae: 0.0718 - val_loss: 0.0584 - val_mae: 0.0778\n",
      "Epoch 19/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0443 - mae: 0.0719 - val_loss: 0.0445 - val_mae: 0.0664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0440 - mae: 0.0721 - val_loss: 0.0121 - val_mae: 0.0490\n",
      "Epoch 21/250\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.0517 - mae: 0.0742 - val_loss: 0.0317 - val_mae: 0.0561\n",
      "Epoch 22/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0467 - mae: 0.0713 - val_loss: 0.0391 - val_mae: 0.0617\n",
      "Epoch 23/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0613 - mae: 0.0778 - val_loss: 0.0146 - val_mae: 0.0526\n",
      "Epoch 24/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0436 - mae: 0.0711 - val_loss: 0.0428 - val_mae: 0.0647\n",
      "Epoch 25/250\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.0442 - mae: 0.0715 - val_loss: 0.0329 - val_mae: 0.0569\n",
      "Epoch 26/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0441 - mae: 0.0723 - val_loss: 0.0139 - val_mae: 0.0516\n",
      "Epoch 27/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0367 - mae: 0.0701 - val_loss: 0.0687 - val_mae: 0.0855\n",
      "Epoch 28/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0466 - mae: 0.0733 - val_loss: 0.0469 - val_mae: 0.0686\n",
      "Epoch 29/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0479 - mae: 0.0724 - val_loss: 0.0117 - val_mae: 0.0483\n",
      "Epoch 30/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0480 - mae: 0.0719 - val_loss: 0.0118 - val_mae: 0.0520\n",
      "Epoch 31/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0420 - mae: 0.0716 - val_loss: 0.0374 - val_mae: 0.0602\n",
      "Epoch 32/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0387 - mae: 0.0699 - val_loss: 0.0436 - val_mae: 0.0654\n",
      "Epoch 33/250\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.0481 - mae: 0.0731 - val_loss: 1.0083 - val_mae: 0.3727\n",
      "Epoch 34/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.1817 - mae: 0.1514 - val_loss: 0.0188 - val_mae: 0.0543\n",
      "Epoch 35/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0538 - mae: 0.0729 - val_loss: 0.0117 - val_mae: 0.0485\n",
      "Epoch 36/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0378 - mae: 0.0689 - val_loss: 0.0321 - val_mae: 0.0564\n",
      "Epoch 37/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0439 - mae: 0.0717 - val_loss: 0.0407 - val_mae: 0.0629\n",
      "Epoch 38/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0422 - mae: 0.0707 - val_loss: 0.0440 - val_mae: 0.0658\n",
      "Epoch 39/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0422 - mae: 0.0703 - val_loss: 0.0244 - val_mae: 0.0546\n",
      "Epoch 40/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0422 - mae: 0.0707 - val_loss: 0.0116 - val_mae: 0.0496\n",
      "Epoch 41/250\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.0366 - mae: 0.0684 - val_loss: 0.0120 - val_mae: 0.0443\n",
      "Epoch 42/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0456 - mae: 0.0735 - val_loss: 0.0463 - val_mae: 0.0680\n",
      "Epoch 43/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0380 - mae: 0.0701 - val_loss: 0.0550 - val_mae: 0.0752\n",
      "Epoch 44/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0391 - mae: 0.0710 - val_loss: 0.0108 - val_mae: 0.0444\n",
      "Epoch 45/250\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.0430 - mae: 0.0714 - val_loss: 0.0112 - val_mae: 0.0478\n",
      "Epoch 46/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0359 - mae: 0.0687 - val_loss: 0.0188 - val_mae: 0.0545\n",
      "Epoch 47/250\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.0521 - mae: 0.0750 - val_loss: 0.0336 - val_mae: 0.0574\n",
      "Epoch 48/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0371 - mae: 0.0693 - val_loss: 0.0347 - val_mae: 0.0572\n",
      "Epoch 49/250\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.0342 - mae: 0.0678 - val_loss: 0.0484 - val_mae: 0.0695\n",
      "Epoch 50/250\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.0362 - mae: 0.0680 - val_loss: 0.0550 - val_mae: 0.0751\n",
      "Epoch 51/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0437 - mae: 0.0708 - val_loss: 0.0581 - val_mae: 0.0775\n",
      "Epoch 52/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0474 - mae: 0.0728 - val_loss: 0.0363 - val_mae: 0.0593\n",
      "Epoch 53/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0341 - mae: 0.0683 - val_loss: 0.0231 - val_mae: 0.0611\n",
      "Epoch 54/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0449 - mae: 0.0723 - val_loss: 0.0118 - val_mae: 0.0489\n",
      "Epoch 55/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0340 - mae: 0.0666 - val_loss: 0.0263 - val_mae: 0.0575\n",
      "Epoch 56/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0321 - mae: 0.0677 - val_loss: 0.0233 - val_mae: 0.0604\n",
      "Epoch 57/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0365 - mae: 0.0709 - val_loss: 0.0261 - val_mae: 0.0568\n",
      "Epoch 58/250\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.0295 - mae: 0.0652 - val_loss: 0.0427 - val_mae: 0.0649\n",
      "Epoch 59/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0269 - mae: 0.0632 - val_loss: 0.0160 - val_mae: 0.0527\n",
      "############### next fold => number 13 ########## \n",
      "Epoch 1/250\n",
      "4/4 [==============================] - 3s 196ms/step - loss: 0.1918 - mae: 0.1359 - val_loss: 0.3758 - val_mae: 0.1446\n",
      "Epoch 2/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0553 - mae: 0.0803 - val_loss: 0.3899 - val_mae: 0.1462\n",
      "Epoch 3/250\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.0480 - mae: 0.0697 - val_loss: 0.2690 - val_mae: 0.1424\n",
      "Epoch 4/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0353 - mae: 0.0644 - val_loss: 0.2793 - val_mae: 0.1406\n",
      "Epoch 5/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0340 - mae: 0.0635 - val_loss: 0.2724 - val_mae: 0.1412\n",
      "Epoch 6/250\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.0555 - mae: 0.0724 - val_loss: 0.2580 - val_mae: 0.1477\n",
      "Epoch 7/250\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.0339 - mae: 0.0671 - val_loss: 0.3608 - val_mae: 0.1410\n",
      "Epoch 8/250\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.0331 - mae: 0.0624 - val_loss: 0.2693 - val_mae: 0.1410\n",
      "Epoch 9/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0353 - mae: 0.0640 - val_loss: 0.2626 - val_mae: 0.1443\n",
      "Epoch 10/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0405 - mae: 0.0667 - val_loss: 0.2186 - val_mae: 0.1397\n",
      "Epoch 11/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0341 - mae: 0.0644 - val_loss: 0.3595 - val_mae: 0.1419\n",
      "Epoch 12/250\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.0311 - mae: 0.0626 - val_loss: 0.3961 - val_mae: 0.1460\n",
      "Epoch 13/250\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.0398 - mae: 0.0652 - val_loss: 0.2705 - val_mae: 0.1859\n",
      "Epoch 14/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0430 - mae: 0.0723 - val_loss: 0.2809 - val_mae: 0.1401\n",
      "Epoch 15/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0365 - mae: 0.0641 - val_loss: 0.3172 - val_mae: 0.1418\n",
      "Epoch 16/250\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.0379 - mae: 0.0637 - val_loss: 0.3751 - val_mae: 0.1440\n",
      "Epoch 17/250\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 0.0356 - mae: 0.0633 - val_loss: 0.2627 - val_mae: 0.1382\n",
      "Epoch 18/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0341 - mae: 0.0642 - val_loss: 0.3162 - val_mae: 0.1432\n",
      "Epoch 19/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0442 - mae: 0.0638 - val_loss: 0.4749 - val_mae: 0.1725\n",
      "Epoch 20/250\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.0463 - mae: 0.0680 - val_loss: 0.2810 - val_mae: 0.1406\n",
      "Epoch 21/250\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 0.0359 - mae: 0.0634 - val_loss: 0.2787 - val_mae: 0.1407\n",
      "Epoch 22/250\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 0.0361 - mae: 0.0634 - val_loss: 0.2808 - val_mae: 0.1406\n",
      "Epoch 23/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0359 - mae: 0.0633 - val_loss: 0.2807 - val_mae: 0.1406\n",
      "Epoch 24/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0358 - mae: 0.0634 - val_loss: 0.2767 - val_mae: 0.1407\n",
      "Epoch 25/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0362 - mae: 0.0637 - val_loss: 0.2815 - val_mae: 0.1407\n",
      "############### next fold => number 14 ########## \n",
      "Epoch 1/250\n",
      "4/4 [==============================] - 4s 194ms/step - loss: 0.0693 - mae: 0.0946 - val_loss: 0.3625 - val_mae: 0.1952\n",
      "Epoch 2/250\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 0.1545 - mae: 0.1316 - val_loss: 0.4409 - val_mae: 0.1882\n",
      "Epoch 3/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.1389 - mae: 0.1329 - val_loss: 0.3560 - val_mae: 0.1500\n",
      "Epoch 4/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0383 - mae: 0.0656 - val_loss: 0.3634 - val_mae: 0.1494\n",
      "Epoch 5/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0267 - mae: 0.0583 - val_loss: 0.3291 - val_mae: 0.1491\n",
      "Epoch 6/250\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.0303 - mae: 0.0590 - val_loss: 0.3461 - val_mae: 0.1506\n",
      "Epoch 7/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0339 - mae: 0.0618 - val_loss: 0.3321 - val_mae: 0.1492\n",
      "Epoch 8/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0347 - mae: 0.0615 - val_loss: 0.3561 - val_mae: 0.1487\n",
      "Epoch 9/250\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.0294 - mae: 0.0586 - val_loss: 0.3375 - val_mae: 0.1520\n",
      "Epoch 10/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0354 - mae: 0.0652 - val_loss: 0.3464 - val_mae: 0.1488\n",
      "Epoch 11/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0285 - mae: 0.0580 - val_loss: 0.3279 - val_mae: 0.1511\n",
      "Epoch 12/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0378 - mae: 0.0667 - val_loss: 0.3416 - val_mae: 0.1666\n",
      "Epoch 13/250\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.0535 - mae: 0.0768 - val_loss: 0.3311 - val_mae: 0.1526\n",
      "Epoch 14/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0318 - mae: 0.0623 - val_loss: 0.3331 - val_mae: 0.1502\n",
      "Epoch 15/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0375 - mae: 0.0624 - val_loss: 0.3527 - val_mae: 0.1501\n",
      "Epoch 16/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0344 - mae: 0.0590 - val_loss: 0.3476 - val_mae: 0.1514\n",
      "Epoch 17/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0303 - mae: 0.0590 - val_loss: 0.3373 - val_mae: 0.1476\n",
      "Epoch 18/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0455 - mae: 0.0683 - val_loss: 0.3300 - val_mae: 0.1489\n",
      "Epoch 19/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0304 - mae: 0.0585 - val_loss: 0.2211 - val_mae: 0.1447\n",
      "Epoch 20/250\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 0.0308 - mae: 0.0604 - val_loss: 0.3184 - val_mae: 0.1472\n",
      "Epoch 21/250\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.0252 - mae: 0.0573 - val_loss: 0.3276 - val_mae: 0.1486\n",
      "Epoch 22/250\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.0311 - mae: 0.0621 - val_loss: 0.1808 - val_mae: 0.1433\n",
      "Epoch 23/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0279 - mae: 0.0589 - val_loss: 0.3415 - val_mae: 0.1522\n",
      "Epoch 24/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0357 - mae: 0.0632 - val_loss: 0.2918 - val_mae: 0.1459\n",
      "Epoch 25/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0246 - mae: 0.0571 - val_loss: 0.2671 - val_mae: 0.1434\n",
      "Epoch 26/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0222 - mae: 0.0566 - val_loss: 0.3379 - val_mae: 0.1517\n",
      "Epoch 27/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0400 - mae: 0.0647 - val_loss: 0.3257 - val_mae: 0.1452\n",
      "Epoch 28/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0364 - mae: 0.0638 - val_loss: 0.3269 - val_mae: 0.1486\n",
      "Epoch 29/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0225 - mae: 0.0557 - val_loss: 0.3236 - val_mae: 0.1587\n",
      "Epoch 30/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0463 - mae: 0.0740 - val_loss: 0.3246 - val_mae: 0.1486\n",
      "Epoch 31/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0285 - mae: 0.0583 - val_loss: 0.3340 - val_mae: 0.1509\n",
      "Epoch 32/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0277 - mae: 0.0582 - val_loss: 0.2791 - val_mae: 0.1459\n",
      "Epoch 33/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0255 - mae: 0.0576 - val_loss: 0.1679 - val_mae: 0.1423\n",
      "Epoch 34/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0255 - mae: 0.0584 - val_loss: 0.3615 - val_mae: 0.1599\n",
      "Epoch 35/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0450 - mae: 0.0680 - val_loss: 0.3143 - val_mae: 0.1476\n",
      "Epoch 36/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0258 - mae: 0.0584 - val_loss: 0.3230 - val_mae: 0.1481\n",
      "Epoch 37/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0264 - mae: 0.0577 - val_loss: 0.3328 - val_mae: 0.1499\n",
      "Epoch 38/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0411 - mae: 0.0625 - val_loss: 0.3200 - val_mae: 0.1473\n",
      "Epoch 39/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0233 - mae: 0.0562 - val_loss: 0.3200 - val_mae: 0.1475\n",
      "Epoch 40/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0245 - mae: 0.0582 - val_loss: 0.3315 - val_mae: 0.1446\n",
      "Epoch 41/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0294 - mae: 0.0608 - val_loss: 0.3265 - val_mae: 0.1483\n",
      "Epoch 42/250\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.0217 - mae: 0.0563 - val_loss: 0.3327 - val_mae: 0.1456\n",
      "Epoch 43/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0283 - mae: 0.0596 - val_loss: 0.3269 - val_mae: 0.1481\n",
      "Epoch 44/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0189 - mae: 0.0536 - val_loss: 0.2550 - val_mae: 0.1435\n",
      "Epoch 45/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0228 - mae: 0.0577 - val_loss: 0.2033 - val_mae: 0.1449\n",
      "Epoch 46/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0274 - mae: 0.0600 - val_loss: 0.3255 - val_mae: 0.1481\n",
      "Epoch 47/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0235 - mae: 0.0554 - val_loss: 0.3336 - val_mae: 0.1503\n",
      "Epoch 48/250\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 0.0249 - mae: 0.0605 - val_loss: 0.2653 - val_mae: 0.1438\n",
      "############### next fold => number 15 ########## \n",
      "Epoch 1/250\n",
      "4/4 [==============================] - 4s 224ms/step - loss: 0.3568 - mae: 0.2278 - val_loss: 0.0141 - val_mae: 0.0563\n",
      "Epoch 2/250\n",
      "4/4 [==============================] - 0s 93ms/step - loss: 0.0977 - mae: 0.0860 - val_loss: 0.0571 - val_mae: 0.0693\n",
      "Epoch 3/250\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 0.0994 - mae: 0.0820 - val_loss: 0.1732 - val_mae: 0.1346\n",
      "Epoch 4/250\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.0937 - mae: 0.0848 - val_loss: 0.0152 - val_mae: 0.0586\n",
      "Epoch 5/250\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.1283 - mae: 0.0984 - val_loss: 0.1225 - val_mae: 0.1084\n",
      "Epoch 6/250\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.1135 - mae: 0.0869 - val_loss: 0.0187 - val_mae: 0.0622\n",
      "Epoch 7/250\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 0.0973 - mae: 0.0796 - val_loss: 0.1545 - val_mae: 0.1254\n",
      "Epoch 8/250\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.0901 - mae: 0.0863 - val_loss: 0.2694 - val_mae: 0.1738\n",
      "Epoch 9/250\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.1195 - mae: 0.0962 - val_loss: 0.2973 - val_mae: 0.1838\n",
      "Epoch 10/250\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 0.1065 - mae: 0.0979 - val_loss: 0.1266 - val_mae: 0.1105\n",
      "Epoch 11/250\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.1067 - mae: 0.0851 - val_loss: 0.2341 - val_mae: 0.1602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/250\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 0.1065 - mae: 0.0956 - val_loss: 0.1427 - val_mae: 0.1192\n",
      "Epoch 13/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0965 - mae: 0.0842 - val_loss: 0.1120 - val_mae: 0.1021\n",
      "Epoch 14/250\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.0926 - mae: 0.0833 - val_loss: 0.0463 - val_mae: 0.0680\n",
      "Epoch 15/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0969 - mae: 0.0857 - val_loss: 0.0881 - val_mae: 0.0882\n",
      "Epoch 16/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0882 - mae: 0.0813 - val_loss: 0.0176 - val_mae: 0.0594\n",
      "############### next fold => number 16 ########## \n",
      "Epoch 1/250\n",
      "4/4 [==============================] - 3s 189ms/step - loss: 0.5308 - mae: 0.2576 - val_loss: 0.0418 - val_mae: 0.0645\n",
      "Epoch 2/250\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 0.1138 - mae: 0.0810 - val_loss: 0.0322 - val_mae: 0.0627\n",
      "Epoch 3/250\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.1085 - mae: 0.0806 - val_loss: 0.0265 - val_mae: 0.0614\n",
      "Epoch 4/250\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 0.1053 - mae: 0.0783 - val_loss: 0.0269 - val_mae: 0.0613\n",
      "Epoch 5/250\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.1008 - mae: 0.0769 - val_loss: 0.0456 - val_mae: 0.0658\n",
      "Epoch 6/250\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 0.1052 - mae: 0.0793 - val_loss: 0.0267 - val_mae: 0.0613\n",
      "Epoch 7/250\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.1119 - mae: 0.0791 - val_loss: 0.0628 - val_mae: 0.0795\n",
      "Epoch 8/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.1131 - mae: 0.0840 - val_loss: 0.0331 - val_mae: 0.0627\n",
      "Epoch 9/250\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 0.1071 - mae: 0.0774 - val_loss: 0.0489 - val_mae: 0.0679\n",
      "Epoch 10/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.1047 - mae: 0.0805 - val_loss: 0.0270 - val_mae: 0.0614\n",
      "Epoch 11/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.1165 - mae: 0.0811 - val_loss: 0.0522 - val_mae: 0.0705\n",
      "Epoch 12/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.1149 - mae: 0.0805 - val_loss: 0.0730 - val_mae: 0.0876\n",
      "Epoch 13/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.1077 - mae: 0.0838 - val_loss: 0.0290 - val_mae: 0.0622\n",
      "Epoch 14/250\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.1029 - mae: 0.0766 - val_loss: 0.0396 - val_mae: 0.0634\n",
      "Epoch 15/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.1121 - mae: 0.0779 - val_loss: 0.0415 - val_mae: 0.0641\n",
      "Epoch 16/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.1055 - mae: 0.0774 - val_loss: 0.0427 - val_mae: 0.0645\n",
      "Epoch 17/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.1034 - mae: 0.0793 - val_loss: 0.0271 - val_mae: 0.0612\n",
      "Epoch 18/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.1049 - mae: 0.0782 - val_loss: 0.0286 - val_mae: 0.0618\n",
      "############### next fold => number 17 ########## \n",
      "Epoch 1/250\n",
      "4/4 [==============================] - 4s 191ms/step - loss: 0.1415 - mae: 0.1100 - val_loss: 0.0931 - val_mae: 0.1189\n",
      "Epoch 2/250\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 0.1682 - mae: 0.1181 - val_loss: 0.0138 - val_mae: 0.0411\n",
      "Epoch 3/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.1112 - mae: 0.0834 - val_loss: 0.0067 - val_mae: 0.0263\n",
      "Epoch 4/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.1138 - mae: 0.0816 - val_loss: 0.0415 - val_mae: 0.0855\n",
      "Epoch 5/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.1304 - mae: 0.1064 - val_loss: 0.0096 - val_mae: 0.0321\n",
      "Epoch 6/250\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.1020 - mae: 0.0820 - val_loss: 0.0067 - val_mae: 0.0270\n",
      "Epoch 7/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.1024 - mae: 0.0813 - val_loss: 0.0067 - val_mae: 0.0268\n",
      "Epoch 8/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0973 - mae: 0.0804 - val_loss: 0.0059 - val_mae: 0.0258\n",
      "Epoch 9/250\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.0783 - mae: 0.0776 - val_loss: 0.0390 - val_mae: 0.0832\n",
      "Epoch 10/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0966 - mae: 0.0847 - val_loss: 0.0088 - val_mae: 0.0307\n",
      "Epoch 11/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.1074 - mae: 0.0831 - val_loss: 0.0079 - val_mae: 0.0291\n",
      "Epoch 12/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0918 - mae: 0.0801 - val_loss: 0.0068 - val_mae: 0.0266\n",
      "Epoch 13/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0732 - mae: 0.0777 - val_loss: 0.0285 - val_mae: 0.0686\n",
      "Epoch 14/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.1179 - mae: 0.0868 - val_loss: 0.0067 - val_mae: 0.0265\n",
      "Epoch 15/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0851 - mae: 0.0813 - val_loss: 0.0058 - val_mae: 0.0263\n",
      "Epoch 16/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0703 - mae: 0.0763 - val_loss: 0.0333 - val_mae: 0.0759\n",
      "Epoch 17/250\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.1012 - mae: 0.0845 - val_loss: 0.0372 - val_mae: 0.0799\n",
      "Epoch 18/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.1041 - mae: 0.0865 - val_loss: 0.0053 - val_mae: 0.0247\n",
      "Epoch 19/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0742 - mae: 0.0772 - val_loss: 0.0083 - val_mae: 0.0298\n",
      "Epoch 20/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0893 - mae: 0.0809 - val_loss: 0.0055 - val_mae: 0.0257\n",
      "Epoch 21/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0661 - mae: 0.0763 - val_loss: 0.0123 - val_mae: 0.0383\n",
      "Epoch 22/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.1071 - mae: 0.0829 - val_loss: 0.0125 - val_mae: 0.0405\n",
      "Epoch 23/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.1021 - mae: 0.0830 - val_loss: 0.0147 - val_mae: 0.0457\n",
      "Epoch 24/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0622 - mae: 0.0762 - val_loss: 0.0625 - val_mae: 0.1082\n",
      "Epoch 25/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0719 - mae: 0.0776 - val_loss: 0.0137 - val_mae: 0.0427\n",
      "Epoch 26/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0580 - mae: 0.0733 - val_loss: 0.1435 - val_mae: 0.1683\n",
      "Epoch 27/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0985 - mae: 0.0917 - val_loss: 0.0189 - val_mae: 0.0526\n",
      "Epoch 28/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0613 - mae: 0.0719 - val_loss: 0.0273 - val_mae: 0.0672\n",
      "Epoch 29/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0754 - mae: 0.0787 - val_loss: 0.0478 - val_mae: 0.0933\n",
      "Epoch 30/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0582 - mae: 0.0744 - val_loss: 0.0056 - val_mae: 0.0252\n",
      "Epoch 31/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.1056 - mae: 0.0844 - val_loss: 0.0220 - val_mae: 0.0592\n",
      "Epoch 32/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0644 - mae: 0.0748 - val_loss: 0.0530 - val_mae: 0.0996\n",
      "Epoch 33/250\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.0588 - mae: 0.0726 - val_loss: 0.5830 - val_mae: 0.3436\n",
      "############### next fold => number 18 ########## \n",
      "Epoch 1/250\n",
      "4/4 [==============================] - 3s 188ms/step - loss: 0.1406 - mae: 0.1065 - val_loss: 0.1736 - val_mae: 0.1486\n",
      "Epoch 2/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.3207 - mae: 0.1923 - val_loss: 0.0161 - val_mae: 0.0557\n",
      "Epoch 3/250\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 0.1173 - mae: 0.0826 - val_loss: 0.0144 - val_mae: 0.0394\n",
      "Epoch 4/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0940 - mae: 0.0751 - val_loss: 0.0139 - val_mae: 0.0390\n",
      "Epoch 5/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0890 - mae: 0.0745 - val_loss: 0.0133 - val_mae: 0.0381\n",
      "Epoch 6/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0944 - mae: 0.0753 - val_loss: 0.0406 - val_mae: 0.0567\n",
      "Epoch 7/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.1069 - mae: 0.0760 - val_loss: 0.0272 - val_mae: 0.0419\n",
      "Epoch 8/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0917 - mae: 0.0758 - val_loss: 0.0304 - val_mae: 0.0448\n",
      "Epoch 9/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0984 - mae: 0.0756 - val_loss: 0.0127 - val_mae: 0.0377\n",
      "Epoch 10/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0879 - mae: 0.0740 - val_loss: 0.0419 - val_mae: 0.0584\n",
      "Epoch 11/250\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.1138 - mae: 0.0850 - val_loss: 0.0299 - val_mae: 0.0447\n",
      "Epoch 12/250\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 0.0854 - mae: 0.0734 - val_loss: 0.0623 - val_mae: 0.0782\n",
      "Epoch 13/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0957 - mae: 0.0783 - val_loss: 0.0644 - val_mae: 0.0799\n",
      "Epoch 14/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0854 - mae: 0.0750 - val_loss: 0.0116 - val_mae: 0.0406\n",
      "Epoch 15/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0874 - mae: 0.0753 - val_loss: 0.0460 - val_mae: 0.0626\n",
      "Epoch 16/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0889 - mae: 0.0798 - val_loss: 0.0115 - val_mae: 0.0398\n",
      "Epoch 17/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0802 - mae: 0.0815 - val_loss: 0.0116 - val_mae: 0.0399\n",
      "Epoch 18/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0928 - mae: 0.0756 - val_loss: 0.0131 - val_mae: 0.0377\n",
      "Epoch 19/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0952 - mae: 0.0744 - val_loss: 0.0137 - val_mae: 0.0387\n",
      "Epoch 20/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0862 - mae: 0.0727 - val_loss: 0.0143 - val_mae: 0.0422\n",
      "Epoch 21/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0926 - mae: 0.0865 - val_loss: 0.0126 - val_mae: 0.0367\n",
      "Epoch 22/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0829 - mae: 0.0737 - val_loss: 0.0119 - val_mae: 0.0412\n",
      "Epoch 23/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0769 - mae: 0.0772 - val_loss: 0.0331 - val_mae: 0.0483\n",
      "Epoch 24/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0910 - mae: 0.0803 - val_loss: 0.0166 - val_mae: 0.0398\n",
      "Epoch 25/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0673 - mae: 0.0723 - val_loss: 0.0305 - val_mae: 0.0450\n",
      "Epoch 26/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0795 - mae: 0.0719 - val_loss: 0.0399 - val_mae: 0.0563\n",
      "Epoch 27/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0776 - mae: 0.0728 - val_loss: 0.0127 - val_mae: 0.0430\n",
      "Epoch 28/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0660 - mae: 0.0730 - val_loss: 0.1000 - val_mae: 0.1060\n",
      "Epoch 29/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0709 - mae: 0.0758 - val_loss: 0.0177 - val_mae: 0.0571\n",
      "Epoch 30/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0992 - mae: 0.0839 - val_loss: 0.0263 - val_mae: 0.0441\n",
      "Epoch 31/250\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 0.0629 - mae: 0.0694 - val_loss: 0.0153 - val_mae: 0.0394\n",
      "############### next fold => number 19 ########## \n",
      "Epoch 1/250\n",
      "4/4 [==============================] - 3s 199ms/step - loss: 1.3398 - mae: 0.4022 - val_loss: 0.1002 - val_mae: 0.1095\n",
      "Epoch 2/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.1197 - mae: 0.0896 - val_loss: 0.0320 - val_mae: 0.0642\n",
      "Epoch 3/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0933 - mae: 0.0739 - val_loss: 0.0268 - val_mae: 0.0549\n",
      "Epoch 4/250\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 0.1039 - mae: 0.0757 - val_loss: 0.0395 - val_mae: 0.0576\n",
      "Epoch 5/250\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 0.1073 - mae: 0.0824 - val_loss: 0.0269 - val_mae: 0.0552\n",
      "Epoch 6/250\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.1098 - mae: 0.0799 - val_loss: 0.0267 - val_mae: 0.0548\n",
      "Epoch 7/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0990 - mae: 0.0749 - val_loss: 0.0528 - val_mae: 0.0744\n",
      "Epoch 8/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.1076 - mae: 0.0824 - val_loss: 0.0268 - val_mae: 0.0551\n",
      "Epoch 9/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0950 - mae: 0.0733 - val_loss: 0.0269 - val_mae: 0.0553\n",
      "Epoch 10/250\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.1009 - mae: 0.0742 - val_loss: 0.0525 - val_mae: 0.0735\n",
      "Epoch 11/250\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 0.1044 - mae: 0.0776 - val_loss: 0.0274 - val_mae: 0.0564\n",
      "Epoch 12/250\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 0.0837 - mae: 0.0733 - val_loss: 0.0528 - val_mae: 0.0743\n",
      "Epoch 13/250\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.0951 - mae: 0.0779 - val_loss: 0.0268 - val_mae: 0.0554\n",
      "Epoch 14/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0877 - mae: 0.0729 - val_loss: 0.0399 - val_mae: 0.0593\n",
      "Epoch 15/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0938 - mae: 0.0819 - val_loss: 0.1333 - val_mae: 0.1279\n",
      "Epoch 16/250\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.1253 - mae: 0.1027 - val_loss: 0.0726 - val_mae: 0.0915\n",
      "Epoch 17/250\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 0.0896 - mae: 0.0775 - val_loss: 0.0430 - val_mae: 0.0652\n",
      "Epoch 18/250\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.0860 - mae: 0.0748 - val_loss: 0.0270 - val_mae: 0.0558\n",
      "Epoch 19/250\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 0.0922 - mae: 0.0739 - val_loss: 0.0293 - val_mae: 0.0603\n",
      "Epoch 20/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0913 - mae: 0.0737 - val_loss: 0.0262 - val_mae: 0.0540\n",
      "Epoch 21/250\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 0.0965 - mae: 0.0748 - val_loss: 0.0271 - val_mae: 0.0565\n",
      "Epoch 22/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.1365 - mae: 0.0998 - val_loss: 0.1094 - val_mae: 0.1375\n",
      "Epoch 23/250\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.0991 - mae: 0.0913 - val_loss: 0.0955 - val_mae: 0.1082\n",
      "Epoch 24/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.1081 - mae: 0.0898 - val_loss: 0.0274 - val_mae: 0.0566\n",
      "Epoch 25/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0862 - mae: 0.0729 - val_loss: 0.0689 - val_mae: 0.0887\n",
      "Epoch 26/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.1204 - mae: 0.0855 - val_loss: 0.0270 - val_mae: 0.0560\n",
      "Epoch 27/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0722 - mae: 0.0697 - val_loss: 0.0688 - val_mae: 0.0894\n",
      "Epoch 28/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0858 - mae: 0.0783 - val_loss: 0.0147 - val_mae: 0.0514\n",
      "Epoch 29/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0632 - mae: 0.0755 - val_loss: 0.0314 - val_mae: 0.0618\n",
      "Epoch 30/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0815 - mae: 0.0694 - val_loss: 0.0300 - val_mae: 0.0559\n",
      "Epoch 31/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0772 - mae: 0.0777 - val_loss: 0.0365 - val_mae: 0.0672\n",
      "Epoch 32/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0888 - mae: 0.0747 - val_loss: 0.1026 - val_mae: 0.1143\n",
      "Epoch 33/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.1408 - mae: 0.1046 - val_loss: 1.2941 - val_mae: 0.4411\n",
      "Epoch 34/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.4331 - mae: 0.1822 - val_loss: 0.0233 - val_mae: 0.0507\n",
      "Epoch 35/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0788 - mae: 0.0696 - val_loss: 0.0236 - val_mae: 0.0543\n",
      "Epoch 36/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0709 - mae: 0.0705 - val_loss: 0.0428 - val_mae: 0.0799\n",
      "Epoch 37/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0921 - mae: 0.0801 - val_loss: 0.0310 - val_mae: 0.0558\n",
      "Epoch 38/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0777 - mae: 0.0708 - val_loss: 0.0167 - val_mae: 0.0519\n",
      "Epoch 39/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0596 - mae: 0.0674 - val_loss: 0.0176 - val_mae: 0.0517\n",
      "Epoch 40/250\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.0737 - mae: 0.0765 - val_loss: 0.0256 - val_mae: 0.0545\n",
      "Epoch 41/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0846 - mae: 0.0728 - val_loss: 0.1779 - val_mae: 0.1527\n",
      "Epoch 42/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.1651 - mae: 0.1021 - val_loss: 0.0277 - val_mae: 0.0573\n",
      "Epoch 43/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0927 - mae: 0.0721 - val_loss: 0.0328 - val_mae: 0.0579\n",
      "############### next fold => number 20 ########## \n",
      "Epoch 1/250\n",
      "4/4 [==============================] - 5s 556ms/step - loss: 0.8439 - mae: 0.2443 - val_loss: 0.0480 - val_mae: 0.0710\n",
      "Epoch 2/250\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 0.0995 - mae: 0.0815 - val_loss: 0.0212 - val_mae: 0.0458\n",
      "Epoch 3/250\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.1115 - mae: 0.0777 - val_loss: 0.0232 - val_mae: 0.0478\n",
      "Epoch 4/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.1083 - mae: 0.0783 - val_loss: 0.0278 - val_mae: 0.0520\n",
      "Epoch 5/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.1104 - mae: 0.0759 - val_loss: 0.0421 - val_mae: 0.0649\n",
      "Epoch 6/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.1107 - mae: 0.0835 - val_loss: 0.0292 - val_mae: 0.0533\n",
      "Epoch 7/250\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 0.0911 - mae: 0.0751 - val_loss: 0.0199 - val_mae: 0.0458\n",
      "Epoch 8/250\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 0.0994 - mae: 0.0768 - val_loss: 0.0197 - val_mae: 0.0452\n",
      "Epoch 9/250\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.0884 - mae: 0.0746 - val_loss: 0.0459 - val_mae: 0.0842\n",
      "Epoch 10/250\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.1395 - mae: 0.1004 - val_loss: 0.0193 - val_mae: 0.0448\n",
      "Epoch 11/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.1093 - mae: 0.0756 - val_loss: 0.0252 - val_mae: 0.0491\n",
      "Epoch 12/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.1063 - mae: 0.0780 - val_loss: 0.0973 - val_mae: 0.1228\n",
      "Epoch 13/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.1387 - mae: 0.1014 - val_loss: 0.0206 - val_mae: 0.0453\n",
      "Epoch 14/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.1027 - mae: 0.0734 - val_loss: 0.0197 - val_mae: 0.0454\n",
      "Epoch 15/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.1022 - mae: 0.0758 - val_loss: 0.0216 - val_mae: 0.0463\n",
      "Epoch 16/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0805 - mae: 0.0727 - val_loss: 0.0210 - val_mae: 0.0457\n",
      "Epoch 17/250\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.0914 - mae: 0.0751 - val_loss: 0.0209 - val_mae: 0.0456\n",
      "Epoch 18/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0834 - mae: 0.0733 - val_loss: 0.0218 - val_mae: 0.0465\n",
      "Epoch 19/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0854 - mae: 0.0735 - val_loss: 0.0233 - val_mae: 0.0549\n",
      "Epoch 20/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0843 - mae: 0.0753 - val_loss: 0.0191 - val_mae: 0.0448\n",
      "Epoch 21/250\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.0772 - mae: 0.0725 - val_loss: 0.0233 - val_mae: 0.0472\n",
      "Epoch 22/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0779 - mae: 0.0710 - val_loss: 0.0275 - val_mae: 0.0633\n",
      "Epoch 23/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0997 - mae: 0.0822 - val_loss: 0.0208 - val_mae: 0.0455\n",
      "Epoch 24/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0816 - mae: 0.0727 - val_loss: 0.0504 - val_mae: 0.0878\n",
      "Epoch 25/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.1218 - mae: 0.0884 - val_loss: 0.0259 - val_mae: 0.0500\n",
      "Epoch 26/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0863 - mae: 0.0707 - val_loss: 0.0200 - val_mae: 0.0447\n",
      "Epoch 27/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0854 - mae: 0.0703 - val_loss: 0.0196 - val_mae: 0.0460\n",
      "Epoch 28/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0828 - mae: 0.0715 - val_loss: 0.0189 - val_mae: 0.0462\n",
      "Epoch 29/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0811 - mae: 0.0742 - val_loss: 0.0204 - val_mae: 0.0450\n",
      "Epoch 30/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0702 - mae: 0.0711 - val_loss: 0.0205 - val_mae: 0.0483\n",
      "Epoch 31/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0818 - mae: 0.0757 - val_loss: 0.0211 - val_mae: 0.0458\n",
      "Epoch 32/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0863 - mae: 0.0736 - val_loss: 0.0240 - val_mae: 0.0483\n",
      "Epoch 33/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0643 - mae: 0.0713 - val_loss: 0.0204 - val_mae: 0.0452\n",
      "Epoch 34/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.1047 - mae: 0.0811 - val_loss: 0.0257 - val_mae: 0.0497\n",
      "Epoch 35/250\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 0.0611 - mae: 0.0691 - val_loss: 0.0222 - val_mae: 0.0468\n",
      "Epoch 36/250\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.0568 - mae: 0.0653 - val_loss: 0.0507 - val_mae: 0.0856\n",
      "Epoch 37/250\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.1202 - mae: 0.0961 - val_loss: 0.0234 - val_mae: 0.0478\n",
      "Epoch 38/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.1108 - mae: 0.0809 - val_loss: 0.0208 - val_mae: 0.0455\n",
      "Epoch 39/250\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.0689 - mae: 0.0692 - val_loss: 0.0216 - val_mae: 0.0463\n",
      "Epoch 40/250\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 0.0639 - mae: 0.0680 - val_loss: 0.0190 - val_mae: 0.0445\n",
      "Epoch 41/250\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.0675 - mae: 0.0665 - val_loss: 0.0600 - val_mae: 0.0891\n",
      "Epoch 42/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0922 - mae: 0.0823 - val_loss: 0.0229 - val_mae: 0.0477\n",
      "Epoch 43/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0653 - mae: 0.0733 - val_loss: 0.0208 - val_mae: 0.0455\n",
      "############### next fold => number 21 ########## \n",
      "Epoch 1/250\n",
      "4/4 [==============================] - 3s 191ms/step - loss: 0.1909 - mae: 0.1572 - val_loss: 0.0097 - val_mae: 0.0504\n",
      "Epoch 2/250\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.1152 - mae: 0.0763 - val_loss: 0.0449 - val_mae: 0.0602\n",
      "Epoch 3/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.1151 - mae: 0.0758 - val_loss: 0.0511 - val_mae: 0.0643\n",
      "Epoch 4/250\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 0.1124 - mae: 0.0764 - val_loss: 0.0473 - val_mae: 0.0617\n",
      "Epoch 5/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.1127 - mae: 0.0756 - val_loss: 0.0422 - val_mae: 0.0581\n",
      "Epoch 6/250\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.1142 - mae: 0.0751 - val_loss: 0.0118 - val_mae: 0.0560\n",
      "Epoch 7/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.1009 - mae: 0.0745 - val_loss: 0.0112 - val_mae: 0.0545\n",
      "Epoch 8/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.1068 - mae: 0.0747 - val_loss: 0.0112 - val_mae: 0.0545\n",
      "Epoch 9/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.1104 - mae: 0.0748 - val_loss: 0.0112 - val_mae: 0.0546\n",
      "Epoch 10/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.1008 - mae: 0.0740 - val_loss: 0.0422 - val_mae: 0.0582\n",
      "Epoch 11/250\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 0.0978 - mae: 0.0746 - val_loss: 0.0458 - val_mae: 0.0607\n",
      "Epoch 12/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.1112 - mae: 0.0750 - val_loss: 0.0452 - val_mae: 0.0603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.1157 - mae: 0.0751 - val_loss: 0.0118 - val_mae: 0.0560\n",
      "Epoch 14/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.1033 - mae: 0.0744 - val_loss: 0.0465 - val_mae: 0.0612\n",
      "Epoch 15/250\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.1109 - mae: 0.0752 - val_loss: 0.0118 - val_mae: 0.0562\n",
      "Epoch 16/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.1068 - mae: 0.0750 - val_loss: 0.0406 - val_mae: 0.0569\n",
      "############### next fold => number 22 ########## \n",
      "Epoch 1/250\n",
      "4/4 [==============================] - 3s 189ms/step - loss: 0.3110 - mae: 0.2113 - val_loss: 0.0529 - val_mae: 0.0735\n",
      "Epoch 2/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0175 - mae: 0.0463 - val_loss: 0.0127 - val_mae: 0.0557\n",
      "Epoch 3/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0234 - mae: 0.0522 - val_loss: 0.0108 - val_mae: 0.0500\n",
      "Epoch 4/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0198 - mae: 0.0502 - val_loss: 0.0142 - val_mae: 0.0592\n",
      "Epoch 5/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0181 - mae: 0.0477 - val_loss: 0.0703 - val_mae: 0.0809\n",
      "Epoch 6/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0233 - mae: 0.0506 - val_loss: 0.0166 - val_mae: 0.0642\n",
      "Epoch 7/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0188 - mae: 0.0485 - val_loss: 0.0588 - val_mae: 0.0749\n",
      "Epoch 8/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0237 - mae: 0.0507 - val_loss: 0.0140 - val_mae: 0.0590\n",
      "Epoch 9/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0184 - mae: 0.0487 - val_loss: 0.0148 - val_mae: 0.0609\n",
      "Epoch 10/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0181 - mae: 0.0475 - val_loss: 0.0183 - val_mae: 0.0677\n",
      "Epoch 11/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0186 - mae: 0.0475 - val_loss: 0.0834 - val_mae: 0.0885\n",
      "Epoch 12/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0277 - mae: 0.0541 - val_loss: 0.0160 - val_mae: 0.0635\n",
      "Epoch 13/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0188 - mae: 0.0483 - val_loss: 0.0137 - val_mae: 0.0583\n",
      "Epoch 14/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0182 - mae: 0.0477 - val_loss: 0.0117 - val_mae: 0.0525\n",
      "Epoch 15/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0186 - mae: 0.0490 - val_loss: 0.0148 - val_mae: 0.0609\n",
      "Epoch 16/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0179 - mae: 0.0477 - val_loss: 0.0138 - val_mae: 0.0584\n",
      "Epoch 17/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0185 - mae: 0.0483 - val_loss: 0.0142 - val_mae: 0.0593\n",
      "Epoch 18/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0181 - mae: 0.0476 - val_loss: 0.0170 - val_mae: 0.0654\n",
      "############### next fold => number 23 ########## \n",
      "Epoch 1/250\n",
      "4/4 [==============================] - 3s 191ms/step - loss: 0.0619 - mae: 0.0935 - val_loss: 0.0396 - val_mae: 0.0890\n",
      "Epoch 2/250\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.0603 - mae: 0.0896 - val_loss: 0.1293 - val_mae: 0.1071\n",
      "Epoch 3/250\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0247 - mae: 0.0532 - val_loss: 0.0565 - val_mae: 0.1035\n",
      "Epoch 4/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0197 - mae: 0.0516 - val_loss: 0.0534 - val_mae: 0.1012\n",
      "Epoch 5/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0192 - mae: 0.0508 - val_loss: 0.0510 - val_mae: 0.0995\n",
      "Epoch 6/250\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.0188 - mae: 0.0504 - val_loss: 0.0485 - val_mae: 0.0976\n",
      "Epoch 7/250\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 0.0185 - mae: 0.0504 - val_loss: 0.0486 - val_mae: 0.0977\n",
      "Epoch 8/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0183 - mae: 0.0504 - val_loss: 0.0465 - val_mae: 0.0961\n",
      "Epoch 9/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0183 - mae: 0.0506 - val_loss: 0.0465 - val_mae: 0.0961\n",
      "Epoch 10/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0186 - mae: 0.0508 - val_loss: 0.0477 - val_mae: 0.0970\n",
      "Epoch 11/250\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.0182 - mae: 0.0503 - val_loss: 0.0451 - val_mae: 0.0950\n",
      "Epoch 12/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0181 - mae: 0.0508 - val_loss: 0.0450 - val_mae: 0.0950\n",
      "Epoch 13/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0177 - mae: 0.0508 - val_loss: 0.0446 - val_mae: 0.0946\n",
      "Epoch 14/250\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 0.0187 - mae: 0.0512 - val_loss: 0.0457 - val_mae: 0.0955\n",
      "Epoch 15/250\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.0184 - mae: 0.0508 - val_loss: 0.0473 - val_mae: 0.0967\n",
      "Epoch 16/250\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 0.0183 - mae: 0.0505 - val_loss: 0.0435 - val_mae: 0.0937\n",
      "############### next fold => number 24 ########## \n",
      "Epoch 1/250\n"
     ]
    }
   ],
   "source": [
    "l1_rnn = 0.01653480436240602\n",
    "l2_rnn = 0.0792386474\n",
    "\n",
    "plot_predictions_models_all_folds(X_train_list, Y_train_list, X_test_list, Y_test_list, RnnDlModel_test(L1 = l1_rnn, L2 = l2_rnn, epochs = 250, patience = 15))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92986eca",
   "metadata": {},
   "source": [
    "### Exporting and viewing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "414f3285",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T12:51:22.103251Z",
     "start_time": "2022-03-09T12:51:21.964537Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>fold_score</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>min_score</th>\n",
       "      <th>max_score</th>\n",
       "      <th>hyperparams</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.06422, 0.08158, 0.10233, 0.10397, 0.0928, 0...</td>\n",
       "      <td>0.08007</td>\n",
       "      <td>0.03786</td>\n",
       "      <td>0.11896</td>\n",
       "      <td>{'alpha': 15, 'l1_ratio': 0.0001}</td>\n",
       "      <td>09-03 12:29:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>RNN</td>\n",
       "      <td>[0.08021, 0.07414, 0.15304, 0.09484, 0.09262, ...</td>\n",
       "      <td>0.08496</td>\n",
       "      <td>0.04367</td>\n",
       "      <td>0.15304</td>\n",
       "      <td>{'L1': 0.09621870580119067, 'L2': 0.0459439662...</td>\n",
       "      <td>09-03 13:50:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>RNN</td>\n",
       "      <td>[0.25442, 0.06626, 0.10818, 0.12145, 0.09141, ...</td>\n",
       "      <td>0.09662</td>\n",
       "      <td>0.04369</td>\n",
       "      <td>0.25442</td>\n",
       "      <td>{'L1': 0.057297844739236325, 'L2': 0.021727812...</td>\n",
       "      <td>09-03 13:16:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Dummy</td>\n",
       "      <td>[0.06752, 0.08603, 0.11788, 0.13216, 0.14218, ...</td>\n",
       "      <td>0.11057</td>\n",
       "      <td>0.05455</td>\n",
       "      <td>0.19172</td>\n",
       "      <td>NaN</td>\n",
       "      <td>09-03 12:29:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>RNN</td>\n",
       "      <td>[0.14024, 0.06254, 0.10764, 0.08193, 0.24885, ...</td>\n",
       "      <td>0.13397</td>\n",
       "      <td>0.05175</td>\n",
       "      <td>0.50838</td>\n",
       "      <td>{'L1': 0.014348080048301116, 'L2': 0.075800478...</td>\n",
       "      <td>09-03 12:58:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.13612, 0.21353, 0.30214, 0.10699, 0.19859, ...</td>\n",
       "      <td>0.16727</td>\n",
       "      <td>0.04825</td>\n",
       "      <td>0.48190</td>\n",
       "      <td>{'alpha': 0.0146728420498667, 'l1_ratio': 0.002}</td>\n",
       "      <td>09-03 12:24:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.13771, 0.21647, 0.30717, 0.10733, 0.20077, ...</td>\n",
       "      <td>0.16939</td>\n",
       "      <td>0.04850</td>\n",
       "      <td>0.48631</td>\n",
       "      <td>{'alpha': 0.013972992093995074, 'l1_ratio': 0....</td>\n",
       "      <td>09-03 12:29:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.13809, 0.21718, 0.30844, 0.1074, 0.20131, 0...</td>\n",
       "      <td>0.16991</td>\n",
       "      <td>0.04856</td>\n",
       "      <td>0.48734</td>\n",
       "      <td>{'alpha': 0.013810108835731945, 'l1_ratio': 0....</td>\n",
       "      <td>09-03 12:29:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.14206, 0.22432, 0.32162, 0.10804, 0.20692, ...</td>\n",
       "      <td>0.17525</td>\n",
       "      <td>0.04917</td>\n",
       "      <td>0.49749</td>\n",
       "      <td>{'alpha': 0.012252161010179409, 'l1_ratio': 0....</td>\n",
       "      <td>09-03 12:24:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.14258, 0.22526, 0.32338, 0.10813, 0.20769, ...</td>\n",
       "      <td>0.17597</td>\n",
       "      <td>0.04925</td>\n",
       "      <td>0.49874</td>\n",
       "      <td>{'alpha': 0.012059999245888445, 'l1_ratio': 0....</td>\n",
       "      <td>09-03 12:24:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.14356, 0.22703, 0.32675, 0.10832, 0.20915, ...</td>\n",
       "      <td>0.17733</td>\n",
       "      <td>0.04941</td>\n",
       "      <td>0.50100</td>\n",
       "      <td>{'alpha': 0.01170332493514783, 'l1_ratio': 0.002}</td>\n",
       "      <td>09-03 12:24:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.14811, 0.23535, 0.34311, 0.10916, 0.21625, ...</td>\n",
       "      <td>0.18392</td>\n",
       "      <td>0.05007</td>\n",
       "      <td>0.51092</td>\n",
       "      <td>{'alpha': 0.010140964989512247, 'l1_ratio': 0....</td>\n",
       "      <td>09-03 12:24:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.1485, 0.23608, 0.34458, 0.10923, 0.21689, 0...</td>\n",
       "      <td>0.18452</td>\n",
       "      <td>0.05011</td>\n",
       "      <td>0.51173</td>\n",
       "      <td>{'alpha': 0.010013047738125233, 'l1_ratio': 0....</td>\n",
       "      <td>09-03 12:29:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.15123, 0.24124, 0.35522, 0.10981, 0.2216, 0...</td>\n",
       "      <td>0.18882</td>\n",
       "      <td>0.05061</td>\n",
       "      <td>0.51755</td>\n",
       "      <td>{'alpha': 0.009142003140607055, 'l1_ratio': 0....</td>\n",
       "      <td>09-03 12:24:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.15154, 0.24184, 0.3565, 0.10987, 0.22217, 0...</td>\n",
       "      <td>0.18933</td>\n",
       "      <td>0.05067</td>\n",
       "      <td>0.51826</td>\n",
       "      <td>{'alpha': 0.009043506240694247, 'l1_ratio': 0....</td>\n",
       "      <td>09-03 12:24:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.15219, 0.24308, 0.35915, 0.10999, 0.22336, ...</td>\n",
       "      <td>0.19040</td>\n",
       "      <td>0.05080</td>\n",
       "      <td>0.51970</td>\n",
       "      <td>{'alpha': 0.008843020133923246, 'l1_ratio': 0....</td>\n",
       "      <td>09-03 12:24:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.15304, 0.24473, 0.36273, 0.11016, 0.225, 0....</td>\n",
       "      <td>0.19182</td>\n",
       "      <td>0.05098</td>\n",
       "      <td>0.52122</td>\n",
       "      <td>{'alpha': 0.008580482228539502, 'l1_ratio': 0....</td>\n",
       "      <td>09-03 12:24:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.15322, 0.24509, 0.3635, 0.1102, 0.22536, 0....</td>\n",
       "      <td>0.19213</td>\n",
       "      <td>0.05102</td>\n",
       "      <td>0.52150</td>\n",
       "      <td>{'alpha': 0.008525114957592832, 'l1_ratio': 0....</td>\n",
       "      <td>09-03 12:29:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.15433, 0.24688, 0.36744, 0.1104, 0.22718, 0...</td>\n",
       "      <td>0.19370</td>\n",
       "      <td>0.05122</td>\n",
       "      <td>0.52283</td>\n",
       "      <td>{'alpha': 0.00824865504516143, 'l1_ratio': 0.002}</td>\n",
       "      <td>09-03 12:24:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.15546, 0.2487, 0.37153, 0.11062, 0.22909, 0...</td>\n",
       "      <td>0.19534</td>\n",
       "      <td>0.05142</td>\n",
       "      <td>0.52461</td>\n",
       "      <td>{'alpha': 0.007972187852829327, 'l1_ratio': 0....</td>\n",
       "      <td>09-03 12:29:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.15629, 0.25013, 0.37476, 0.11079, 0.23062, ...</td>\n",
       "      <td>0.19664</td>\n",
       "      <td>0.05159</td>\n",
       "      <td>0.52597</td>\n",
       "      <td>{'alpha': 0.007761189375655681, 'l1_ratio': 0....</td>\n",
       "      <td>09-03 12:24:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.15643, 0.25039, 0.37538, 0.11083, 0.23091, ...</td>\n",
       "      <td>0.19689</td>\n",
       "      <td>0.05162</td>\n",
       "      <td>0.52622</td>\n",
       "      <td>{'alpha': 0.007721708673987133, 'l1_ratio': 0....</td>\n",
       "      <td>09-03 12:29:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.15746, 0.25253, 0.38032, 0.11109, 0.23331, ...</td>\n",
       "      <td>0.19889</td>\n",
       "      <td>0.05187</td>\n",
       "      <td>0.52818</td>\n",
       "      <td>{'alpha': 0.007412780959755382, 'l1_ratio': 0....</td>\n",
       "      <td>09-03 12:29:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.15875, 0.25477, 0.38564, 0.11137, 0.23592, ...</td>\n",
       "      <td>0.20103</td>\n",
       "      <td>0.05215</td>\n",
       "      <td>0.53013</td>\n",
       "      <td>{'alpha': 0.007095865090499115, 'l1_ratio': 0....</td>\n",
       "      <td>09-03 12:24:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.1602, 0.25723, 0.39163, 0.11171, 0.23892, 0...</td>\n",
       "      <td>0.20345</td>\n",
       "      <td>0.05246</td>\n",
       "      <td>0.53214</td>\n",
       "      <td>{'alpha': 0.006757087937199803, 'l1_ratio': 0....</td>\n",
       "      <td>09-03 12:24:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.16138, 0.26, 0.39859, 0.11209, 0.24247, 0.3...</td>\n",
       "      <td>0.20624</td>\n",
       "      <td>0.05283</td>\n",
       "      <td>0.53421</td>\n",
       "      <td>{'alpha': 0.006386120174330504, 'l1_ratio': 0....</td>\n",
       "      <td>09-03 12:29:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.1615, 0.26027, 0.39929, 0.11213, 0.24283, 0...</td>\n",
       "      <td>0.20652</td>\n",
       "      <td>0.05287</td>\n",
       "      <td>0.53441</td>\n",
       "      <td>{'alpha': 0.006350125620749983, 'l1_ratio': 0....</td>\n",
       "      <td>09-03 12:29:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.16197, 0.26144, 0.40232, 0.11229, 0.24441, ...</td>\n",
       "      <td>0.20774</td>\n",
       "      <td>0.05303</td>\n",
       "      <td>0.53521</td>\n",
       "      <td>{'alpha': 0.006196262213498094, 'l1_ratio': 0....</td>\n",
       "      <td>09-03 12:24:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.16269, 0.2633, 0.40722, 0.11255, 0.24699, 0...</td>\n",
       "      <td>0.20971</td>\n",
       "      <td>0.05329</td>\n",
       "      <td>0.53641</td>\n",
       "      <td>{'alpha': 0.005956299408837825, 'l1_ratio': 0....</td>\n",
       "      <td>09-03 12:24:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.1644, 0.26967, 0.4212, 0.11325, 0.25466, 0....</td>\n",
       "      <td>0.21532</td>\n",
       "      <td>0.05402</td>\n",
       "      <td>0.53910</td>\n",
       "      <td>{'alpha': 0.005326520491586842, 'l1_ratio': 0....</td>\n",
       "      <td>09-03 12:29:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.16589, 0.27603, 0.44034, 0.11413, 0.26599, ...</td>\n",
       "      <td>0.22293</td>\n",
       "      <td>0.05514</td>\n",
       "      <td>0.54160</td>\n",
       "      <td>{'alpha': 0.004575045885497732, 'l1_ratio': 0....</td>\n",
       "      <td>09-03 12:29:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.1662, 0.28163, 0.45969, 0.11494, 0.27859, 0...</td>\n",
       "      <td>0.23059</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>0.54284</td>\n",
       "      <td>{'alpha': 0.003921567122926205, 'l1_ratio': 0....</td>\n",
       "      <td>09-03 12:24:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.16614, 0.28238, 0.46256, 0.11504, 0.28055, ...</td>\n",
       "      <td>0.23173</td>\n",
       "      <td>0.05638</td>\n",
       "      <td>0.54275</td>\n",
       "      <td>{'alpha': 0.0038331083901101564, 'l1_ratio': 0...</td>\n",
       "      <td>09-03 12:29:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.16549, 0.28577, 0.47637, 0.11552, 0.29048, ...</td>\n",
       "      <td>0.23723</td>\n",
       "      <td>0.05713</td>\n",
       "      <td>0.54099</td>\n",
       "      <td>{'alpha': 0.0034329476668071954, 'l1_ratio': 0...</td>\n",
       "      <td>09-03 12:24:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.16541, 0.28666, 0.48029, 0.11566, 0.29345, ...</td>\n",
       "      <td>0.23878</td>\n",
       "      <td>0.05732</td>\n",
       "      <td>0.54026</td>\n",
       "      <td>{'alpha': 0.003326744477208967, 'l1_ratio': 0....</td>\n",
       "      <td>09-03 12:29:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.16178, 0.29209, 0.50732, 0.11644, 0.31503, ...</td>\n",
       "      <td>0.24929</td>\n",
       "      <td>0.05875</td>\n",
       "      <td>0.53287</td>\n",
       "      <td>{'alpha': 0.0026855647112063973, 'l1_ratio': 0...</td>\n",
       "      <td>09-03 12:29:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>RNN</td>\n",
       "      <td>[0.0689, 0.07123, 0.11638, 0.20017, 0.19916, 0...</td>\n",
       "      <td>0.25531</td>\n",
       "      <td>0.05985</td>\n",
       "      <td>3.30555</td>\n",
       "      <td>{'L1': 0.023731675537587336, 'L2': 0.034759771...</td>\n",
       "      <td>09-03 13:08:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.15803, 0.29463, 0.52338, 0.11676, 0.33012, ...</td>\n",
       "      <td>0.25567</td>\n",
       "      <td>0.05959</td>\n",
       "      <td>0.52613</td>\n",
       "      <td>{'alpha': 0.002352189152994055, 'l1_ratio': 0....</td>\n",
       "      <td>09-03 12:29:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.1574, 0.295, 0.5258, 0.11679, 0.33256, 0.41...</td>\n",
       "      <td>0.25665</td>\n",
       "      <td>0.05971</td>\n",
       "      <td>0.52580</td>\n",
       "      <td>{'alpha': 0.0023051888612781123, 'l1_ratio': 0...</td>\n",
       "      <td>09-03 12:24:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.14706, 0.29882, 0.55603, 0.11743, 0.3653, 0...</td>\n",
       "      <td>0.26908</td>\n",
       "      <td>0.06119</td>\n",
       "      <td>0.55603</td>\n",
       "      <td>{'alpha': 0.0017797294733377272, 'l1_ratio': 0...</td>\n",
       "      <td>09-03 12:29:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.13635, 0.30063, 0.58061, 0.1174, 0.39709, 0...</td>\n",
       "      <td>0.27974</td>\n",
       "      <td>0.06233</td>\n",
       "      <td>0.58061</td>\n",
       "      <td>{'alpha': 0.0014239662159368826, 'l1_ratio': 0...</td>\n",
       "      <td>09-03 12:29:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.13527, 0.30075, 0.58291, 0.11737, 0.40026, ...</td>\n",
       "      <td>0.28071</td>\n",
       "      <td>0.06244</td>\n",
       "      <td>0.58291</td>\n",
       "      <td>{'alpha': 0.001393919451913494, 'l1_ratio': 0....</td>\n",
       "      <td>09-03 12:29:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.12487, 0.30148, 0.60465, 0.11738, 0.43215, ...</td>\n",
       "      <td>0.29027</td>\n",
       "      <td>0.06332</td>\n",
       "      <td>0.60465</td>\n",
       "      <td>{'alpha': 0.0011298541481733742, 'l1_ratio': 0...</td>\n",
       "      <td>09-03 12:29:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.12322, 0.30157, 0.60788, 0.11747, 0.43719, ...</td>\n",
       "      <td>0.29172</td>\n",
       "      <td>0.06344</td>\n",
       "      <td>0.60788</td>\n",
       "      <td>{'alpha': 0.0010936509814599787, 'l1_ratio': 0...</td>\n",
       "      <td>09-03 12:29:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.09834, 0.29143, 0.70277, 0.11837, 0.62478, ...</td>\n",
       "      <td>0.36053</td>\n",
       "      <td>0.06926</td>\n",
       "      <td>0.82106</td>\n",
       "      <td>{'alpha': 0.00026124357602507587, 'l1_ratio': ...</td>\n",
       "      <td>09-03 12:24:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.1916, 0.28887, 0.79484, 0.24018, 0.55197, 0...</td>\n",
       "      <td>0.64564</td>\n",
       "      <td>0.09470</td>\n",
       "      <td>2.74110</td>\n",
       "      <td>{'alpha': 4.734703522749628e-06, 'l1_ratio': 0...</td>\n",
       "      <td>09-03 12:24:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>RNN</td>\n",
       "      <td>[0.13022, 0.13787, 0.33697, 0.17142, 0.09978, ...</td>\n",
       "      <td>16.67472</td>\n",
       "      <td>0.05134</td>\n",
       "      <td>529.02793</td>\n",
       "      <td>{'L1': 0.03261277975872569, 'L2': 0.0899236359...</td>\n",
       "      <td>09-03 13:04:14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         name                                         fold_score  mean_score  \\\n",
       "20  LinearReg  [0.06422, 0.08158, 0.10233, 0.10397, 0.0928, 0...     0.08007   \n",
       "46        RNN  [0.08021, 0.07414, 0.15304, 0.09484, 0.09262, ...     0.08496   \n",
       "45        RNN  [0.25442, 0.06626, 0.10818, 0.12145, 0.09141, ...     0.09662   \n",
       "21      Dummy  [0.06752, 0.08603, 0.11788, 0.13216, 0.14218, ...     0.11057   \n",
       "42        RNN  [0.14024, 0.06254, 0.10764, 0.08193, 0.24885, ...     0.13397   \n",
       "10  LinearReg  [0.13612, 0.21353, 0.30214, 0.10699, 0.19859, ...     0.16727   \n",
       "38  LinearReg  [0.13771, 0.21647, 0.30717, 0.10733, 0.20077, ...     0.16939   \n",
       "25  LinearReg  [0.13809, 0.21718, 0.30844, 0.1074, 0.20131, 0...     0.16991   \n",
       "17  LinearReg  [0.14206, 0.22432, 0.32162, 0.10804, 0.20692, ...     0.17525   \n",
       "11  LinearReg  [0.14258, 0.22526, 0.32338, 0.10813, 0.20769, ...     0.17597   \n",
       "14  LinearReg  [0.14356, 0.22703, 0.32675, 0.10832, 0.20915, ...     0.17733   \n",
       "7   LinearReg  [0.14811, 0.23535, 0.34311, 0.10916, 0.21625, ...     0.18392   \n",
       "22  LinearReg  [0.1485, 0.23608, 0.34458, 0.10923, 0.21689, 0...     0.18452   \n",
       "18  LinearReg  [0.15123, 0.24124, 0.35522, 0.10981, 0.2216, 0...     0.18882   \n",
       "6   LinearReg  [0.15154, 0.24184, 0.3565, 0.10987, 0.22217, 0...     0.18933   \n",
       "4   LinearReg  [0.15219, 0.24308, 0.35915, 0.10999, 0.22336, ...     0.19040   \n",
       "5   LinearReg  [0.15304, 0.24473, 0.36273, 0.11016, 0.225, 0....     0.19182   \n",
       "35  LinearReg  [0.15322, 0.24509, 0.3635, 0.1102, 0.22536, 0....     0.19213   \n",
       "16  LinearReg  [0.15433, 0.24688, 0.36744, 0.1104, 0.22718, 0...     0.19370   \n",
       "36  LinearReg  [0.15546, 0.2487, 0.37153, 0.11062, 0.22909, 0...     0.19534   \n",
       "15  LinearReg  [0.15629, 0.25013, 0.37476, 0.11079, 0.23062, ...     0.19664   \n",
       "37  LinearReg  [0.15643, 0.25039, 0.37538, 0.11083, 0.23091, ...     0.19689   \n",
       "33  LinearReg  [0.15746, 0.25253, 0.38032, 0.11109, 0.23331, ...     0.19889   \n",
       "2   LinearReg  [0.15875, 0.25477, 0.38564, 0.11137, 0.23592, ...     0.20103   \n",
       "12  LinearReg  [0.1602, 0.25723, 0.39163, 0.11171, 0.23892, 0...     0.20345   \n",
       "31  LinearReg  [0.16138, 0.26, 0.39859, 0.11209, 0.24247, 0.3...     0.20624   \n",
       "32  LinearReg  [0.1615, 0.26027, 0.39929, 0.11213, 0.24283, 0...     0.20652   \n",
       "3   LinearReg  [0.16197, 0.26144, 0.40232, 0.11229, 0.24441, ...     0.20774   \n",
       "0   LinearReg  [0.16269, 0.2633, 0.40722, 0.11255, 0.24699, 0...     0.20971   \n",
       "23  LinearReg  [0.1644, 0.26967, 0.4212, 0.11325, 0.25466, 0....     0.21532   \n",
       "26  LinearReg  [0.16589, 0.27603, 0.44034, 0.11413, 0.26599, ...     0.22293   \n",
       "8   LinearReg  [0.1662, 0.28163, 0.45969, 0.11494, 0.27859, 0...     0.23059   \n",
       "29  LinearReg  [0.16614, 0.28238, 0.46256, 0.11504, 0.28055, ...     0.23173   \n",
       "13  LinearReg  [0.16549, 0.28577, 0.47637, 0.11552, 0.29048, ...     0.23723   \n",
       "27  LinearReg  [0.16541, 0.28666, 0.48029, 0.11566, 0.29345, ...     0.23878   \n",
       "30  LinearReg  [0.16178, 0.29209, 0.50732, 0.11644, 0.31503, ...     0.24929   \n",
       "44        RNN  [0.0689, 0.07123, 0.11638, 0.20017, 0.19916, 0...     0.25531   \n",
       "28  LinearReg  [0.15803, 0.29463, 0.52338, 0.11676, 0.33012, ...     0.25567   \n",
       "1   LinearReg  [0.1574, 0.295, 0.5258, 0.11679, 0.33256, 0.41...     0.25665   \n",
       "24  LinearReg  [0.14706, 0.29882, 0.55603, 0.11743, 0.3653, 0...     0.26908   \n",
       "41  LinearReg  [0.13635, 0.30063, 0.58061, 0.1174, 0.39709, 0...     0.27974   \n",
       "39  LinearReg  [0.13527, 0.30075, 0.58291, 0.11737, 0.40026, ...     0.28071   \n",
       "34  LinearReg  [0.12487, 0.30148, 0.60465, 0.11738, 0.43215, ...     0.29027   \n",
       "40  LinearReg  [0.12322, 0.30157, 0.60788, 0.11747, 0.43719, ...     0.29172   \n",
       "9   LinearReg  [0.09834, 0.29143, 0.70277, 0.11837, 0.62478, ...     0.36053   \n",
       "19  LinearReg  [0.1916, 0.28887, 0.79484, 0.24018, 0.55197, 0...     0.64564   \n",
       "43        RNN  [0.13022, 0.13787, 0.33697, 0.17142, 0.09978, ...    16.67472   \n",
       "\n",
       "    min_score  max_score                                        hyperparams  \\\n",
       "20    0.03786    0.11896                  {'alpha': 15, 'l1_ratio': 0.0001}   \n",
       "46    0.04367    0.15304  {'L1': 0.09621870580119067, 'L2': 0.0459439662...   \n",
       "45    0.04369    0.25442  {'L1': 0.057297844739236325, 'L2': 0.021727812...   \n",
       "21    0.05455    0.19172                                                NaN   \n",
       "42    0.05175    0.50838  {'L1': 0.014348080048301116, 'L2': 0.075800478...   \n",
       "10    0.04825    0.48190   {'alpha': 0.0146728420498667, 'l1_ratio': 0.002}   \n",
       "38    0.04850    0.48631  {'alpha': 0.013972992093995074, 'l1_ratio': 0....   \n",
       "25    0.04856    0.48734  {'alpha': 0.013810108835731945, 'l1_ratio': 0....   \n",
       "17    0.04917    0.49749  {'alpha': 0.012252161010179409, 'l1_ratio': 0....   \n",
       "11    0.04925    0.49874  {'alpha': 0.012059999245888445, 'l1_ratio': 0....   \n",
       "14    0.04941    0.50100  {'alpha': 0.01170332493514783, 'l1_ratio': 0.002}   \n",
       "7     0.05007    0.51092  {'alpha': 0.010140964989512247, 'l1_ratio': 0....   \n",
       "22    0.05011    0.51173  {'alpha': 0.010013047738125233, 'l1_ratio': 0....   \n",
       "18    0.05061    0.51755  {'alpha': 0.009142003140607055, 'l1_ratio': 0....   \n",
       "6     0.05067    0.51826  {'alpha': 0.009043506240694247, 'l1_ratio': 0....   \n",
       "4     0.05080    0.51970  {'alpha': 0.008843020133923246, 'l1_ratio': 0....   \n",
       "5     0.05098    0.52122  {'alpha': 0.008580482228539502, 'l1_ratio': 0....   \n",
       "35    0.05102    0.52150  {'alpha': 0.008525114957592832, 'l1_ratio': 0....   \n",
       "16    0.05122    0.52283  {'alpha': 0.00824865504516143, 'l1_ratio': 0.002}   \n",
       "36    0.05142    0.52461  {'alpha': 0.007972187852829327, 'l1_ratio': 0....   \n",
       "15    0.05159    0.52597  {'alpha': 0.007761189375655681, 'l1_ratio': 0....   \n",
       "37    0.05162    0.52622  {'alpha': 0.007721708673987133, 'l1_ratio': 0....   \n",
       "33    0.05187    0.52818  {'alpha': 0.007412780959755382, 'l1_ratio': 0....   \n",
       "2     0.05215    0.53013  {'alpha': 0.007095865090499115, 'l1_ratio': 0....   \n",
       "12    0.05246    0.53214  {'alpha': 0.006757087937199803, 'l1_ratio': 0....   \n",
       "31    0.05283    0.53421  {'alpha': 0.006386120174330504, 'l1_ratio': 0....   \n",
       "32    0.05287    0.53441  {'alpha': 0.006350125620749983, 'l1_ratio': 0....   \n",
       "3     0.05303    0.53521  {'alpha': 0.006196262213498094, 'l1_ratio': 0....   \n",
       "0     0.05329    0.53641  {'alpha': 0.005956299408837825, 'l1_ratio': 0....   \n",
       "23    0.05402    0.53910  {'alpha': 0.005326520491586842, 'l1_ratio': 0....   \n",
       "26    0.05514    0.54160  {'alpha': 0.004575045885497732, 'l1_ratio': 0....   \n",
       "8     0.05623    0.54284  {'alpha': 0.003921567122926205, 'l1_ratio': 0....   \n",
       "29    0.05638    0.54275  {'alpha': 0.0038331083901101564, 'l1_ratio': 0...   \n",
       "13    0.05713    0.54099  {'alpha': 0.0034329476668071954, 'l1_ratio': 0...   \n",
       "27    0.05732    0.54026  {'alpha': 0.003326744477208967, 'l1_ratio': 0....   \n",
       "30    0.05875    0.53287  {'alpha': 0.0026855647112063973, 'l1_ratio': 0...   \n",
       "44    0.05985    3.30555  {'L1': 0.023731675537587336, 'L2': 0.034759771...   \n",
       "28    0.05959    0.52613  {'alpha': 0.002352189152994055, 'l1_ratio': 0....   \n",
       "1     0.05971    0.52580  {'alpha': 0.0023051888612781123, 'l1_ratio': 0...   \n",
       "24    0.06119    0.55603  {'alpha': 0.0017797294733377272, 'l1_ratio': 0...   \n",
       "41    0.06233    0.58061  {'alpha': 0.0014239662159368826, 'l1_ratio': 0...   \n",
       "39    0.06244    0.58291  {'alpha': 0.001393919451913494, 'l1_ratio': 0....   \n",
       "34    0.06332    0.60465  {'alpha': 0.0011298541481733742, 'l1_ratio': 0...   \n",
       "40    0.06344    0.60788  {'alpha': 0.0010936509814599787, 'l1_ratio': 0...   \n",
       "9     0.06926    0.82106  {'alpha': 0.00026124357602507587, 'l1_ratio': ...   \n",
       "19    0.09470    2.74110  {'alpha': 4.734703522749628e-06, 'l1_ratio': 0...   \n",
       "43    0.05134  529.02793  {'L1': 0.03261277975872569, 'L2': 0.0899236359...   \n",
       "\n",
       "              date  \n",
       "20  09-03 12:29:18  \n",
       "46  09-03 13:50:07  \n",
       "45  09-03 13:16:23  \n",
       "21  09-03 12:29:22  \n",
       "42  09-03 12:58:59  \n",
       "10  09-03 12:24:17  \n",
       "38  09-03 12:29:47  \n",
       "25  09-03 12:29:33  \n",
       "17  09-03 12:24:24  \n",
       "11  09-03 12:24:18  \n",
       "14  09-03 12:24:21  \n",
       "7   09-03 12:24:13  \n",
       "22  09-03 12:29:30  \n",
       "18  09-03 12:24:25  \n",
       "6   09-03 12:24:12  \n",
       "4   09-03 12:24:10  \n",
       "5   09-03 12:24:11  \n",
       "35  09-03 12:29:44  \n",
       "16  09-03 12:24:23  \n",
       "36  09-03 12:29:45  \n",
       "15  09-03 12:24:22  \n",
       "37  09-03 12:29:46  \n",
       "33  09-03 12:29:41  \n",
       "2   09-03 12:24:08  \n",
       "12  09-03 12:24:19  \n",
       "31  09-03 12:29:39  \n",
       "32  09-03 12:29:40  \n",
       "3   09-03 12:24:09  \n",
       "0   09-03 12:24:06  \n",
       "23  09-03 12:29:31  \n",
       "26  09-03 12:29:34  \n",
       "8   09-03 12:24:14  \n",
       "29  09-03 12:29:37  \n",
       "13  09-03 12:24:20  \n",
       "27  09-03 12:29:35  \n",
       "30  09-03 12:29:38  \n",
       "44  09-03 13:08:24  \n",
       "28  09-03 12:29:36  \n",
       "1   09-03 12:24:07  \n",
       "24  09-03 12:29:32  \n",
       "41  09-03 12:29:51  \n",
       "39  09-03 12:29:48  \n",
       "34  09-03 12:29:43  \n",
       "40  09-03 12:29:50  \n",
       "9   09-03 12:24:16  \n",
       "19  09-03 12:24:28  \n",
       "43  09-03 13:04:14  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result = read_result()\n",
    "df_result = df_result.sort_values(by=\"mean_score\", ascending = True)\n",
    "df_result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "262.102px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
