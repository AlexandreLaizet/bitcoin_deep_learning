{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "86a7b326",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T10:20:38.601435Z",
     "start_time": "2022-03-10T10:20:27.408185Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import requests \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys; sys.path\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from datetime import datetime\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from bitcoin_deep_learning.call_api import ApiCall\n",
    "from bitcoin_deep_learning.model import LinearRegressionBaselineModel, RnnDlModel,RandomForestReg, DummyModel, RnnDlModel_test\n",
    "from bitcoin_deep_learning.trainer import cv_train, read_result\n",
    "from bitcoin_deep_learning.cross_val import cross_val, get_cross_XY, cross_val_trade\n",
    "from bitcoin_deep_learning.metrics import *\n",
    "api = ApiCall()\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67db4bac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T10:44:17.163064Z",
     "start_time": "2022-03-10T10:44:16.211055Z"
    }
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "train_df= ApiCall().read_local()\n",
    "for i in range(1,len(list(train_df.columns))-1):\n",
    "    train_df[list(train_df.columns)[i]] = scaler.fit_transform(np.array(train_df[train_df.columns[1]]).reshape(-1, 1))\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab32b96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T10:30:29.239356Z",
     "start_time": "2022-03-10T10:30:14.646435Z"
    }
   },
   "outputs": [],
   "source": [
    "model = RandomForestReg()\n",
    "cv_train(model,train_df)\n",
    "read_result().sort_values(by=\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1050ccf2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T11:44:34.629111Z",
     "start_time": "2022-03-10T11:44:34.606586Z"
    }
   },
   "outputs": [],
   "source": [
    "\"yolo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ef4a70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T11:18:40.522116Z",
     "start_time": "2022-03-10T11:01:30.760235Z"
    }
   },
   "outputs": [],
   "source": [
    "for n_estimators in [100,500,700,1000,1500,3000]:\n",
    "    for warm_start in  [True,False]:\n",
    "        for bootstrap in [True,False]:\n",
    "            for criterion in [\"squared_error\", \"absolute_error\", \"poisson\"]:\n",
    "                for min_samples_leaf in [1,5,10,20]:\n",
    "                    model = RandomForestReg(warm_start=warm_start,\n",
    "                                            n_estimators=n_estimators,\n",
    "                                           bootstrap=bootstrap,\n",
    "                                           criterion=criterion,\n",
    "                                           min_samples_leaf=min_samples_leaf)\n",
    "\n",
    "                    cv_train(model,train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3616cc2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T10:27:39.434122Z",
     "start_time": "2022-03-10T10:27:39.434082Z"
    }
   },
   "outputs": [],
   "source": [
    "X0 = [[i+5,-2*i]for i in range(1001)]\n",
    "X1 = np.sin(np.arange(1001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638826b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T16:59:21.879685Z",
     "start_time": "2022-03-09T16:59:21.742616Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(X0)\n",
    "df[\"date\"] = X1\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be498d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T16:59:23.604949Z",
     "start_time": "2022-03-09T16:59:22.410190Z"
    }
   },
   "outputs": [],
   "source": [
    "model = LinearRegressionBaselineModel()\n",
    "#model = RnnDlModel(epochs=10,patience=2)\n",
    "past_reality, reality,reality_diff, prediction_diff = cross_val_trade(model,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661fbc00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T16:59:23.796539Z",
     "start_time": "2022-03-09T16:59:23.617223Z"
    }
   },
   "outputs": [],
   "source": [
    "past_reality[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a71cbc9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T16:59:24.300710Z",
     "start_time": "2022-03-09T16:59:23.806693Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(reality[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59aa718",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T16:59:25.305410Z",
     "start_time": "2022-03-09T16:59:24.977799Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(prediction_diff[0],c=\"r\")\n",
    "plt.plot(reality_diff[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f3a3d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T16:59:29.429191Z",
     "start_time": "2022-03-09T16:59:27.980345Z"
    }
   },
   "outputs": [],
   "source": [
    "model = LinearRegressionBaselineModel()\n",
    "#model = RnnDlModel(epochs=10,patience=2)\n",
    "past_reality, reality,reality_diff, prediction_diff = cross_val_trade(model,df)\n",
    "plt.plot(prediction_diff[0],c=\"r\")\n",
    "plt.plot(reality_diff[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3603a08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T16:52:39.686158Z",
     "start_time": "2022-03-09T16:52:39.543063Z"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cc3bed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T16:54:14.625068Z",
     "start_time": "2022-03-09T16:54:13.512900Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_list, Y_train_list, X_test_list,Y_test_list = get_cross_XY(df.drop(columns=\"date\"),data=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad51d86c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T16:54:14.762448Z",
     "start_time": "2022-03-09T16:54:14.632659Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, Y_train, X_test,Y_test = X_train_list[0], Y_train_list[0], X_test_list[0],Y_test_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b1c728",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T16:54:42.591675Z",
     "start_time": "2022-03-09T16:54:42.461813Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "scaler = StandardScaler()\n",
    "#X_train_scaled =  scaler.fit_transform(X_train[:,-1,:])\n",
    "#X_test_scaled = scaler.transform(X_test[:,-1,:])\n",
    "X_train_scaled =  (X_train[:,-1,:])\n",
    "X_test_scaled = (X_test[:,-1,:])\n",
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0e31f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T16:54:43.329373Z",
     "start_time": "2022-03-09T16:54:42.981451Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "model = ElasticNet()\n",
    "model.fit(X_train_scaled,Y_train)\n",
    "Y_pred = model.predict(X_test_scaled)\n",
    "plt.plot(Y_pred)\n",
    "plt.plot(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254814c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T16:54:15.529568Z",
     "start_time": "2022-03-09T16:54:15.350092Z"
    }
   },
   "outputs": [],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a73db8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T16:54:15.713904Z",
     "start_time": "2022-03-09T16:54:15.542868Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train[:,-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6298ed9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T15:39:33.674825Z",
     "start_time": "2022-03-09T15:39:33.537909Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train[:,-1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ca6d99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T14:54:05.248499Z",
     "start_time": "2022-03-09T14:54:05.021024Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0fa236",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T15:39:33.832071Z",
     "start_time": "2022-03-09T15:39:33.688143Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train[:,-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d98795d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T15:44:53.023640Z",
     "start_time": "2022-03-09T15:44:45.930468Z"
    }
   },
   "outputs": [],
   "source": [
    "model = LinearRegressionBaselineModel(alpha=0.1,l1_ratio=0.001)\n",
    "df = ApiCall().read_local()\n",
    "X_train_list, Y_train_list, X_test_list,Y_test_list = get_cross_XY(df,data=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffce926",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T15:45:07.391989Z",
     "start_time": "2022-03-09T15:44:58.984581Z"
    }
   },
   "outputs": [],
   "source": [
    "cross_val_trade(model,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454232ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T15:47:30.179538Z",
     "start_time": "2022-03-09T15:47:26.175042Z"
    }
   },
   "outputs": [],
   "source": [
    "past_reality, reality,reality_diff, prediction_diff = cross_val_trade(model,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5d9b8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T16:28:26.745583Z",
     "start_time": "2022-03-09T16:28:26.561663Z"
    }
   },
   "outputs": [],
   "source": [
    "ct = 0\n",
    "preds = []\n",
    "computed_reality = []\n",
    "for past_prices, diffs in zip(past_reality,prediction_diff):\n",
    "    preds.append(past_prices * diffs+ past_prices)\n",
    "preds  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcb48e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T17:03:14.025454Z",
     "start_time": "2022-03-09T17:03:13.903822Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a42f71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T17:03:05.746462Z",
     "start_time": "2022-03-09T17:03:05.610887Z"
    }
   },
   "outputs": [],
   "source": [
    "df = api.read_local()\n",
    "scaler = MinMaxScaler()\n",
    "#df  =scaler.fit_transform(df.drop(columns=\"date\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33afb8e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T17:05:18.570310Z",
     "start_time": "2022-03-09T17:05:18.439994Z"
    }
   },
   "outputs": [],
   "source": [
    "df[df.columns[1]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9652d735",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T17:05:55.466306Z",
     "start_time": "2022-03-09T17:05:55.336089Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8616a701",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T17:08:48.818805Z",
     "start_time": "2022-03-09T17:08:48.656506Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360c1fe3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T17:08:49.756169Z",
     "start_time": "2022-03-09T17:08:49.535475Z"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7fa4f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T17:14:27.791406Z",
     "start_time": "2022-03-09T17:14:23.473082Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df = api.read_local()\n",
    "scaler = MinMaxScaler()\n",
    "for i in range(1,len(list(df.columns))):\n",
    "    df[list(df.columns)[i]] = scaler.fit_transform(np.array(df[df.columns[1]]).reshape(-1, 1))\n",
    "\n",
    "model = LinearRegressionBaselineModel(alpha=0.5,l1_ratio=0.001)\n",
    "#model = RnnDlModel(epochs=10,patience=2)\n",
    "past_reality, reality,reality_diff, prediction_diff = cross_val_trade(model,df)\n",
    "for i in range(10):\n",
    "    plt.plot(prediction_diff[i],c=\"r\")\n",
    "    plt.plot(reality_diff[i])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3accc8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T17:14:28.010131Z",
     "start_time": "2022-03-09T17:14:27.798627Z"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8e1678",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T17:14:30.525658Z",
     "start_time": "2022-03-09T17:14:28.024636Z"
    }
   },
   "outputs": [],
   "source": [
    "fold_score, score= train(model,df)\n",
    "print(fold_score,score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613ccd8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T17:23:46.544656Z",
     "start_time": "2022-03-09T17:19:17.670903Z"
    }
   },
   "outputs": [],
   "source": [
    "for counter in range(20):\n",
    "    alpha = 0.015 * random.random()\n",
    "    l1 = random.random()*0.01\n",
    "    # Instanciate model\n",
    "    regression_model = LinearRegressionBaselineModel(alpha = alpha, l1_ratio = l1)\n",
    "    # Train and Fit data using the crossval\n",
    "    val_score, score = train(regression_model,df);\n",
    "    print(val_score,score)\n",
    "    past_reality, reality,reality_diff, prediction_diff = cross_val_trade(model,df)\n",
    "    for i in range(len(reality)):\n",
    "        plt.plot(prediction_diff[i],c=\"r\")\n",
    "        plt.plot(reality_diff[i])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99cef92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T17:23:46.730289Z",
     "start_time": "2022-03-09T17:23:46.561158Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from bitcoin_deep_learning.trainer import read_result\n",
    "read_result().sort_values(by=\"date\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a626c8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T17:52:26.052552Z",
     "start_time": "2022-03-09T17:36:07.704082Z"
    }
   },
   "outputs": [],
   "source": [
    "df = api.read_local()\n",
    "scaler = MinMaxScaler()\n",
    "for i in range(1,len(list(df.columns))-1):\n",
    "    df[list(df.columns)[i]] = scaler.fit_transform(np.array(df[df.columns[1]]).reshape(-1, 1))\n",
    "\n",
    "model = LinearRegressionBaselineModel(alpha=0.5,l1_ratio=0.001)\n",
    "#model = RnnDlModel(epochs=10,patience=2)\n",
    "past_reality, reality,reality_diff, prediction_diff = cross_val_trade(model,df)\n",
    "ALPHA = [0.001,0.005,0.01,0.1,5,1,10,100]\n",
    "L1 = [0.0001,0.0005,0.001,0.005,0.001,0.005,0.01,0.1,0.5,1]\n",
    "for alpha in ALPHA :\n",
    "    for l1 in L1 : \n",
    "        # Instanciate model\n",
    "        regression_model = LinearRegressionBaselineModel(alpha = alpha, l1_ratio = l1)\n",
    "        # Train and Fit data using the crossval\n",
    "        val_score, score = train(regression_model,df);\n",
    "        print(val_score,score)\n",
    "        past_reality, reality,reality_diff, prediction_diff = cross_val_trade(model,df)\n",
    "        for i in range(len(reality)):\n",
    "            plt.plot(prediction_diff[i],c=\"r\")\n",
    "            plt.plot(reality_diff[i])\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f11863",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T17:52:26.245981Z",
     "start_time": "2022-03-09T17:52:26.065419Z"
    }
   },
   "outputs": [],
   "source": [
    "read_result().sort_values(by=\"date\",ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8690ed32",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-03-09T18:31:31.901Z"
    }
   },
   "outputs": [],
   "source": [
    "df = api.read_local()\n",
    "scaler = MinMaxScaler()\n",
    "for i in range(1,len(list(df.columns))):\n",
    "    df[list(df.columns)[i]] = scaler.fit_transform(np.array(df[df.columns[1]]).reshape(-1, 1))\n",
    "\n",
    "model = LinearRegressionBaselineModel(alpha=0.5,l1_ratio=0.001)\n",
    "#model = RnnDlModel(epochs=10,patience=2)\n",
    "past_reality, reality,reality_diff, prediction_diff = cross_val_trade(model,df)\n",
    "ALPHA = [0.001,0.005,0.01,0.1,5,1,10,100]\n",
    "L1 = [0.0001,0.0005,0.001,0.005,0.001,0.005,0.01,0.1,0.5,1]\n",
    "for alpha in ALPHA :\n",
    "    for l1 in L1 : \n",
    "        # Instanciate model\n",
    "        regression_model = LinearRegressionBaselineModel(alpha = alpha, l1_ratio = l1)\n",
    "        # Train and Fit data using the crossval\n",
    "        val_score, score = train(regression_model,df);\n",
    "        print(val_score,score)\n",
    "        past_reality, reality,reality_diff, prediction_diff = cross_val_trade(model,df)\n",
    "        for i in range(len(reality)):\n",
    "            plt.plot(reality[i])\n",
    "            plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf83a68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T18:34:24.142241Z",
     "start_time": "2022-03-09T18:34:24.013993Z"
    }
   },
   "outputs": [],
   "source": [
    "x = np.eye(260,3,31)\n",
    "x.reshape(260,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06390c76",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T18:29:04.773254Z",
     "start_time": "2022-03-09T18:28:59.474360Z"
    }
   },
   "outputs": [],
   "source": [
    "read_result().sort_values(by=\"mean_score\",ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c1510c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T08:46:55.653991Z",
     "start_time": "2022-03-10T08:46:55.513440Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "def train(model,\n",
    "          df,\n",
    "          save:bool=True,\n",
    "          precision:int=5\n",
    "          ):\n",
    "    reality,prediction = cross_val(model,df)\n",
    "    fold_score = [round(mean_absolute_error(Y_true,Y_pred),precision)\n",
    "                            for Y_true,Y_pred in zip(reality,prediction)]\n",
    "    score =round(np.mean(np.array(fold_score)),precision)\n",
    "    # Option to save results\n",
    "    if save == True :\n",
    "        file_path = os.path.join(ROOT_DIR,\n",
    "                                        \"cross_val_data\",\n",
    "                                        'test.csv')\n",
    "        # Check if file is there and create it otherwise\n",
    "        if not os.path.isfile(file_path):\n",
    "            fieldnames = [\"name\",'fold_score',\"mean_score\",\"min_score\",\"max_score\",'hyperparams','date']\n",
    "            pd.DataFrame(columns=fieldnames).to_csv(file_path,index=False)\n",
    "        # Append a new line with current CV results\n",
    "        with open(file_path , 'a', newline='') as csvfile:\n",
    "            fieldnames = [\"name\",'fold_score',\"mean_score\",\"min_score\",\"max_score\",'hyperparams','date']\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "            writer.writerow({\"name\":model.name, \"fold_score\":fold_score,\n",
    "                            \"mean_score\":score,\"min_score\":min(fold_score),\n",
    "                            \"max_score\":max(fold_score),\n",
    "                            \"hyperparams\":model.hyperparams,\n",
    "                            'date':datetime.now().strftime(\"%d-%m %H:%M:%S\")})\n",
    "            print(\"Training done\")\n",
    "        return fold_score, score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be304499",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T08:46:56.167435Z",
     "start_time": "2022-03-10T08:46:56.011474Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = ApiCall().read_local()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c1e567",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T09:10:57.769630Z",
     "start_time": "2022-03-10T09:10:57.618451Z"
    }
   },
   "outputs": [],
   "source": [
    "read_result(file=\"CV_trader.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01e5590",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T08:47:34.381188Z",
     "start_time": "2022-03-10T08:47:30.526438Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "model = LinearRegressionBaselineModel()\n",
    "train(model,train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6afa5c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T09:14:33.839416Z",
     "start_time": "2022-03-10T09:14:33.690768Z"
    }
   },
   "outputs": [],
   "source": [
    "ROOT_DIR = \"/Users/Zalo/code/AlexandreLaizet/bitcoin_deep_learning\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d920d59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T09:15:44.039668Z",
     "start_time": "2022-03-10T09:15:43.881272Z"
    }
   },
   "outputs": [],
   "source": [
    "file_path = os.path.join(ROOT_DIR,\n",
    "                        \"cross_val_data\",\n",
    "                        'CV_trader.csv')\n",
    "fieldnames = [\"name\",'fold_score',\"mean_score\",\"min_score\",\"max_score\",'hyperparams','date',\n",
    "             \"roi_hodler\", \"sharpe_hodler\", \"roi_trader\", \"sharpe_trader\",\"roi_whale\", \"sharpe_whale\",\n",
    "              \"roi_hodler_whale\",  \"sharpe_hodler_whale\", \"roi_charles\", \n",
    "                \"sharpe_charles\"]\n",
    "pd.DataFrame(columns=fieldnames).to_csv(file_path,index=False)\n",
    "read_result(file=\"CV_trader.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a0a6ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T08:56:00.298685Z",
     "start_time": "2022-03-10T08:55:55.872938Z"
    }
   },
   "outputs": [],
   "source": [
    "from bitcoin_deep_learning.metrics import iterate_cross_val_results\n",
    "iterate_cross_val_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904352b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T08:58:25.380019Z",
     "start_time": "2022-03-10T08:58:20.477232Z"
    }
   },
   "outputs": [],
   "source": [
    "roi_hodler, roi_trader, roi_whale, roi_hodler_whale, roi_charles, sharpe_hodler, sharpe_trader, sharpe_whale, sharpe_hodler_whale, sharpe_charles = iterate_cross_val_results()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f8a684",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_path , 'a', newline='') as csvfile:\n",
    "            #fieldnames = [\"name\",'fold_score',\"mean_score\",\"min_score\",\"max_score\",'hyperparams','date']\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "            writer.writerow({\"name\":model.name, \"fold_score\":fold_score,\n",
    "                            \"mean_score\":score,\"min_score\":min(fold_score),\n",
    "                            \"max_score\":max(fold_score),\n",
    "                            \"hyperparams\":model.hyperparams,\n",
    "                            'date':datetime.now().strftime(\"%d-%m %H:%M:%S\"),\n",
    "                            \"roi_hodler\":roi_hodler\n",
    "                            \"sharpe_hodler\": sharpe_hodler\n",
    "                            \"roi_trader\": roi_trader\n",
    "                            \"sharpe_trader\": sharpe_trader\n",
    "                            \"roi_whale\": roi_whale\n",
    "                            \"sharpe_whale\": sharpe_whale\n",
    "                            \"roi_hodler_whale\": roi_hodler_whale\n",
    "                            \"sharpe_hodler_whale\": sharpe_hodler_whale\n",
    "                            \"roi_charles\": roi_charles\n",
    "                            \"sharpe_charles\":sharpe_charles})\n",
    "            print(\"Training done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c339f31b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T10:03:05.174992Z",
     "start_time": "2022-03-10T10:03:05.031502Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df= ApiCall().read_local()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf7529a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T10:03:32.173858Z",
     "start_time": "2022-03-10T10:03:31.982100Z"
    }
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "train_df= ApiCall().read_local()\n",
    "for i in range(1,len(list(train_df.columns))-1):\n",
    "    train_df[list(train_df.columns)[i]] = scaler.fit_transform(np.array(train_df[train_df.columns[1]]).reshape(-1, 1))\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf31bc7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T10:03:36.052997Z",
     "start_time": "2022-03-10T10:03:33.990322Z"
    }
   },
   "outputs": [],
   "source": [
    "for warm_start in  [True,False]:\n",
    "    for max_features in [\"auto\", \"sqrt\", \"log2\"]:\n",
    "        for bootstrap in [True,False]:\n",
    "            for criterion in [\"squared_error\", \"absolute_error\", \"poisson\"]:\n",
    "                    for max_depht in [None,True]:\n",
    "                        if max_depht :\n",
    "                            max_depht = np.random.randint(1,1000)\n",
    "                        print(\"oui\")\n",
    "                        min_samples_split = random.randint(2,100)\n",
    "                        min_samples_leaf = random.randint(2,100)\n",
    "                        model = RandomForestReg(warm_start=warm_start,\n",
    "                                               max_features=max_features,\n",
    "                                               bootstrap=bootstrap,\n",
    "                                               criterion=criterion,\n",
    "                                               max_depht=max_depht,\n",
    "                                               min_samples_split=min_samples_split,\n",
    "                                               min_samples_leaf=min_samples_leaf)\n",
    "\n",
    "                        cv_train(model,train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b16729",
   "metadata": {},
   "source": [
    "# Dummy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc2d49d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [00:02<00:00, 13.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.23901045179407965, 0.3477205291545489, 0.33400412784029365, 0.32553008918894033, -0.005360588130910227, -0.38389642791425205, -0.3141090385585297, -0.30868398804863684, -0.2126595928196786, -0.060139076467191965, 0.16689361278589554, -0.3036397556129774, -0.34790184987238437, 0.24942335583166275, 0.2076396206086819, 0.1080712096662022, 0.09101817200523654, 0.059394731120385735, 0.023539343735346607, 0.3021824268229776, 0.39415030197918854, 0.2890920102664558, 0.3651169244895911, 0.37344415648179985, 0.35332358768821837, -0.14638556686848347, -0.3547472325526173, -0.48224192315571035, 0.12942813901731598, 0.14667686299033966, 0.32234273596290053, 0.19428169383617955]\n",
      "Training with trader done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>fold_score</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>min_score</th>\n",
       "      <th>max_score</th>\n",
       "      <th>hyperparams</th>\n",
       "      <th>date</th>\n",
       "      <th>roi_hodler</th>\n",
       "      <th>sharpe_hodler</th>\n",
       "      <th>roi_trader</th>\n",
       "      <th>sharpe_trader</th>\n",
       "      <th>roi_whale</th>\n",
       "      <th>sharpe_whale</th>\n",
       "      <th>roi_hodler_whale</th>\n",
       "      <th>sharpe_hodler_whale</th>\n",
       "      <th>roi_charles</th>\n",
       "      <th>sharpe_charles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dummy</td>\n",
       "      <td>[0.06752, 0.08603, 0.11788, 0.13216, 0.14218, ...</td>\n",
       "      <td>0.11057</td>\n",
       "      <td>0.05455</td>\n",
       "      <td>0.19172</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10-03 15:53:23</td>\n",
       "      <td>0.076063</td>\n",
       "      <td>2.692379</td>\n",
       "      <td>0.053090</td>\n",
       "      <td>0.637716</td>\n",
       "      <td>0.055913</td>\n",
       "      <td>0.458252</td>\n",
       "      <td>0.056260</td>\n",
       "      <td>0.510347</td>\n",
       "      <td>0.065704</td>\n",
       "      <td>1.186462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.20636, 0.26691, 0.91792, 0.5793, 0.12272, 0...</td>\n",
       "      <td>0.62972</td>\n",
       "      <td>0.07553</td>\n",
       "      <td>2.95176</td>\n",
       "      <td>{'alpha': 0.05, 'l1_ratio': 0.0001}</td>\n",
       "      <td>10-03 15:50:33</td>\n",
       "      <td>0.076063</td>\n",
       "      <td>2.692379</td>\n",
       "      <td>0.034135</td>\n",
       "      <td>1.414102</td>\n",
       "      <td>0.025962</td>\n",
       "      <td>1.131473</td>\n",
       "      <td>0.044834</td>\n",
       "      <td>0.932677</td>\n",
       "      <td>0.054169</td>\n",
       "      <td>1.510994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.20636, 0.26691, 0.91792, 0.5793, 0.12272, 0...</td>\n",
       "      <td>0.62972</td>\n",
       "      <td>0.07553</td>\n",
       "      <td>2.95176</td>\n",
       "      <td>{'alpha': 0.05, 'l1_ratio': 0.0001}</td>\n",
       "      <td>10-03 15:45:20</td>\n",
       "      <td>0.076063</td>\n",
       "      <td>2.692379</td>\n",
       "      <td>0.034135</td>\n",
       "      <td>1.414102</td>\n",
       "      <td>0.025962</td>\n",
       "      <td>1.131473</td>\n",
       "      <td>0.044834</td>\n",
       "      <td>0.932677</td>\n",
       "      <td>0.054169</td>\n",
       "      <td>1.510994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.13652, 0.3541, 0.89001, 0.09658, 0.24001, 0...</td>\n",
       "      <td>0.39088</td>\n",
       "      <td>0.07920</td>\n",
       "      <td>1.68089</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.5}</td>\n",
       "      <td>10-03 15:42:00</td>\n",
       "      <td>0.076063</td>\n",
       "      <td>2.692379</td>\n",
       "      <td>0.004387</td>\n",
       "      <td>0.530331</td>\n",
       "      <td>-0.012604</td>\n",
       "      <td>-0.949174</td>\n",
       "      <td>-0.012604</td>\n",
       "      <td>-0.949174</td>\n",
       "      <td>0.023209</td>\n",
       "      <td>0.649548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.13652, 0.3541, 0.89001, 0.09658, 0.24001, 0...</td>\n",
       "      <td>0.39088</td>\n",
       "      <td>0.07920</td>\n",
       "      <td>1.68089</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.5}</td>\n",
       "      <td>10-03 15:41:40</td>\n",
       "      <td>0.076063</td>\n",
       "      <td>2.692379</td>\n",
       "      <td>0.004387</td>\n",
       "      <td>0.530331</td>\n",
       "      <td>-0.012604</td>\n",
       "      <td>-0.949174</td>\n",
       "      <td>-0.012604</td>\n",
       "      <td>-0.949174</td>\n",
       "      <td>0.023209</td>\n",
       "      <td>0.649548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.13652, 0.3541, 0.89001, 0.09658, 0.24001, 0...</td>\n",
       "      <td>0.39088</td>\n",
       "      <td>0.07920</td>\n",
       "      <td>1.68089</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.5}</td>\n",
       "      <td>10-03 15:40:06</td>\n",
       "      <td>0.076063</td>\n",
       "      <td>2.692379</td>\n",
       "      <td>0.004387</td>\n",
       "      <td>0.530331</td>\n",
       "      <td>-0.012604</td>\n",
       "      <td>-0.949174</td>\n",
       "      <td>-0.012604</td>\n",
       "      <td>-0.949174</td>\n",
       "      <td>0.023209</td>\n",
       "      <td>0.649548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.13652, 0.3541, 0.89001, 0.09658, 0.24001, 0...</td>\n",
       "      <td>0.39088</td>\n",
       "      <td>0.07920</td>\n",
       "      <td>1.68089</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.5}</td>\n",
       "      <td>10-03 15:39:42</td>\n",
       "      <td>0.076063</td>\n",
       "      <td>2.692379</td>\n",
       "      <td>0.004387</td>\n",
       "      <td>0.530331</td>\n",
       "      <td>-0.012604</td>\n",
       "      <td>-0.949174</td>\n",
       "      <td>-0.012604</td>\n",
       "      <td>-0.949174</td>\n",
       "      <td>0.023209</td>\n",
       "      <td>0.649548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestReg</td>\n",
       "      <td>[0.19037, 0.07132, 0.12205, 0.15436, 0.11077, ...</td>\n",
       "      <td>0.13984</td>\n",
       "      <td>0.04739</td>\n",
       "      <td>0.35404</td>\n",
       "      <td>None</td>\n",
       "      <td>10-03 13:12:35</td>\n",
       "      <td>0.076063</td>\n",
       "      <td>2.692379</td>\n",
       "      <td>-0.022602</td>\n",
       "      <td>-0.603253</td>\n",
       "      <td>-0.003665</td>\n",
       "      <td>-0.027767</td>\n",
       "      <td>-0.003665</td>\n",
       "      <td>-0.027767</td>\n",
       "      <td>0.064577</td>\n",
       "      <td>1.047856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestReg</td>\n",
       "      <td>[0.07313, 0.07909, 0.10424, 0.12256, 0.11114, ...</td>\n",
       "      <td>0.10006</td>\n",
       "      <td>0.06343</td>\n",
       "      <td>0.17766</td>\n",
       "      <td>None</td>\n",
       "      <td>10-03 12:08:28</td>\n",
       "      <td>0.076063</td>\n",
       "      <td>2.692379</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.099678</td>\n",
       "      <td>2.089733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.06979, 0.08286, 0.09448, 0.10667, 0.08963, ...</td>\n",
       "      <td>0.07873</td>\n",
       "      <td>0.03510</td>\n",
       "      <td>0.11721</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.5}</td>\n",
       "      <td>10-03 12:04:27</td>\n",
       "      <td>0.076063</td>\n",
       "      <td>2.692379</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.099678</td>\n",
       "      <td>2.089733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              name                                         fold_score  \\\n",
       "9            Dummy  [0.06752, 0.08603, 0.11788, 0.13216, 0.14218, ...   \n",
       "8        LinearReg  [0.20636, 0.26691, 0.91792, 0.5793, 0.12272, 0...   \n",
       "7        LinearReg  [0.20636, 0.26691, 0.91792, 0.5793, 0.12272, 0...   \n",
       "6        LinearReg  [0.13652, 0.3541, 0.89001, 0.09658, 0.24001, 0...   \n",
       "5        LinearReg  [0.13652, 0.3541, 0.89001, 0.09658, 0.24001, 0...   \n",
       "4        LinearReg  [0.13652, 0.3541, 0.89001, 0.09658, 0.24001, 0...   \n",
       "3        LinearReg  [0.13652, 0.3541, 0.89001, 0.09658, 0.24001, 0...   \n",
       "2  RandomForestReg  [0.19037, 0.07132, 0.12205, 0.15436, 0.11077, ...   \n",
       "1  RandomForestReg  [0.07313, 0.07909, 0.10424, 0.12256, 0.11114, ...   \n",
       "0        LinearReg  [0.06979, 0.08286, 0.09448, 0.10667, 0.08963, ...   \n",
       "\n",
       "   mean_score  min_score  max_score                          hyperparams  \\\n",
       "9     0.11057    0.05455    0.19172                                  NaN   \n",
       "8     0.62972    0.07553    2.95176  {'alpha': 0.05, 'l1_ratio': 0.0001}   \n",
       "7     0.62972    0.07553    2.95176  {'alpha': 0.05, 'l1_ratio': 0.0001}   \n",
       "6     0.39088    0.07920    1.68089        {'alpha': 1, 'l1_ratio': 0.5}   \n",
       "5     0.39088    0.07920    1.68089        {'alpha': 1, 'l1_ratio': 0.5}   \n",
       "4     0.39088    0.07920    1.68089        {'alpha': 1, 'l1_ratio': 0.5}   \n",
       "3     0.39088    0.07920    1.68089        {'alpha': 1, 'l1_ratio': 0.5}   \n",
       "2     0.13984    0.04739    0.35404                                 None   \n",
       "1     0.10006    0.06343    0.17766                                 None   \n",
       "0     0.07873    0.03510    0.11721        {'alpha': 1, 'l1_ratio': 0.5}   \n",
       "\n",
       "             date  roi_hodler  sharpe_hodler  roi_trader  sharpe_trader  \\\n",
       "9  10-03 15:53:23    0.076063       2.692379    0.053090       0.637716   \n",
       "8  10-03 15:50:33    0.076063       2.692379    0.034135       1.414102   \n",
       "7  10-03 15:45:20    0.076063       2.692379    0.034135       1.414102   \n",
       "6  10-03 15:42:00    0.076063       2.692379    0.004387       0.530331   \n",
       "5  10-03 15:41:40    0.076063       2.692379    0.004387       0.530331   \n",
       "4  10-03 15:40:06    0.076063       2.692379    0.004387       0.530331   \n",
       "3  10-03 15:39:42    0.076063       2.692379    0.004387       0.530331   \n",
       "2  10-03 13:12:35    0.076063       2.692379   -0.022602      -0.603253   \n",
       "1  10-03 12:08:28    0.076063       2.692379    0.000000       0.000000   \n",
       "0  10-03 12:04:27    0.076063       2.692379    0.000000       0.000000   \n",
       "\n",
       "   roi_whale  sharpe_whale  roi_hodler_whale  sharpe_hodler_whale  \\\n",
       "9   0.055913      0.458252          0.056260             0.510347   \n",
       "8   0.025962      1.131473          0.044834             0.932677   \n",
       "7   0.025962      1.131473          0.044834             0.932677   \n",
       "6  -0.012604     -0.949174         -0.012604            -0.949174   \n",
       "5  -0.012604     -0.949174         -0.012604            -0.949174   \n",
       "4  -0.012604     -0.949174         -0.012604            -0.949174   \n",
       "3  -0.012604     -0.949174         -0.012604            -0.949174   \n",
       "2  -0.003665     -0.027767         -0.003665            -0.027767   \n",
       "1   0.000000      0.000000          0.000000             0.000000   \n",
       "0   0.000000      0.000000          0.000000             0.000000   \n",
       "\n",
       "   roi_charles  sharpe_charles  \n",
       "9     0.065704        1.186462  \n",
       "8     0.054169        1.510994  \n",
       "7     0.054169        1.510994  \n",
       "6     0.023209        0.649548  \n",
       "5     0.023209        0.649548  \n",
       "4     0.023209        0.649548  \n",
       "3     0.023209        0.649548  \n",
       "2     0.064577        1.047856  \n",
       "1     0.099678        2.089733  \n",
       "0     0.099678        2.089733  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DummyModel()\n",
    "cv_train(model,ApiCall().read_local(data=\"train\"))\n",
    "read_result().sort_values(by=\"date\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21aa4bb",
   "metadata": {},
   "source": [
    "# Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cd23d26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T11:22:37.446679Z",
     "start_time": "2022-03-10T11:19:30.119973Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██████████████████████████▎                                                                                             | 7/32 [00:00<00:02,  9.35it/s]/Users/alexandrelaizet/.pyenv/versions/3.8.12/envs/bitcoin/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.588e-01, tolerance: 2.421e-04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      " 25%|██████████████████████████████                                                                                          | 8/32 [00:00<00:02,  8.97it/s]/Users/alexandrelaizet/.pyenv/versions/3.8.12/envs/bitcoin/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.542e-01, tolerance: 2.041e-04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      " 28%|█████████████████████████████████▊                                                                                      | 9/32 [00:00<00:02,  8.39it/s]/Users/alexandrelaizet/.pyenv/versions/3.8.12/envs/bitcoin/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.327e-01, tolerance: 2.361e-04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      " 31%|█████████████████████████████████████▏                                                                                 | 10/32 [00:01<00:02,  8.05it/s]/Users/alexandrelaizet/.pyenv/versions/3.8.12/envs/bitcoin/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.594e-01, tolerance: 2.550e-04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      " 69%|█████████████████████████████████████████████████████████████████████████████████▊                                     | 22/32 [00:02<00:01,  9.28it/s]/Users/alexandrelaizet/.pyenv/versions/3.8.12/envs/bitcoin/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.663e-01, tolerance: 4.180e-04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      " 78%|████████████████████████████████████████████████████████████████████████████████████████████▉                          | 25/32 [00:02<00:00,  8.70it/s]/Users/alexandrelaizet/.pyenv/versions/3.8.12/envs/bitcoin/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.060e-01, tolerance: 1.876e-04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      " 81%|████████████████████████████████████████████████████████████████████████████████████████████████▋                      | 26/32 [00:02<00:00,  8.01it/s]/Users/alexandrelaizet/.pyenv/versions/3.8.12/envs/bitcoin/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.161e-01, tolerance: 2.200e-04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      " 84%|████████████████████████████████████████████████████████████████████████████████████████████████████▍                  | 27/32 [00:03<00:00,  7.88it/s]/Users/alexandrelaizet/.pyenv/versions/3.8.12/envs/bitcoin/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.681e-01, tolerance: 2.269e-04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      " 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████▏              | 28/32 [00:03<00:00,  7.79it/s]/Users/alexandrelaizet/.pyenv/versions/3.8.12/envs/bitcoin/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.957e-01, tolerance: 2.707e-04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      " 91%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▊           | 29/32 [00:03<00:00,  7.45it/s]/Users/alexandrelaizet/.pyenv/versions/3.8.12/envs/bitcoin/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.600e-01, tolerance: 3.494e-04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      " 94%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▌       | 30/32 [00:03<00:00,  7.28it/s]/Users/alexandrelaizet/.pyenv/versions/3.8.12/envs/bitcoin/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.573e-01, tolerance: 3.760e-04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      " 97%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎   | 31/32 [00:03<00:00,  7.18it/s]/Users/alexandrelaizet/.pyenv/versions/3.8.12/envs/bitcoin/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.850e-01, tolerance: 3.928e-04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [00:03<00:00,  8.43it/s]\n",
      "/Users/alexandrelaizet/.pyenv/versions/3.8.12/envs/bitcoin/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.588e-01, tolerance: 2.421e-04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/alexandrelaizet/.pyenv/versions/3.8.12/envs/bitcoin/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.542e-01, tolerance: 2.041e-04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/alexandrelaizet/.pyenv/versions/3.8.12/envs/bitcoin/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.327e-01, tolerance: 2.361e-04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/alexandrelaizet/.pyenv/versions/3.8.12/envs/bitcoin/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.594e-01, tolerance: 2.550e-04\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexandrelaizet/.pyenv/versions/3.8.12/envs/bitcoin/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.663e-01, tolerance: 4.180e-04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/alexandrelaizet/.pyenv/versions/3.8.12/envs/bitcoin/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.060e-01, tolerance: 1.876e-04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/alexandrelaizet/.pyenv/versions/3.8.12/envs/bitcoin/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.161e-01, tolerance: 2.200e-04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/alexandrelaizet/.pyenv/versions/3.8.12/envs/bitcoin/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.681e-01, tolerance: 2.269e-04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/alexandrelaizet/.pyenv/versions/3.8.12/envs/bitcoin/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.957e-01, tolerance: 2.707e-04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/alexandrelaizet/.pyenv/versions/3.8.12/envs/bitcoin/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.600e-01, tolerance: 3.494e-04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/alexandrelaizet/.pyenv/versions/3.8.12/envs/bitcoin/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.573e-01, tolerance: 3.760e-04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/alexandrelaizet/.pyenv/versions/3.8.12/envs/bitcoin/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.850e-01, tolerance: 3.928e-04\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2172702355097862, 0.1773772102797484, 0.0, 0.1514171292931079, 0.1801592210272307, -0.2777363797714766, -0.29076824191104333, -0.1519077596832361, -0.12283953354687571, 0.0, 0.0, 0.025019800333978326, -0.3098439858605323, 0.025969350391875423, 0.0, 0.010580015231917095, 0.0, 0.10367793770043066, 0.0, 0.0, 0.0, 0.24950755221124288, 0.3816146715351807, 0.0, 0.38341082597163556, -0.07469147054300573, -0.24133489844179024, -0.38243218377026755, 0.20217003805619904, -0.053894493234533325, 0.3554664065473805, 0.18448470378028614]\n",
      "Training with trader done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>fold_score</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>min_score</th>\n",
       "      <th>max_score</th>\n",
       "      <th>hyperparams</th>\n",
       "      <th>date</th>\n",
       "      <th>roi_hodler</th>\n",
       "      <th>sharpe_hodler</th>\n",
       "      <th>roi_trader</th>\n",
       "      <th>sharpe_trader</th>\n",
       "      <th>roi_whale</th>\n",
       "      <th>sharpe_whale</th>\n",
       "      <th>roi_hodler_whale</th>\n",
       "      <th>sharpe_hodler_whale</th>\n",
       "      <th>roi_charles</th>\n",
       "      <th>sharpe_charles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.13652, 0.3541, 0.89001, 0.09658, 0.24001, 0...</td>\n",
       "      <td>0.39088</td>\n",
       "      <td>0.07920</td>\n",
       "      <td>1.68089</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.5}</td>\n",
       "      <td>10-03 15:54:12</td>\n",
       "      <td>0.076063</td>\n",
       "      <td>2.692379</td>\n",
       "      <td>0.004387</td>\n",
       "      <td>0.530331</td>\n",
       "      <td>-0.012604</td>\n",
       "      <td>-0.949174</td>\n",
       "      <td>-0.012604</td>\n",
       "      <td>-0.949174</td>\n",
       "      <td>0.023209</td>\n",
       "      <td>0.649548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dummy</td>\n",
       "      <td>[0.06752, 0.08603, 0.11788, 0.13216, 0.14218, ...</td>\n",
       "      <td>0.11057</td>\n",
       "      <td>0.05455</td>\n",
       "      <td>0.19172</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10-03 15:53:23</td>\n",
       "      <td>0.076063</td>\n",
       "      <td>2.692379</td>\n",
       "      <td>0.053090</td>\n",
       "      <td>0.637716</td>\n",
       "      <td>0.055913</td>\n",
       "      <td>0.458252</td>\n",
       "      <td>0.056260</td>\n",
       "      <td>0.510347</td>\n",
       "      <td>0.065704</td>\n",
       "      <td>1.186462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.20636, 0.26691, 0.91792, 0.5793, 0.12272, 0...</td>\n",
       "      <td>0.62972</td>\n",
       "      <td>0.07553</td>\n",
       "      <td>2.95176</td>\n",
       "      <td>{'alpha': 0.05, 'l1_ratio': 0.0001}</td>\n",
       "      <td>10-03 15:50:33</td>\n",
       "      <td>0.076063</td>\n",
       "      <td>2.692379</td>\n",
       "      <td>0.034135</td>\n",
       "      <td>1.414102</td>\n",
       "      <td>0.025962</td>\n",
       "      <td>1.131473</td>\n",
       "      <td>0.044834</td>\n",
       "      <td>0.932677</td>\n",
       "      <td>0.054169</td>\n",
       "      <td>1.510994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.20636, 0.26691, 0.91792, 0.5793, 0.12272, 0...</td>\n",
       "      <td>0.62972</td>\n",
       "      <td>0.07553</td>\n",
       "      <td>2.95176</td>\n",
       "      <td>{'alpha': 0.05, 'l1_ratio': 0.0001}</td>\n",
       "      <td>10-03 15:45:20</td>\n",
       "      <td>0.076063</td>\n",
       "      <td>2.692379</td>\n",
       "      <td>0.034135</td>\n",
       "      <td>1.414102</td>\n",
       "      <td>0.025962</td>\n",
       "      <td>1.131473</td>\n",
       "      <td>0.044834</td>\n",
       "      <td>0.932677</td>\n",
       "      <td>0.054169</td>\n",
       "      <td>1.510994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.13652, 0.3541, 0.89001, 0.09658, 0.24001, 0...</td>\n",
       "      <td>0.39088</td>\n",
       "      <td>0.07920</td>\n",
       "      <td>1.68089</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.5}</td>\n",
       "      <td>10-03 15:42:00</td>\n",
       "      <td>0.076063</td>\n",
       "      <td>2.692379</td>\n",
       "      <td>0.004387</td>\n",
       "      <td>0.530331</td>\n",
       "      <td>-0.012604</td>\n",
       "      <td>-0.949174</td>\n",
       "      <td>-0.012604</td>\n",
       "      <td>-0.949174</td>\n",
       "      <td>0.023209</td>\n",
       "      <td>0.649548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.13652, 0.3541, 0.89001, 0.09658, 0.24001, 0...</td>\n",
       "      <td>0.39088</td>\n",
       "      <td>0.07920</td>\n",
       "      <td>1.68089</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.5}</td>\n",
       "      <td>10-03 15:41:40</td>\n",
       "      <td>0.076063</td>\n",
       "      <td>2.692379</td>\n",
       "      <td>0.004387</td>\n",
       "      <td>0.530331</td>\n",
       "      <td>-0.012604</td>\n",
       "      <td>-0.949174</td>\n",
       "      <td>-0.012604</td>\n",
       "      <td>-0.949174</td>\n",
       "      <td>0.023209</td>\n",
       "      <td>0.649548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.13652, 0.3541, 0.89001, 0.09658, 0.24001, 0...</td>\n",
       "      <td>0.39088</td>\n",
       "      <td>0.07920</td>\n",
       "      <td>1.68089</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.5}</td>\n",
       "      <td>10-03 15:40:06</td>\n",
       "      <td>0.076063</td>\n",
       "      <td>2.692379</td>\n",
       "      <td>0.004387</td>\n",
       "      <td>0.530331</td>\n",
       "      <td>-0.012604</td>\n",
       "      <td>-0.949174</td>\n",
       "      <td>-0.012604</td>\n",
       "      <td>-0.949174</td>\n",
       "      <td>0.023209</td>\n",
       "      <td>0.649548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.13652, 0.3541, 0.89001, 0.09658, 0.24001, 0...</td>\n",
       "      <td>0.39088</td>\n",
       "      <td>0.07920</td>\n",
       "      <td>1.68089</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.5}</td>\n",
       "      <td>10-03 15:39:42</td>\n",
       "      <td>0.076063</td>\n",
       "      <td>2.692379</td>\n",
       "      <td>0.004387</td>\n",
       "      <td>0.530331</td>\n",
       "      <td>-0.012604</td>\n",
       "      <td>-0.949174</td>\n",
       "      <td>-0.012604</td>\n",
       "      <td>-0.949174</td>\n",
       "      <td>0.023209</td>\n",
       "      <td>0.649548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestReg</td>\n",
       "      <td>[0.19037, 0.07132, 0.12205, 0.15436, 0.11077, ...</td>\n",
       "      <td>0.13984</td>\n",
       "      <td>0.04739</td>\n",
       "      <td>0.35404</td>\n",
       "      <td>None</td>\n",
       "      <td>10-03 13:12:35</td>\n",
       "      <td>0.076063</td>\n",
       "      <td>2.692379</td>\n",
       "      <td>-0.022602</td>\n",
       "      <td>-0.603253</td>\n",
       "      <td>-0.003665</td>\n",
       "      <td>-0.027767</td>\n",
       "      <td>-0.003665</td>\n",
       "      <td>-0.027767</td>\n",
       "      <td>0.064577</td>\n",
       "      <td>1.047856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestReg</td>\n",
       "      <td>[0.07313, 0.07909, 0.10424, 0.12256, 0.11114, ...</td>\n",
       "      <td>0.10006</td>\n",
       "      <td>0.06343</td>\n",
       "      <td>0.17766</td>\n",
       "      <td>None</td>\n",
       "      <td>10-03 12:08:28</td>\n",
       "      <td>0.076063</td>\n",
       "      <td>2.692379</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.099678</td>\n",
       "      <td>2.089733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.06979, 0.08286, 0.09448, 0.10667, 0.08963, ...</td>\n",
       "      <td>0.07873</td>\n",
       "      <td>0.03510</td>\n",
       "      <td>0.11721</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.5}</td>\n",
       "      <td>10-03 12:04:27</td>\n",
       "      <td>0.076063</td>\n",
       "      <td>2.692379</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.099678</td>\n",
       "      <td>2.089733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               name                                         fold_score  \\\n",
       "10        LinearReg  [0.13652, 0.3541, 0.89001, 0.09658, 0.24001, 0...   \n",
       "9             Dummy  [0.06752, 0.08603, 0.11788, 0.13216, 0.14218, ...   \n",
       "8         LinearReg  [0.20636, 0.26691, 0.91792, 0.5793, 0.12272, 0...   \n",
       "7         LinearReg  [0.20636, 0.26691, 0.91792, 0.5793, 0.12272, 0...   \n",
       "6         LinearReg  [0.13652, 0.3541, 0.89001, 0.09658, 0.24001, 0...   \n",
       "5         LinearReg  [0.13652, 0.3541, 0.89001, 0.09658, 0.24001, 0...   \n",
       "4         LinearReg  [0.13652, 0.3541, 0.89001, 0.09658, 0.24001, 0...   \n",
       "3         LinearReg  [0.13652, 0.3541, 0.89001, 0.09658, 0.24001, 0...   \n",
       "2   RandomForestReg  [0.19037, 0.07132, 0.12205, 0.15436, 0.11077, ...   \n",
       "1   RandomForestReg  [0.07313, 0.07909, 0.10424, 0.12256, 0.11114, ...   \n",
       "0         LinearReg  [0.06979, 0.08286, 0.09448, 0.10667, 0.08963, ...   \n",
       "\n",
       "    mean_score  min_score  max_score                          hyperparams  \\\n",
       "10     0.39088    0.07920    1.68089        {'alpha': 1, 'l1_ratio': 0.5}   \n",
       "9      0.11057    0.05455    0.19172                                  NaN   \n",
       "8      0.62972    0.07553    2.95176  {'alpha': 0.05, 'l1_ratio': 0.0001}   \n",
       "7      0.62972    0.07553    2.95176  {'alpha': 0.05, 'l1_ratio': 0.0001}   \n",
       "6      0.39088    0.07920    1.68089        {'alpha': 1, 'l1_ratio': 0.5}   \n",
       "5      0.39088    0.07920    1.68089        {'alpha': 1, 'l1_ratio': 0.5}   \n",
       "4      0.39088    0.07920    1.68089        {'alpha': 1, 'l1_ratio': 0.5}   \n",
       "3      0.39088    0.07920    1.68089        {'alpha': 1, 'l1_ratio': 0.5}   \n",
       "2      0.13984    0.04739    0.35404                                 None   \n",
       "1      0.10006    0.06343    0.17766                                 None   \n",
       "0      0.07873    0.03510    0.11721        {'alpha': 1, 'l1_ratio': 0.5}   \n",
       "\n",
       "              date  roi_hodler  sharpe_hodler  roi_trader  sharpe_trader  \\\n",
       "10  10-03 15:54:12    0.076063       2.692379    0.004387       0.530331   \n",
       "9   10-03 15:53:23    0.076063       2.692379    0.053090       0.637716   \n",
       "8   10-03 15:50:33    0.076063       2.692379    0.034135       1.414102   \n",
       "7   10-03 15:45:20    0.076063       2.692379    0.034135       1.414102   \n",
       "6   10-03 15:42:00    0.076063       2.692379    0.004387       0.530331   \n",
       "5   10-03 15:41:40    0.076063       2.692379    0.004387       0.530331   \n",
       "4   10-03 15:40:06    0.076063       2.692379    0.004387       0.530331   \n",
       "3   10-03 15:39:42    0.076063       2.692379    0.004387       0.530331   \n",
       "2   10-03 13:12:35    0.076063       2.692379   -0.022602      -0.603253   \n",
       "1   10-03 12:08:28    0.076063       2.692379    0.000000       0.000000   \n",
       "0   10-03 12:04:27    0.076063       2.692379    0.000000       0.000000   \n",
       "\n",
       "    roi_whale  sharpe_whale  roi_hodler_whale  sharpe_hodler_whale  \\\n",
       "10  -0.012604     -0.949174         -0.012604            -0.949174   \n",
       "9    0.055913      0.458252          0.056260             0.510347   \n",
       "8    0.025962      1.131473          0.044834             0.932677   \n",
       "7    0.025962      1.131473          0.044834             0.932677   \n",
       "6   -0.012604     -0.949174         -0.012604            -0.949174   \n",
       "5   -0.012604     -0.949174         -0.012604            -0.949174   \n",
       "4   -0.012604     -0.949174         -0.012604            -0.949174   \n",
       "3   -0.012604     -0.949174         -0.012604            -0.949174   \n",
       "2   -0.003665     -0.027767         -0.003665            -0.027767   \n",
       "1    0.000000      0.000000          0.000000             0.000000   \n",
       "0    0.000000      0.000000          0.000000             0.000000   \n",
       "\n",
       "    roi_charles  sharpe_charles  \n",
       "10     0.023209        0.649548  \n",
       "9      0.065704        1.186462  \n",
       "8      0.054169        1.510994  \n",
       "7      0.054169        1.510994  \n",
       "6      0.023209        0.649548  \n",
       "5      0.023209        0.649548  \n",
       "4      0.023209        0.649548  \n",
       "3      0.023209        0.649548  \n",
       "2      0.064577        1.047856  \n",
       "1      0.099678        2.089733  \n",
       "0      0.099678        2.089733  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearRegressionBaselineModel()\n",
    "cv_train(model,ApiCall().read_local(data=\"train\"))\n",
    "read_result().sort_values(by=\"date\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b8b61e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T10:06:03.430091Z",
     "start_time": "2022-03-10T10:06:03.297699Z"
    }
   },
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9fbdfc66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [02:26<00:00,  4.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.39423765465400606, 0.0, 0.0, 0.14175623511513047, -0.2824240613868797, -0.3141090385585297, -0.24699767200798428, -0.022270976617830507, 0.03086579265353362, 0.1718204129251013, 0.025019800333978326, 0.13920950857719383, 0.31110708210274485, 0.0, 0.0031862182371953374, 0.0, 0.0, 0.0, 0.283302223859873, 0.0, 0.0, 0.0, 0.3000199366901142, 0.38341082597163556, -0.14638556686848347, -0.24133489844179024, -0.38243218377026755, 0.23476900945553636, 0.2192444658295618, 0.0, 0.0]\n",
      "Training with trader done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>fold_score</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>min_score</th>\n",
       "      <th>max_score</th>\n",
       "      <th>hyperparams</th>\n",
       "      <th>date</th>\n",
       "      <th>roi_hodler</th>\n",
       "      <th>sharpe_hodler</th>\n",
       "      <th>roi_trader</th>\n",
       "      <th>sharpe_trader</th>\n",
       "      <th>roi_whale</th>\n",
       "      <th>sharpe_whale</th>\n",
       "      <th>roi_hodler_whale</th>\n",
       "      <th>sharpe_hodler_whale</th>\n",
       "      <th>roi_charles</th>\n",
       "      <th>sharpe_charles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RandomForestReg</td>\n",
       "      <td>[0.19047, 0.07148, 0.1206, 0.15337, 0.11154, 0...</td>\n",
       "      <td>0.13959</td>\n",
       "      <td>0.04774</td>\n",
       "      <td>0.35085</td>\n",
       "      <td>None</td>\n",
       "      <td>10-03 16:00:37</td>\n",
       "      <td>0.076063</td>\n",
       "      <td>2.692379</td>\n",
       "      <td>-0.023732</td>\n",
       "      <td>-0.631008</td>\n",
       "      <td>-0.004575</td>\n",
       "      <td>-0.119665</td>\n",
       "      <td>-0.004575</td>\n",
       "      <td>-0.119665</td>\n",
       "      <td>0.031312</td>\n",
       "      <td>0.773876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.13652, 0.3541, 0.89001, 0.09658, 0.24001, 0...</td>\n",
       "      <td>0.39088</td>\n",
       "      <td>0.07920</td>\n",
       "      <td>1.68089</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.5}</td>\n",
       "      <td>10-03 15:54:12</td>\n",
       "      <td>0.076063</td>\n",
       "      <td>2.692379</td>\n",
       "      <td>0.004387</td>\n",
       "      <td>0.530331</td>\n",
       "      <td>-0.012604</td>\n",
       "      <td>-0.949174</td>\n",
       "      <td>-0.012604</td>\n",
       "      <td>-0.949174</td>\n",
       "      <td>0.023209</td>\n",
       "      <td>0.649548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dummy</td>\n",
       "      <td>[0.06752, 0.08603, 0.11788, 0.13216, 0.14218, ...</td>\n",
       "      <td>0.11057</td>\n",
       "      <td>0.05455</td>\n",
       "      <td>0.19172</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10-03 15:53:23</td>\n",
       "      <td>0.076063</td>\n",
       "      <td>2.692379</td>\n",
       "      <td>0.053090</td>\n",
       "      <td>0.637716</td>\n",
       "      <td>0.055913</td>\n",
       "      <td>0.458252</td>\n",
       "      <td>0.056260</td>\n",
       "      <td>0.510347</td>\n",
       "      <td>0.065704</td>\n",
       "      <td>1.186462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.20636, 0.26691, 0.91792, 0.5793, 0.12272, 0...</td>\n",
       "      <td>0.62972</td>\n",
       "      <td>0.07553</td>\n",
       "      <td>2.95176</td>\n",
       "      <td>{'alpha': 0.05, 'l1_ratio': 0.0001}</td>\n",
       "      <td>10-03 15:50:33</td>\n",
       "      <td>0.076063</td>\n",
       "      <td>2.692379</td>\n",
       "      <td>0.034135</td>\n",
       "      <td>1.414102</td>\n",
       "      <td>0.025962</td>\n",
       "      <td>1.131473</td>\n",
       "      <td>0.044834</td>\n",
       "      <td>0.932677</td>\n",
       "      <td>0.054169</td>\n",
       "      <td>1.510994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.20636, 0.26691, 0.91792, 0.5793, 0.12272, 0...</td>\n",
       "      <td>0.62972</td>\n",
       "      <td>0.07553</td>\n",
       "      <td>2.95176</td>\n",
       "      <td>{'alpha': 0.05, 'l1_ratio': 0.0001}</td>\n",
       "      <td>10-03 15:45:20</td>\n",
       "      <td>0.076063</td>\n",
       "      <td>2.692379</td>\n",
       "      <td>0.034135</td>\n",
       "      <td>1.414102</td>\n",
       "      <td>0.025962</td>\n",
       "      <td>1.131473</td>\n",
       "      <td>0.044834</td>\n",
       "      <td>0.932677</td>\n",
       "      <td>0.054169</td>\n",
       "      <td>1.510994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.13652, 0.3541, 0.89001, 0.09658, 0.24001, 0...</td>\n",
       "      <td>0.39088</td>\n",
       "      <td>0.07920</td>\n",
       "      <td>1.68089</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.5}</td>\n",
       "      <td>10-03 15:42:00</td>\n",
       "      <td>0.076063</td>\n",
       "      <td>2.692379</td>\n",
       "      <td>0.004387</td>\n",
       "      <td>0.530331</td>\n",
       "      <td>-0.012604</td>\n",
       "      <td>-0.949174</td>\n",
       "      <td>-0.012604</td>\n",
       "      <td>-0.949174</td>\n",
       "      <td>0.023209</td>\n",
       "      <td>0.649548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.13652, 0.3541, 0.89001, 0.09658, 0.24001, 0...</td>\n",
       "      <td>0.39088</td>\n",
       "      <td>0.07920</td>\n",
       "      <td>1.68089</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.5}</td>\n",
       "      <td>10-03 15:41:40</td>\n",
       "      <td>0.076063</td>\n",
       "      <td>2.692379</td>\n",
       "      <td>0.004387</td>\n",
       "      <td>0.530331</td>\n",
       "      <td>-0.012604</td>\n",
       "      <td>-0.949174</td>\n",
       "      <td>-0.012604</td>\n",
       "      <td>-0.949174</td>\n",
       "      <td>0.023209</td>\n",
       "      <td>0.649548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.13652, 0.3541, 0.89001, 0.09658, 0.24001, 0...</td>\n",
       "      <td>0.39088</td>\n",
       "      <td>0.07920</td>\n",
       "      <td>1.68089</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.5}</td>\n",
       "      <td>10-03 15:40:06</td>\n",
       "      <td>0.076063</td>\n",
       "      <td>2.692379</td>\n",
       "      <td>0.004387</td>\n",
       "      <td>0.530331</td>\n",
       "      <td>-0.012604</td>\n",
       "      <td>-0.949174</td>\n",
       "      <td>-0.012604</td>\n",
       "      <td>-0.949174</td>\n",
       "      <td>0.023209</td>\n",
       "      <td>0.649548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.13652, 0.3541, 0.89001, 0.09658, 0.24001, 0...</td>\n",
       "      <td>0.39088</td>\n",
       "      <td>0.07920</td>\n",
       "      <td>1.68089</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.5}</td>\n",
       "      <td>10-03 15:39:42</td>\n",
       "      <td>0.076063</td>\n",
       "      <td>2.692379</td>\n",
       "      <td>0.004387</td>\n",
       "      <td>0.530331</td>\n",
       "      <td>-0.012604</td>\n",
       "      <td>-0.949174</td>\n",
       "      <td>-0.012604</td>\n",
       "      <td>-0.949174</td>\n",
       "      <td>0.023209</td>\n",
       "      <td>0.649548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestReg</td>\n",
       "      <td>[0.19037, 0.07132, 0.12205, 0.15436, 0.11077, ...</td>\n",
       "      <td>0.13984</td>\n",
       "      <td>0.04739</td>\n",
       "      <td>0.35404</td>\n",
       "      <td>None</td>\n",
       "      <td>10-03 13:12:35</td>\n",
       "      <td>0.076063</td>\n",
       "      <td>2.692379</td>\n",
       "      <td>-0.022602</td>\n",
       "      <td>-0.603253</td>\n",
       "      <td>-0.003665</td>\n",
       "      <td>-0.027767</td>\n",
       "      <td>-0.003665</td>\n",
       "      <td>-0.027767</td>\n",
       "      <td>0.064577</td>\n",
       "      <td>1.047856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestReg</td>\n",
       "      <td>[0.07313, 0.07909, 0.10424, 0.12256, 0.11114, ...</td>\n",
       "      <td>0.10006</td>\n",
       "      <td>0.06343</td>\n",
       "      <td>0.17766</td>\n",
       "      <td>None</td>\n",
       "      <td>10-03 12:08:28</td>\n",
       "      <td>0.076063</td>\n",
       "      <td>2.692379</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.099678</td>\n",
       "      <td>2.089733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.06979, 0.08286, 0.09448, 0.10667, 0.08963, ...</td>\n",
       "      <td>0.07873</td>\n",
       "      <td>0.03510</td>\n",
       "      <td>0.11721</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.5}</td>\n",
       "      <td>10-03 12:04:27</td>\n",
       "      <td>0.076063</td>\n",
       "      <td>2.692379</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.099678</td>\n",
       "      <td>2.089733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               name                                         fold_score  \\\n",
       "11  RandomForestReg  [0.19047, 0.07148, 0.1206, 0.15337, 0.11154, 0...   \n",
       "10        LinearReg  [0.13652, 0.3541, 0.89001, 0.09658, 0.24001, 0...   \n",
       "9             Dummy  [0.06752, 0.08603, 0.11788, 0.13216, 0.14218, ...   \n",
       "8         LinearReg  [0.20636, 0.26691, 0.91792, 0.5793, 0.12272, 0...   \n",
       "7         LinearReg  [0.20636, 0.26691, 0.91792, 0.5793, 0.12272, 0...   \n",
       "6         LinearReg  [0.13652, 0.3541, 0.89001, 0.09658, 0.24001, 0...   \n",
       "5         LinearReg  [0.13652, 0.3541, 0.89001, 0.09658, 0.24001, 0...   \n",
       "4         LinearReg  [0.13652, 0.3541, 0.89001, 0.09658, 0.24001, 0...   \n",
       "3         LinearReg  [0.13652, 0.3541, 0.89001, 0.09658, 0.24001, 0...   \n",
       "2   RandomForestReg  [0.19037, 0.07132, 0.12205, 0.15436, 0.11077, ...   \n",
       "1   RandomForestReg  [0.07313, 0.07909, 0.10424, 0.12256, 0.11114, ...   \n",
       "0         LinearReg  [0.06979, 0.08286, 0.09448, 0.10667, 0.08963, ...   \n",
       "\n",
       "    mean_score  min_score  max_score                          hyperparams  \\\n",
       "11     0.13959    0.04774    0.35085                                 None   \n",
       "10     0.39088    0.07920    1.68089        {'alpha': 1, 'l1_ratio': 0.5}   \n",
       "9      0.11057    0.05455    0.19172                                  NaN   \n",
       "8      0.62972    0.07553    2.95176  {'alpha': 0.05, 'l1_ratio': 0.0001}   \n",
       "7      0.62972    0.07553    2.95176  {'alpha': 0.05, 'l1_ratio': 0.0001}   \n",
       "6      0.39088    0.07920    1.68089        {'alpha': 1, 'l1_ratio': 0.5}   \n",
       "5      0.39088    0.07920    1.68089        {'alpha': 1, 'l1_ratio': 0.5}   \n",
       "4      0.39088    0.07920    1.68089        {'alpha': 1, 'l1_ratio': 0.5}   \n",
       "3      0.39088    0.07920    1.68089        {'alpha': 1, 'l1_ratio': 0.5}   \n",
       "2      0.13984    0.04739    0.35404                                 None   \n",
       "1      0.10006    0.06343    0.17766                                 None   \n",
       "0      0.07873    0.03510    0.11721        {'alpha': 1, 'l1_ratio': 0.5}   \n",
       "\n",
       "              date  roi_hodler  sharpe_hodler  roi_trader  sharpe_trader  \\\n",
       "11  10-03 16:00:37    0.076063       2.692379   -0.023732      -0.631008   \n",
       "10  10-03 15:54:12    0.076063       2.692379    0.004387       0.530331   \n",
       "9   10-03 15:53:23    0.076063       2.692379    0.053090       0.637716   \n",
       "8   10-03 15:50:33    0.076063       2.692379    0.034135       1.414102   \n",
       "7   10-03 15:45:20    0.076063       2.692379    0.034135       1.414102   \n",
       "6   10-03 15:42:00    0.076063       2.692379    0.004387       0.530331   \n",
       "5   10-03 15:41:40    0.076063       2.692379    0.004387       0.530331   \n",
       "4   10-03 15:40:06    0.076063       2.692379    0.004387       0.530331   \n",
       "3   10-03 15:39:42    0.076063       2.692379    0.004387       0.530331   \n",
       "2   10-03 13:12:35    0.076063       2.692379   -0.022602      -0.603253   \n",
       "1   10-03 12:08:28    0.076063       2.692379    0.000000       0.000000   \n",
       "0   10-03 12:04:27    0.076063       2.692379    0.000000       0.000000   \n",
       "\n",
       "    roi_whale  sharpe_whale  roi_hodler_whale  sharpe_hodler_whale  \\\n",
       "11  -0.004575     -0.119665         -0.004575            -0.119665   \n",
       "10  -0.012604     -0.949174         -0.012604            -0.949174   \n",
       "9    0.055913      0.458252          0.056260             0.510347   \n",
       "8    0.025962      1.131473          0.044834             0.932677   \n",
       "7    0.025962      1.131473          0.044834             0.932677   \n",
       "6   -0.012604     -0.949174         -0.012604            -0.949174   \n",
       "5   -0.012604     -0.949174         -0.012604            -0.949174   \n",
       "4   -0.012604     -0.949174         -0.012604            -0.949174   \n",
       "3   -0.012604     -0.949174         -0.012604            -0.949174   \n",
       "2   -0.003665     -0.027767         -0.003665            -0.027767   \n",
       "1    0.000000      0.000000          0.000000             0.000000   \n",
       "0    0.000000      0.000000          0.000000             0.000000   \n",
       "\n",
       "    roi_charles  sharpe_charles  \n",
       "11     0.031312        0.773876  \n",
       "10     0.023209        0.649548  \n",
       "9      0.065704        1.186462  \n",
       "8      0.054169        1.510994  \n",
       "7      0.054169        1.510994  \n",
       "6      0.023209        0.649548  \n",
       "5      0.023209        0.649548  \n",
       "4      0.023209        0.649548  \n",
       "3      0.023209        0.649548  \n",
       "2      0.064577        1.047856  \n",
       "1      0.099678        2.089733  \n",
       "0      0.099678        2.089733  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestReg()\n",
    "cv_train(model,ApiCall().read_local(data=\"train\"))\n",
    "read_result().sort_values(by=\"date\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2d919d",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1eec6c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                | 0/32 [00:00<?, ?it/s]2022-03-10 16:03:14.849376: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 8s 522ms/step - loss: 0.1677 - mae: 0.1342 - val_loss: 0.0446 - val_mae: 0.0748\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 162ms/step - loss: 0.0523 - mae: 0.0731 - val_loss: 0.0436 - val_mae: 0.0738\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 168ms/step - loss: 0.0513 - mae: 0.0728 - val_loss: 0.0430 - val_mae: 0.0733\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 160ms/step - loss: 0.0504 - mae: 0.0732 - val_loss: 0.0428 - val_mae: 0.0732\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 1s 141ms/step - loss: 0.0497 - mae: 0.0742 - val_loss: 0.0429 - val_mae: 0.0735\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 140ms/step - loss: 0.0491 - mae: 0.0747 - val_loss: 0.0431 - val_mae: 0.0737\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 1s 133ms/step - loss: 0.0499 - mae: 0.0756 - val_loss: 0.0437 - val_mae: 0.0742\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 1s 135ms/step - loss: 0.0498 - mae: 0.0767 - val_loss: 0.0431 - val_mae: 0.0737\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 1s 133ms/step - loss: 0.0497 - mae: 0.0755 - val_loss: 0.0428 - val_mae: 0.0734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|███▊                                                                                                                    | 1/32 [00:14<07:22, 14.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 10s 1s/step - loss: 0.1487 - mae: 0.1296 - val_loss: 0.0180 - val_mae: 0.0422\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 265ms/step - loss: 0.0707 - mae: 0.0830 - val_loss: 0.0460 - val_mae: 0.0847\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.0552 - mae: 0.0820 - val_loss: 0.0242 - val_mae: 0.0555\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.0574 - mae: 0.0806 - val_loss: 0.0376 - val_mae: 0.0747\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 1s 213ms/step - loss: 0.0622 - mae: 0.0858 - val_loss: 0.0399 - val_mae: 0.0779\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.0594 - mae: 0.0832 - val_loss: 0.0180 - val_mae: 0.0438\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.0601 - mae: 0.0788 - val_loss: 0.0158 - val_mae: 0.0430\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 1s 207ms/step - loss: 0.0523 - mae: 0.0785 - val_loss: 0.0194 - val_mae: 0.0477\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 1s 206ms/step - loss: 0.0502 - mae: 0.0793 - val_loss: 0.0168 - val_mae: 0.0444\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 1s 200ms/step - loss: 0.0593 - mae: 0.0842 - val_loss: 0.0499 - val_mae: 0.0885\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 1s 190ms/step - loss: 0.0551 - mae: 0.0825 - val_loss: 0.0429 - val_mae: 0.0779\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 1s 151ms/step - loss: 0.0503 - mae: 0.0785 - val_loss: 0.0246 - val_mae: 0.0530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|███████▌                                                                                                                | 2/32 [00:41<10:52, 21.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 7s 444ms/step - loss: 0.2752 - mae: 0.1753 - val_loss: 0.0343 - val_mae: 0.0602\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 142ms/step - loss: 0.0634 - mae: 0.0786 - val_loss: 0.0263 - val_mae: 0.0506\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 134ms/step - loss: 0.0530 - mae: 0.0753 - val_loss: 0.0192 - val_mae: 0.0413\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 129ms/step - loss: 0.0467 - mae: 0.0715 - val_loss: 0.0666 - val_mae: 0.0904\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.0777 - mae: 0.0916 - val_loss: 0.0487 - val_mae: 0.0752\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 133ms/step - loss: 0.0503 - mae: 0.0775 - val_loss: 0.0132 - val_mae: 0.0331\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 1s 134ms/step - loss: 0.0555 - mae: 0.0765 - val_loss: 0.0335 - val_mae: 0.0592\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.0482 - mae: 0.0717 - val_loss: 0.0380 - val_mae: 0.0645\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 1s 128ms/step - loss: 0.0536 - mae: 0.0757 - val_loss: 0.0063 - val_mae: 0.0311\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.0487 - mae: 0.0724 - val_loss: 0.1296 - val_mae: 0.1315\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 1s 131ms/step - loss: 0.0843 - mae: 0.0946 - val_loss: 0.0075 - val_mae: 0.0312\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 1s 129ms/step - loss: 0.0605 - mae: 0.0780 - val_loss: 0.0252 - val_mae: 0.0491\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 1s 129ms/step - loss: 0.0504 - mae: 0.0750 - val_loss: 0.0158 - val_mae: 0.0370\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.0526 - mae: 0.0737 - val_loss: 0.0186 - val_mae: 0.0407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|███████████▎                                                                                                            | 3/32 [00:56<09:01, 18.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 7s 461ms/step - loss: 0.0604 - mae: 0.0802 - val_loss: 0.0126 - val_mae: 0.0413\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 137ms/step - loss: 0.0578 - mae: 0.0660 - val_loss: 0.0618 - val_mae: 0.0592\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 138ms/step - loss: 0.0455 - mae: 0.0654 - val_loss: 0.0602 - val_mae: 0.0577\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 138ms/step - loss: 0.0471 - mae: 0.0658 - val_loss: 0.0668 - val_mae: 0.0636\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 1s 141ms/step - loss: 0.0446 - mae: 0.0660 - val_loss: 0.0574 - val_mae: 0.0552\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.0463 - mae: 0.0666 - val_loss: 0.0543 - val_mae: 0.0523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|███████████████                                                                                                         | 4/32 [01:07<07:20, 15.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 7s 440ms/step - loss: 0.3069 - mae: 0.1980 - val_loss: 0.1049 - val_mae: 0.0882\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 123ms/step - loss: 0.0414 - mae: 0.0597 - val_loss: 0.1468 - val_mae: 0.1095\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.0507 - mae: 0.0655 - val_loss: 0.1465 - val_mae: 0.1093\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.0424 - mae: 0.0623 - val_loss: 0.0326 - val_mae: 0.0752\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 1s 127ms/step - loss: 0.0465 - mae: 0.0612 - val_loss: 0.1515 - val_mae: 0.1120\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.0405 - mae: 0.0621 - val_loss: 0.1528 - val_mae: 0.1128\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.0410 - mae: 0.0635 - val_loss: 0.0405 - val_mae: 0.0791\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 1s 126ms/step - loss: 0.0364 - mae: 0.0622 - val_loss: 0.0330 - val_mae: 0.0754\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 1s 137ms/step - loss: 0.0402 - mae: 0.0622 - val_loss: 0.1843 - val_mae: 0.1277\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x1569e0a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|██████████████████▊                                                                                                     | 5/32 [01:19<06:29, 14.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 8s 437ms/step - loss: 0.1737 - mae: 0.1225 - val_loss: 0.0987 - val_mae: 0.1607\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 129ms/step - loss: 0.1144 - mae: 0.1094 - val_loss: 0.1742 - val_mae: 0.1271\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 133ms/step - loss: 0.0536 - mae: 0.0684 - val_loss: 0.1663 - val_mae: 0.1239\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 132ms/step - loss: 0.0530 - mae: 0.0664 - val_loss: 0.1605 - val_mae: 0.1217\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 1s 131ms/step - loss: 0.0505 - mae: 0.0646 - val_loss: 0.1593 - val_mae: 0.1212\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 129ms/step - loss: 0.0522 - mae: 0.0646 - val_loss: 0.1538 - val_mae: 0.1189\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x1559723a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|██████████████████████▌                                                                                                 | 6/32 [01:31<05:48, 13.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 8s 438ms/step - loss: 0.0934 - mae: 0.0921 - val_loss: 0.0908 - val_mae: 0.1026\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 129ms/step - loss: 0.0855 - mae: 0.0906 - val_loss: 0.0732 - val_mae: 0.1005\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 131ms/step - loss: 0.0607 - mae: 0.0744 - val_loss: 0.0727 - val_mae: 0.0999\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 131ms/step - loss: 0.0582 - mae: 0.0732 - val_loss: 0.0728 - val_mae: 0.1003\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 1s 131ms/step - loss: 0.0576 - mae: 0.0726 - val_loss: 0.0726 - val_mae: 0.1000\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 136ms/step - loss: 0.0565 - mae: 0.0724 - val_loss: 0.0726 - val_mae: 0.1000\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 1s 141ms/step - loss: 0.0552 - mae: 0.0723 - val_loss: 0.0608 - val_mae: 0.1014\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 1s 141ms/step - loss: 0.0450 - mae: 0.0711 - val_loss: 0.0726 - val_mae: 0.0999\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 1s 133ms/step - loss: 0.0510 - mae: 0.0707 - val_loss: 0.2131 - val_mae: 0.1579\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 1s 135ms/step - loss: 0.0743 - mae: 0.0876 - val_loss: 0.0740 - val_mae: 0.1009\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 1s 142ms/step - loss: 0.0383 - mae: 0.0693 - val_loss: 0.0749 - val_mae: 0.1016\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 1s 142ms/step - loss: 0.0380 - mae: 0.0690 - val_loss: 0.0753 - val_mae: 0.1018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██████████████████████████▎                                                                                             | 7/32 [01:45<05:46, 13.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 7s 516ms/step - loss: 0.1742 - mae: 0.1399 - val_loss: 0.0805 - val_mae: 0.0938\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 128ms/step - loss: 0.0372 - mae: 0.0706 - val_loss: 0.1045 - val_mae: 0.1089\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 132ms/step - loss: 0.0345 - mae: 0.0674 - val_loss: 0.0959 - val_mae: 0.1030\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 128ms/step - loss: 0.0377 - mae: 0.0697 - val_loss: 0.0717 - val_mae: 0.0879\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 1s 152ms/step - loss: 0.0389 - mae: 0.0681 - val_loss: 0.0738 - val_mae: 0.0894\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 133ms/step - loss: 0.0324 - mae: 0.0644 - val_loss: 0.0841 - val_mae: 0.0963\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 1s 124ms/step - loss: 0.0328 - mae: 0.0660 - val_loss: 0.0812 - val_mae: 0.0943\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 127ms/step - loss: 0.0338 - mae: 0.0661 - val_loss: 0.2688 - val_mae: 0.1881\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 1s 128ms/step - loss: 0.0393 - mae: 0.0790 - val_loss: 0.0821 - val_mae: 0.0950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██████████████████████████████                                                                                          | 8/32 [01:58<05:24, 13.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 8s 443ms/step - loss: 0.1978 - mae: 0.1454 - val_loss: 0.0413 - val_mae: 0.0636\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 128ms/step - loss: 0.0527 - mae: 0.0752 - val_loss: 0.0454 - val_mae: 0.0703\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 128ms/step - loss: 0.0361 - mae: 0.0672 - val_loss: 0.0508 - val_mae: 0.0755\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 128ms/step - loss: 0.0343 - mae: 0.0668 - val_loss: 0.0837 - val_mae: 0.0986\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.0373 - mae: 0.0690 - val_loss: 0.0841 - val_mae: 0.0990\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 177ms/step - loss: 0.0381 - mae: 0.0716 - val_loss: 0.0455 - val_mae: 0.0701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|█████████████████████████████████▊                                                                                      | 9/32 [02:10<04:56, 12.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 9s 551ms/step - loss: 0.0423 - mae: 0.0770 - val_loss: 0.3376 - val_mae: 0.1990\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 150ms/step - loss: 0.0616 - mae: 0.0967 - val_loss: 0.0284 - val_mae: 0.0546\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.0444 - mae: 0.0721 - val_loss: 0.0284 - val_mae: 0.0547\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.0378 - mae: 0.0722 - val_loss: 0.0560 - val_mae: 0.0550\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 0.0393 - mae: 0.0704 - val_loss: 0.0703 - val_mae: 0.0670\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 204ms/step - loss: 0.0375 - mae: 0.0706 - val_loss: 0.0899 - val_mae: 0.0819\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 1s 206ms/step - loss: 0.0378 - mae: 0.0719 - val_loss: 0.0633 - val_mae: 0.0612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|█████████████████████████████████████▏                                                                                 | 10/32 [02:28<05:22, 14.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 7s 466ms/step - loss: 0.2235 - mae: 0.1720 - val_loss: 0.0371 - val_mae: 0.0572\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 152ms/step - loss: 0.0664 - mae: 0.0805 - val_loss: 0.0384 - val_mae: 0.0594\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 153ms/step - loss: 0.0497 - mae: 0.0774 - val_loss: 0.0353 - val_mae: 0.0544\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.0503 - mae: 0.0780 - val_loss: 0.0355 - val_mae: 0.0547\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.0480 - mae: 0.0766 - val_loss: 0.0485 - val_mae: 0.0725\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.0500 - mae: 0.0776 - val_loss: 0.0352 - val_mae: 0.0542\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 127ms/step - loss: 0.0479 - mae: 0.0755 - val_loss: 0.0395 - val_mae: 0.0613\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 0.0654 - mae: 0.0843 - val_loss: 0.0219 - val_mae: 0.0515\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.0567 - mae: 0.0812 - val_loss: 0.0358 - val_mae: 0.0553\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.0530 - mae: 0.0786 - val_loss: 0.0322 - val_mae: 0.0627\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.0517 - mae: 0.0793 - val_loss: 0.0356 - val_mae: 0.0552\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 127ms/step - loss: 0.0413 - mae: 0.0740 - val_loss: 0.0400 - val_mae: 0.0616\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 1s 177ms/step - loss: 0.0499 - mae: 0.0778 - val_loss: 0.0523 - val_mae: 0.0765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|████████████████████████████████████████▉                                                                              | 11/32 [02:43<05:05, 14.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 9s 518ms/step - loss: 0.3014 - mae: 0.1898 - val_loss: 0.0165 - val_mae: 0.0499\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 186ms/step - loss: 0.0565 - mae: 0.0827 - val_loss: 0.0529 - val_mae: 0.0652\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 0.0539 - mae: 0.0795 - val_loss: 0.0189 - val_mae: 0.0515\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.0460 - mae: 0.0777 - val_loss: 0.0165 - val_mae: 0.0499\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.0454 - mae: 0.0769 - val_loss: 0.0177 - val_mae: 0.0499\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 166ms/step - loss: 0.0422 - mae: 0.0752 - val_loss: 0.0271 - val_mae: 0.0531\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 1s 170ms/step - loss: 0.0438 - mae: 0.0758 - val_loss: 0.0181 - val_mae: 0.0503\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.0372 - mae: 0.0740 - val_loss: 0.0181 - val_mae: 0.0503\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 1s 160ms/step - loss: 0.0502 - mae: 0.0796 - val_loss: 0.0755 - val_mae: 0.0843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|████████████████████████████████████████████▋                                                                          | 12/32 [02:57<04:53, 14.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 7s 455ms/step - loss: 0.1444 - mae: 0.1228 - val_loss: 0.0223 - val_mae: 0.0445\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.0898 - mae: 0.1087 - val_loss: 0.0269 - val_mae: 0.0504\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 133ms/step - loss: 0.0767 - mae: 0.0966 - val_loss: 0.0125 - val_mae: 0.0447\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.0574 - mae: 0.0825 - val_loss: 0.0373 - val_mae: 0.0623\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 118ms/step - loss: 0.0701 - mae: 0.0886 - val_loss: 0.0263 - val_mae: 0.0495\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 120ms/step - loss: 0.0455 - mae: 0.0783 - val_loss: 0.0125 - val_mae: 0.0415\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.0597 - mae: 0.0824 - val_loss: 0.0445 - val_mae: 0.0700\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 1s 127ms/step - loss: 0.0655 - mae: 0.0861 - val_loss: 0.0265 - val_mae: 0.0499\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 1s 137ms/step - loss: 0.0392 - mae: 0.0758 - val_loss: 0.0128 - val_mae: 0.0412\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 1s 124ms/step - loss: 0.0435 - mae: 0.0759 - val_loss: 0.0121 - val_mae: 0.0424\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.0452 - mae: 0.0783 - val_loss: 0.0372 - val_mae: 0.0614\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 119ms/step - loss: 0.0533 - mae: 0.0768 - val_loss: 0.0110 - val_mae: 0.0396\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.0477 - mae: 0.0807 - val_loss: 0.0338 - val_mae: 0.0583\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.0534 - mae: 0.0814 - val_loss: 0.0243 - val_mae: 0.0473\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 1s 182ms/step - loss: 0.0383 - mae: 0.0729 - val_loss: 0.0301 - val_mae: 0.0544\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 1s 127ms/step - loss: 0.0440 - mae: 0.0781 - val_loss: 0.0321 - val_mae: 0.0568\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.0374 - mae: 0.0724 - val_loss: 0.0264 - val_mae: 0.0499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████████████████████████████████████████████████▎                                                                      | 13/32 [03:15<04:54, 15.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 7s 476ms/step - loss: 0.0902 - mae: 0.1042 - val_loss: 0.0112 - val_mae: 0.0468\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 142ms/step - loss: 0.0496 - mae: 0.0749 - val_loss: 0.0900 - val_mae: 0.0997\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 122ms/step - loss: 0.0433 - mae: 0.0723 - val_loss: 0.0516 - val_mae: 0.0726\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 127ms/step - loss: 0.0383 - mae: 0.0695 - val_loss: 0.1254 - val_mae: 0.1221\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 1s 133ms/step - loss: 0.0586 - mae: 0.0838 - val_loss: 0.0510 - val_mae: 0.0719\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 127ms/step - loss: 0.0582 - mae: 0.0747 - val_loss: 0.0426 - val_mae: 0.0646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████████████████████████████████████████████████████                                                                   | 14/32 [03:26<04:15, 14.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 7s 441ms/step - loss: 0.0545 - mae: 0.0763 - val_loss: 0.2815 - val_mae: 0.1407\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 131ms/step - loss: 0.0366 - mae: 0.0633 - val_loss: 0.2779 - val_mae: 0.1407\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 135ms/step - loss: 0.0362 - mae: 0.0635 - val_loss: 0.2771 - val_mae: 0.1408\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 141ms/step - loss: 0.0356 - mae: 0.0637 - val_loss: 0.2846 - val_mae: 0.1409\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.0367 - mae: 0.0642 - val_loss: 0.3609 - val_mae: 0.1420\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 128ms/step - loss: 0.0407 - mae: 0.0641 - val_loss: 0.2796 - val_mae: 0.1407\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 1s 134ms/step - loss: 0.0359 - mae: 0.0633 - val_loss: 0.2728 - val_mae: 0.1412\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.0360 - mae: 0.0643 - val_loss: 0.2841 - val_mae: 0.1408\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.0358 - mae: 0.0635 - val_loss: 0.2867 - val_mae: 0.1412\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.0364 - mae: 0.0634 - val_loss: 0.2826 - val_mae: 0.1407\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.0361 - mae: 0.0634 - val_loss: 0.2713 - val_mae: 0.1420\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 1s 127ms/step - loss: 0.0365 - mae: 0.0637 - val_loss: 0.3576 - val_mae: 0.1413\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 1s 132ms/step - loss: 0.0507 - mae: 0.0663 - val_loss: 0.2779 - val_mae: 0.1407\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 1s 133ms/step - loss: 0.0367 - mae: 0.0634 - val_loss: 0.2763 - val_mae: 0.1408\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 1s 131ms/step - loss: 0.0357 - mae: 0.0638 - val_loss: 0.2819 - val_mae: 0.1407\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 1s 133ms/step - loss: 0.0362 - mae: 0.0635 - val_loss: 0.2788 - val_mae: 0.1407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|███████████████████████████████████████████████████████▊                                                               | 15/32 [03:42<04:11, 14.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 7s 439ms/step - loss: 0.1826 - mae: 0.1377 - val_loss: 0.4037 - val_mae: 0.1772\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 145ms/step - loss: 0.0921 - mae: 0.1044 - val_loss: 0.3574 - val_mae: 0.1587\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 132ms/step - loss: 0.0469 - mae: 0.0680 - val_loss: 0.3578 - val_mae: 0.1493\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 127ms/step - loss: 0.0320 - mae: 0.0594 - val_loss: 0.3611 - val_mae: 0.1487\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.0336 - mae: 0.0597 - val_loss: 0.4129 - val_mae: 0.1487\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.0329 - mae: 0.0597 - val_loss: 0.3576 - val_mae: 0.1493\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 1s 132ms/step - loss: 0.0322 - mae: 0.0594 - val_loss: 0.3591 - val_mae: 0.1490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|███████████████████████████████████████████████████████████▌                                                           | 16/32 [03:54<03:41, 13.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 7s 435ms/step - loss: 0.2287 - mae: 0.1474 - val_loss: 0.0282 - val_mae: 0.0762\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.1485 - mae: 0.1028 - val_loss: 0.0701 - val_mae: 0.0775\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 131ms/step - loss: 0.0994 - mae: 0.0829 - val_loss: 0.0529 - val_mae: 0.0676\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 127ms/step - loss: 0.0951 - mae: 0.0805 - val_loss: 0.0260 - val_mae: 0.0662\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.0980 - mae: 0.0802 - val_loss: 0.1809 - val_mae: 0.1377\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 131ms/step - loss: 0.1039 - mae: 0.0926 - val_loss: 0.0737 - val_mae: 0.0794\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 1s 137ms/step - loss: 0.0964 - mae: 0.0818 - val_loss: 0.1006 - val_mae: 0.0958\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 1s 134ms/step - loss: 0.1003 - mae: 0.0855 - val_loss: 0.0918 - val_mae: 0.0907\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 1s 127ms/step - loss: 0.0975 - mae: 0.0830 - val_loss: 0.0728 - val_mae: 0.0789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|███████████████████████████████████████████████████████████████▏                                                       | 17/32 [04:06<03:20, 13.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 7s 446ms/step - loss: 0.5808 - mae: 0.2453 - val_loss: 0.1243 - val_mae: 0.1244\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 127ms/step - loss: 0.1283 - mae: 0.0998 - val_loss: 0.0293 - val_mae: 0.0669\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.1092 - mae: 0.0839 - val_loss: 0.0277 - val_mae: 0.0625\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 125ms/step - loss: 0.0974 - mae: 0.0762 - val_loss: 0.1308 - val_mae: 0.1272\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 1s 124ms/step - loss: 0.1275 - mae: 0.0963 - val_loss: 0.0422 - val_mae: 0.0643\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.0996 - mae: 0.0786 - val_loss: 0.0463 - val_mae: 0.0663\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.0982 - mae: 0.0778 - val_loss: 0.0638 - val_mae: 0.0802\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 1s 125ms/step - loss: 0.1055 - mae: 0.0869 - val_loss: 0.0435 - val_mae: 0.0646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|██████████████████████████████████████████████████████████████████▉                                                    | 18/32 [04:18<03:01, 12.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 15s 477ms/step - loss: 0.1267 - mae: 0.0975 - val_loss: 0.0068 - val_mae: 0.0266\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 133ms/step - loss: 0.1098 - mae: 0.0840 - val_loss: 0.0139 - val_mae: 0.0423\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 145ms/step - loss: 0.1042 - mae: 0.0846 - val_loss: 0.0262 - val_mae: 0.0600\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 127ms/step - loss: 0.1242 - mae: 0.0884 - val_loss: 0.0058 - val_mae: 0.0253\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 1s 150ms/step - loss: 0.0962 - mae: 0.0814 - val_loss: 0.0074 - val_mae: 0.0270\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 143ms/step - loss: 0.0715 - mae: 0.0758 - val_loss: 0.0254 - val_mae: 0.0585\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 1s 165ms/step - loss: 0.1048 - mae: 0.0893 - val_loss: 0.0121 - val_mae: 0.0392\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 1s 150ms/step - loss: 0.1043 - mae: 0.0861 - val_loss: 0.0151 - val_mae: 0.0436\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 1s 131ms/step - loss: 0.1002 - mae: 0.0817 - val_loss: 0.0079 - val_mae: 0.0285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|██████████████████████████████████████████████████████████████████████▋                                                | 19/32 [04:39<03:19, 15.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 8s 434ms/step - loss: 0.4280 - mae: 0.2171 - val_loss: 0.0165 - val_mae: 0.0560\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.1181 - mae: 0.0878 - val_loss: 0.0126 - val_mae: 0.0379\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 126ms/step - loss: 0.1130 - mae: 0.0825 - val_loss: 0.0147 - val_mae: 0.0517\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 137ms/step - loss: 0.1070 - mae: 0.0789 - val_loss: 0.0126 - val_mae: 0.0454\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 1s 138ms/step - loss: 0.0981 - mae: 0.0765 - val_loss: 0.0122 - val_mae: 0.0438\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 135ms/step - loss: 0.0991 - mae: 0.0775 - val_loss: 0.0142 - val_mae: 0.0398\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.0964 - mae: 0.0747 - val_loss: 0.0129 - val_mae: 0.0381\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 1s 140ms/step - loss: 0.0792 - mae: 0.0743 - val_loss: 0.0569 - val_mae: 0.0730\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 1s 143ms/step - loss: 0.0911 - mae: 0.0763 - val_loss: 0.0234 - val_mae: 0.0713\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 1s 150ms/step - loss: 0.1086 - mae: 0.0832 - val_loss: 0.0118 - val_mae: 0.0428\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 1s 140ms/step - loss: 0.1017 - mae: 0.0801 - val_loss: 0.0115 - val_mae: 0.0383\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 1s 155ms/step - loss: 0.1049 - mae: 0.0805 - val_loss: 0.0410 - val_mae: 0.0569\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.1164 - mae: 0.0789 - val_loss: 0.0184 - val_mae: 0.0404\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 1s 131ms/step - loss: 0.0913 - mae: 0.0744 - val_loss: 0.1419 - val_mae: 0.1310\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 1s 132ms/step - loss: 0.1190 - mae: 0.0925 - val_loss: 0.0200 - val_mae: 0.0406\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 1s 150ms/step - loss: 0.0957 - mae: 0.0751 - val_loss: 0.0297 - val_mae: 0.0443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████████████████████████████████████████████████████████████████████████▍                                            | 20/32 [04:56<03:11, 15.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 8s 432ms/step - loss: 1.8883 - mae: 0.4214 - val_loss: 0.0395 - val_mae: 0.0567\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 131ms/step - loss: 0.1095 - mae: 0.0763 - val_loss: 0.0330 - val_mae: 0.0653\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.0983 - mae: 0.0761 - val_loss: 0.0417 - val_mae: 0.0600\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 129ms/step - loss: 0.1019 - mae: 0.0758 - val_loss: 0.0590 - val_mae: 0.0783\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.1201 - mae: 0.0858 - val_loss: 0.0293 - val_mae: 0.0592\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 0.0902 - mae: 0.0736 - val_loss: 0.0413 - val_mae: 0.0598\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.0903 - mae: 0.0737 - val_loss: 0.0309 - val_mae: 0.0628\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.1038 - mae: 0.0810 - val_loss: 0.0280 - val_mae: 0.0578\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.0934 - mae: 0.0747 - val_loss: 0.0254 - val_mae: 0.0552\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 1s 132ms/step - loss: 0.0918 - mae: 0.0751 - val_loss: 0.0261 - val_mae: 0.0541\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 1s 196ms/step - loss: 0.0889 - mae: 0.0719 - val_loss: 0.0245 - val_mae: 0.0524\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 1s 172ms/step - loss: 0.1078 - mae: 0.0863 - val_loss: 0.0243 - val_mae: 0.0523\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 1s 160ms/step - loss: 0.0822 - mae: 0.0721 - val_loss: 0.0310 - val_mae: 0.0558\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 1s 147ms/step - loss: 0.0804 - mae: 0.0736 - val_loss: 0.0424 - val_mae: 0.0636\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 1s 159ms/step - loss: 0.0833 - mae: 0.0744 - val_loss: 0.0408 - val_mae: 0.0588\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.0790 - mae: 0.0707 - val_loss: 0.0412 - val_mae: 0.0591\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 0.0715 - mae: 0.0702 - val_loss: 0.0482 - val_mae: 0.0689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████████████████████████████████████████████████████████████████████████████                                         | 21/32 [05:15<03:02, 16.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 7s 534ms/step - loss: 0.2103 - mae: 0.1260 - val_loss: 0.0218 - val_mae: 0.0513\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 136ms/step - loss: 0.1114 - mae: 0.0847 - val_loss: 0.0264 - val_mae: 0.0505\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.0927 - mae: 0.0743 - val_loss: 0.0236 - val_mae: 0.0480\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 140ms/step - loss: 0.0961 - mae: 0.0733 - val_loss: 0.0204 - val_mae: 0.0450\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.1331 - mae: 0.0940 - val_loss: 0.0202 - val_mae: 0.0472\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 129ms/step - loss: 0.1165 - mae: 0.0813 - val_loss: 0.0201 - val_mae: 0.0449\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 128ms/step - loss: 0.1017 - mae: 0.0739 - val_loss: 0.0223 - val_mae: 0.0526\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 1s 128ms/step - loss: 0.1189 - mae: 0.0788 - val_loss: 0.0201 - val_mae: 0.0449\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 1s 131ms/step - loss: 0.0861 - mae: 0.0735 - val_loss: 0.0194 - val_mae: 0.0448\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 0.1027 - mae: 0.0743 - val_loss: 0.0237 - val_mae: 0.0481\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.1080 - mae: 0.0751 - val_loss: 0.0233 - val_mae: 0.0478\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.0890 - mae: 0.0731 - val_loss: 0.0194 - val_mae: 0.0451\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 1s 132ms/step - loss: 0.0993 - mae: 0.0741 - val_loss: 0.0228 - val_mae: 0.0474\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 1s 129ms/step - loss: 0.0944 - mae: 0.0767 - val_loss: 0.0245 - val_mae: 0.0487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|█████████████████████████████████████████████████████████████████████████████████▊                                     | 22/32 [05:30<02:41, 16.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 8s 533ms/step - loss: 0.5146 - mae: 0.2297 - val_loss: 0.1044 - val_mae: 0.1009\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 129ms/step - loss: 0.1160 - mae: 0.0881 - val_loss: 0.0053 - val_mae: 0.0372\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 128ms/step - loss: 0.1184 - mae: 0.0839 - val_loss: 0.0535 - val_mae: 0.0660\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 0.1055 - mae: 0.0757 - val_loss: 0.0090 - val_mae: 0.0485\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 120ms/step - loss: 0.1082 - mae: 0.0756 - val_loss: 0.0071 - val_mae: 0.0461\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.0945 - mae: 0.0803 - val_loss: 0.0097 - val_mae: 0.0500\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 1s 132ms/step - loss: 0.1064 - mae: 0.0773 - val_loss: 0.0250 - val_mae: 0.0564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|█████████████████████████████████████████████████████████████████████████████████████▌                                 | 23/32 [05:42<02:15, 15.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 8s 670ms/step - loss: 0.0499 - mae: 0.0789 - val_loss: 0.1580 - val_mae: 0.1281\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 181ms/step - loss: 0.0437 - mae: 0.0727 - val_loss: 0.0121 - val_mae: 0.0539\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 163ms/step - loss: 0.0187 - mae: 0.0486 - val_loss: 0.0125 - val_mae: 0.0552\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 168ms/step - loss: 0.0207 - mae: 0.0496 - val_loss: 0.0130 - val_mae: 0.0565\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 1s 134ms/step - loss: 0.0190 - mae: 0.0482 - val_loss: 0.0130 - val_mae: 0.0563\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 156ms/step - loss: 0.0191 - mae: 0.0486 - val_loss: 0.0626 - val_mae: 0.0764\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 1s 184ms/step - loss: 0.0220 - mae: 0.0490 - val_loss: 0.0943 - val_mae: 0.0947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|█████████████████████████████████████████████████████████████████████████████████████████▎                             | 24/32 [05:55<01:55, 14.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 7s 436ms/step - loss: 0.5291 - mae: 0.2410 - val_loss: 0.0492 - val_mae: 0.0970\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 127ms/step - loss: 0.0337 - mae: 0.0690 - val_loss: 0.0433 - val_mae: 0.0936\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 0.0181 - mae: 0.0500 - val_loss: 0.0444 - val_mae: 0.0945\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.0181 - mae: 0.0498 - val_loss: 0.0396 - val_mae: 0.0900\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 127ms/step - loss: 0.0180 - mae: 0.0501 - val_loss: 0.0381 - val_mae: 0.0884\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 126ms/step - loss: 0.0179 - mae: 0.0502 - val_loss: 0.0430 - val_mae: 0.0934\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 1s 127ms/step - loss: 0.0220 - mae: 0.0518 - val_loss: 0.0462 - val_mae: 0.0959\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 1s 133ms/step - loss: 0.0177 - mae: 0.0500 - val_loss: 0.0391 - val_mae: 0.0897\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 119ms/step - loss: 0.0187 - mae: 0.0521 - val_loss: 0.0382 - val_mae: 0.0886\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 1s 182ms/step - loss: 0.0183 - mae: 0.0517 - val_loss: 0.0466 - val_mae: 0.0963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|████████████████████████████████████████████████████████████████████████████████████████████▉                          | 25/32 [06:09<01:38, 14.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 9s 541ms/step - loss: 0.5210 - mae: 0.1989 - val_loss: 0.1186 - val_mae: 0.1262\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 162ms/step - loss: 0.0252 - mae: 0.0518 - val_loss: 0.0594 - val_mae: 0.1156\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 128ms/step - loss: 0.0190 - mae: 0.0502 - val_loss: 0.0602 - val_mae: 0.1164\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 132ms/step - loss: 0.0188 - mae: 0.0499 - val_loss: 0.0567 - val_mae: 0.1084\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.0181 - mae: 0.0501 - val_loss: 0.0610 - val_mae: 0.1172\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 0.0186 - mae: 0.0483 - val_loss: 0.0604 - val_mae: 0.1165\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 1s 254ms/step - loss: 0.0185 - mae: 0.0497 - val_loss: 0.0584 - val_mae: 0.1125\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.0163 - mae: 0.0472 - val_loss: 0.0614 - val_mae: 0.1174\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 0.0195 - mae: 0.0489 - val_loss: 0.0569 - val_mae: 0.1116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████████████████████████████████████████████████████████████████████████████████████████████▋                      | 26/32 [06:27<01:32, 15.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 9s 662ms/step - loss: 0.1161 - mae: 0.1085 - val_loss: 0.1557 - val_mae: 0.1242\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 193ms/step - loss: 0.0448 - mae: 0.0673 - val_loss: 0.0490 - val_mae: 0.0991\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 157ms/step - loss: 0.0273 - mae: 0.0621 - val_loss: 0.0492 - val_mae: 0.0995\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 125ms/step - loss: 0.0269 - mae: 0.0619 - val_loss: 0.0489 - val_mae: 0.0988\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 127ms/step - loss: 0.0255 - mae: 0.0615 - val_loss: 0.0477 - val_mae: 0.0955\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.0256 - mae: 0.0624 - val_loss: 0.0496 - val_mae: 0.1004\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.0260 - mae: 0.0611 - val_loss: 0.0512 - val_mae: 0.1038\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.0273 - mae: 0.0609 - val_loss: 0.0481 - val_mae: 0.0965\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.0256 - mae: 0.0615 - val_loss: 0.0506 - val_mae: 0.1027\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 1s 126ms/step - loss: 0.0253 - mae: 0.0604 - val_loss: 0.0483 - val_mae: 0.0953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████████████████████████████████████████████████████████████████████████████████████████████████▍                  | 27/32 [06:42<01:16, 15.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 7s 435ms/step - loss: 0.0805 - mae: 0.0897 - val_loss: 0.0433 - val_mae: 0.0715\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 126ms/step - loss: 0.0298 - mae: 0.0710 - val_loss: 0.0481 - val_mae: 0.0762\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 126ms/step - loss: 0.0298 - mae: 0.0711 - val_loss: 0.0413 - val_mae: 0.0706\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 131ms/step - loss: 0.0298 - mae: 0.0715 - val_loss: 0.0526 - val_mae: 0.0805\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 1s 128ms/step - loss: 0.0307 - mae: 0.0713 - val_loss: 0.0448 - val_mae: 0.0733\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 0.0285 - mae: 0.0698 - val_loss: 0.0396 - val_mae: 0.0698\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 0.0315 - mae: 0.0725 - val_loss: 0.0525 - val_mae: 0.0804\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.0303 - mae: 0.0712 - val_loss: 0.0426 - val_mae: 0.0719\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.0297 - mae: 0.0711 - val_loss: 0.0545 - val_mae: 0.0823\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 1s 127ms/step - loss: 0.0285 - mae: 0.0685 - val_loss: 0.0464 - val_mae: 0.0749\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.0297 - mae: 0.0709 - val_loss: 0.0433 - val_mae: 0.0723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████▏              | 28/32 [06:55<00:58, 14.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 8s 441ms/step - loss: 0.1624 - mae: 0.1303 - val_loss: 0.0667 - val_mae: 0.0823\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 127ms/step - loss: 0.1484 - mae: 0.1268 - val_loss: 0.0947 - val_mae: 0.1005\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 127ms/step - loss: 0.0371 - mae: 0.0764 - val_loss: 0.0933 - val_mae: 0.0994\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 136ms/step - loss: 0.0367 - mae: 0.0757 - val_loss: 0.0736 - val_mae: 0.0859\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.0367 - mae: 0.0759 - val_loss: 0.0776 - val_mae: 0.0884\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 130ms/step - loss: 0.0361 - mae: 0.0758 - val_loss: 0.0803 - val_mae: 0.0902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▊           | 29/32 [07:06<00:40, 13.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 7s 466ms/step - loss: 0.1851 - mae: 0.1688 - val_loss: 0.0817 - val_mae: 0.1160\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.0869 - mae: 0.0959 - val_loss: 0.1290 - val_mae: 0.1070\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.0438 - mae: 0.0800 - val_loss: 0.1577 - val_mae: 0.1114\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.0373 - mae: 0.0788 - val_loss: 0.1944 - val_mae: 0.1279\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 1s 144ms/step - loss: 0.0354 - mae: 0.0765 - val_loss: 0.1670 - val_mae: 0.1153\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 137ms/step - loss: 0.0328 - mae: 0.0750 - val_loss: 0.1609 - val_mae: 0.1134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▌       | 30/32 [07:17<00:25, 12.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 8s 438ms/step - loss: 0.1214 - mae: 0.1234 - val_loss: 0.3358 - val_mae: 0.2018\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 128ms/step - loss: 0.1158 - mae: 0.1213 - val_loss: 0.0881 - val_mae: 0.0861\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 127ms/step - loss: 0.0595 - mae: 0.0919 - val_loss: 0.0735 - val_mae: 0.0757\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.0571 - mae: 0.0891 - val_loss: 0.0749 - val_mae: 0.0767\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 1s 140ms/step - loss: 0.0544 - mae: 0.0885 - val_loss: 0.0664 - val_mae: 0.0701\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 0.0779 - mae: 0.0975 - val_loss: 0.0732 - val_mae: 0.0756\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.0608 - mae: 0.0960 - val_loss: 0.0901 - val_mae: 0.0876\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 0.0605 - mae: 0.0938 - val_loss: 0.0842 - val_mae: 0.0834\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.0584 - mae: 0.0902 - val_loss: 0.0691 - val_mae: 0.0730\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.0681 - mae: 0.0935 - val_loss: 0.0701 - val_mae: 0.0738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎   | 31/32 [07:30<00:12, 12.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 7s 593ms/step - loss: 0.2202 - mae: 0.1583 - val_loss: 0.0671 - val_mae: 0.0843\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.1004 - mae: 0.1017 - val_loss: 0.0641 - val_mae: 0.0834\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 127ms/step - loss: 0.0948 - mae: 0.1014 - val_loss: 0.0548 - val_mae: 0.0821\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.0751 - mae: 0.0975 - val_loss: 0.0552 - val_mae: 0.0822\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.0664 - mae: 0.0953 - val_loss: 0.0819 - val_mae: 0.1016\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.1414 - mae: 0.1271 - val_loss: 0.0546 - val_mae: 0.0819\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 0.0721 - mae: 0.0972 - val_loss: 0.0648 - val_mae: 0.0835\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.0746 - mae: 0.0985 - val_loss: 0.0554 - val_mae: 0.0819\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.0748 - mae: 0.0979 - val_loss: 0.0564 - val_mae: 0.0820\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 1s 128ms/step - loss: 0.0643 - mae: 0.0952 - val_loss: 0.0550 - val_mae: 0.0817\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.0662 - mae: 0.0954 - val_loss: 0.0633 - val_mae: 0.0832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [07:44<00:00, 14.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 7s 437ms/step - loss: 0.1298 - mae: 0.1330 - val_loss: 0.0663 - val_mae: 0.0799\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.0530 - mae: 0.0779 - val_loss: 0.0442 - val_mae: 0.0743\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 129ms/step - loss: 0.0514 - mae: 0.0767 - val_loss: 0.0619 - val_mae: 0.0767\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 131ms/step - loss: 0.0517 - mae: 0.0751 - val_loss: 0.0431 - val_mae: 0.0734\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.0490 - mae: 0.0752 - val_loss: 0.0479 - val_mae: 0.0788\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.0490 - mae: 0.0775 - val_loss: 0.0486 - val_mae: 0.0753\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.0503 - mae: 0.0754 - val_loss: 0.0526 - val_mae: 0.0838\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.0477 - mae: 0.0764 - val_loss: 0.0420 - val_mae: 0.0746\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 129ms/step - loss: 0.0642 - mae: 0.0870 - val_loss: 0.0791 - val_mae: 0.1058\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 127ms/step - loss: 0.0646 - mae: 0.0880 - val_loss: 0.0678 - val_mae: 0.0847\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 1s 129ms/step - loss: 0.1161 - mae: 0.1098 - val_loss: 0.0679 - val_mae: 0.0817\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 128ms/step - loss: 0.0758 - mae: 0.0770 - val_loss: 0.0597 - val_mae: 0.0753\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 1s 129ms/step - loss: 0.0601 - mae: 0.0732 - val_loss: 0.0435 - val_mae: 0.0738\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 8s 457ms/step - loss: 0.3393 - mae: 0.2037 - val_loss: 0.2157 - val_mae: 0.2016\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 135ms/step - loss: 0.0923 - mae: 0.1064 - val_loss: 0.0201 - val_mae: 0.0488\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 147ms/step - loss: 0.0567 - mae: 0.0814 - val_loss: 0.0197 - val_mae: 0.0482\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 128ms/step - loss: 0.0553 - mae: 0.0796 - val_loss: 0.0651 - val_mae: 0.1031\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 1s 135ms/step - loss: 0.0626 - mae: 0.0874 - val_loss: 0.0195 - val_mae: 0.0479\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 124ms/step - loss: 0.0559 - mae: 0.0799 - val_loss: 0.0370 - val_mae: 0.0723\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 1s 123ms/step - loss: 0.0488 - mae: 0.0802 - val_loss: 0.0206 - val_mae: 0.0489\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.0824 - mae: 0.0933 - val_loss: 0.0312 - val_mae: 0.0590\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 1s 123ms/step - loss: 0.0923 - mae: 0.0928 - val_loss: 0.0178 - val_mae: 0.0459\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.0526 - mae: 0.0784 - val_loss: 0.0498 - val_mae: 0.0840\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 1s 138ms/step - loss: 0.0651 - mae: 0.0868 - val_loss: 0.0210 - val_mae: 0.0494\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 1s 147ms/step - loss: 0.0557 - mae: 0.0821 - val_loss: 0.0349 - val_mae: 0.0679\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 1s 127ms/step - loss: 0.0457 - mae: 0.0773 - val_loss: 0.0420 - val_mae: 0.0776\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 1s 132ms/step - loss: 0.0446 - mae: 0.0744 - val_loss: 0.0169 - val_mae: 0.0453\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 1s 134ms/step - loss: 0.0625 - mae: 0.0851 - val_loss: 0.0172 - val_mae: 0.0447\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 1s 133ms/step - loss: 0.0498 - mae: 0.0769 - val_loss: 0.0151 - val_mae: 0.0432\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 0.0450 - mae: 0.0718 - val_loss: 0.0598 - val_mae: 0.0868\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 0.0841 - mae: 0.0921 - val_loss: 0.0222 - val_mae: 0.0517\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.0651 - mae: 0.0822 - val_loss: 0.0280 - val_mae: 0.0495\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.0540 - mae: 0.0792 - val_loss: 0.0483 - val_mae: 0.0743\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 13s 625ms/step - loss: 0.0840 - mae: 0.0898 - val_loss: 0.0149 - val_mae: 0.0355\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 133ms/step - loss: 0.0534 - mae: 0.0750 - val_loss: 0.0067 - val_mae: 0.0309\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 153ms/step - loss: 0.0500 - mae: 0.0718 - val_loss: 0.0387 - val_mae: 0.0650\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 127ms/step - loss: 0.0538 - mae: 0.0742 - val_loss: 0.0573 - val_mae: 0.0827\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 1s 123ms/step - loss: 0.0542 - mae: 0.0787 - val_loss: 0.0402 - val_mae: 0.0668\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 141ms/step - loss: 0.0497 - mae: 0.0756 - val_loss: 0.0068 - val_mae: 0.0311\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 1s 152ms/step - loss: 0.0501 - mae: 0.0714 - val_loss: 0.0847 - val_mae: 0.1039\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 8s 444ms/step - loss: 0.2438 - mae: 0.1636 - val_loss: 0.0556 - val_mae: 0.0534\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 126ms/step - loss: 0.0423 - mae: 0.0668 - val_loss: 0.0101 - val_mae: 0.0405\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.0626 - mae: 0.0684 - val_loss: 0.0514 - val_mae: 0.0494\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.0450 - mae: 0.0647 - val_loss: 0.0633 - val_mae: 0.0604\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 1s 128ms/step - loss: 0.0462 - mae: 0.0678 - val_loss: 0.0529 - val_mae: 0.0511\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.0617 - mae: 0.0694 - val_loss: 0.0899 - val_mae: 0.0818\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 1s 134ms/step - loss: 0.0448 - mae: 0.0696 - val_loss: 0.0687 - val_mae: 0.0652\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 7s 437ms/step - loss: 0.1123 - mae: 0.1062 - val_loss: 0.0252 - val_mae: 0.0683\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 129ms/step - loss: 0.2438 - mae: 0.1566 - val_loss: 0.1867 - val_mae: 0.1293\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 135ms/step - loss: 0.0452 - mae: 0.0693 - val_loss: 0.1104 - val_mae: 0.0890\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 133ms/step - loss: 0.0421 - mae: 0.0615 - val_loss: 0.0363 - val_mae: 0.0785\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 1s 127ms/step - loss: 0.0513 - mae: 0.0598 - val_loss: 0.1601 - val_mae: 0.1162\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.0451 - mae: 0.0635 - val_loss: 0.0308 - val_mae: 0.0733\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 7s 432ms/step - loss: 0.1687 - mae: 0.1487 - val_loss: 0.1311 - val_mae: 0.1086\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.0527 - mae: 0.0683 - val_loss: 0.1661 - val_mae: 0.1239\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 128ms/step - loss: 0.0556 - mae: 0.0646 - val_loss: 0.2342 - val_mae: 0.1478\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.0506 - mae: 0.0685 - val_loss: 0.0399 - val_mae: 0.1001\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 1s 127ms/step - loss: 0.0361 - mae: 0.0583 - val_loss: 0.1444 - val_mae: 0.1148\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.0404 - mae: 0.0606 - val_loss: 0.0254 - val_mae: 0.0728\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 1s 126ms/step - loss: 0.0514 - mae: 0.0742 - val_loss: 0.1717 - val_mae: 0.1259\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.0368 - mae: 0.0624 - val_loss: 0.0341 - val_mae: 0.0955\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.0375 - mae: 0.0647 - val_loss: 0.2022 - val_mae: 0.1367\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 1s 256ms/step - loss: 0.0402 - mae: 0.0648 - val_loss: 0.0331 - val_mae: 0.0941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n",
      "4/4 [==============================] - 1s 136ms/step - loss: 0.0436 - mae: 0.0683 - val_loss: 0.0321 - val_mae: 0.0894\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 8s 440ms/step - loss: 0.2045 - mae: 0.1571 - val_loss: 0.1217 - val_mae: 0.1129\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.0625 - mae: 0.0766 - val_loss: 0.0760 - val_mae: 0.1026\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.0598 - mae: 0.0752 - val_loss: 0.0764 - val_mae: 0.1027\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 132ms/step - loss: 0.0501 - mae: 0.0712 - val_loss: 0.0941 - val_mae: 0.1031\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 1s 144ms/step - loss: 0.0692 - mae: 0.0787 - val_loss: 0.1150 - val_mae: 0.1105\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 133ms/step - loss: 0.1208 - mae: 0.1079 - val_loss: 0.1014 - val_mae: 0.1024\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 1s 133ms/step - loss: 0.0506 - mae: 0.0707 - val_loss: 0.0734 - val_mae: 0.1008\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 1s 129ms/step - loss: 0.0411 - mae: 0.0694 - val_loss: 0.0865 - val_mae: 0.1096\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 1s 129ms/step - loss: 0.0360 - mae: 0.0674 - val_loss: 0.1101 - val_mae: 0.1100\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 1s 128ms/step - loss: 0.0855 - mae: 0.0945 - val_loss: 0.0718 - val_mae: 0.0995\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.0379 - mae: 0.0671 - val_loss: 0.0806 - val_mae: 0.1021\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.0389 - mae: 0.0699 - val_loss: 0.0766 - val_mae: 0.1029\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 127ms/step - loss: 0.0347 - mae: 0.0663 - val_loss: 0.0809 - val_mae: 0.1058\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 1s 133ms/step - loss: 0.0305 - mae: 0.0652 - val_loss: 0.0661 - val_mae: 0.1003\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.0338 - mae: 0.0675 - val_loss: 0.0961 - val_mae: 0.1151\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.0309 - mae: 0.0668 - val_loss: 0.0893 - val_mae: 0.1111\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.0289 - mae: 0.0660 - val_loss: 0.0849 - val_mae: 0.1078\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.0304 - mae: 0.0656 - val_loss: 0.0682 - val_mae: 0.0983\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 1s 133ms/step - loss: 0.0414 - mae: 0.0712 - val_loss: 0.1394 - val_mae: 0.1335\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 7s 434ms/step - loss: 0.3901 - mae: 0.2022 - val_loss: 0.1029 - val_mae: 0.1086\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 132ms/step - loss: 0.0351 - mae: 0.0679 - val_loss: 0.0844 - val_mae: 0.0967\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 127ms/step - loss: 0.0360 - mae: 0.0682 - val_loss: 0.1022 - val_mae: 0.1081\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 131ms/step - loss: 0.0308 - mae: 0.0670 - val_loss: 0.0865 - val_mae: 0.0981\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.0348 - mae: 0.0687 - val_loss: 0.0933 - val_mae: 0.1024\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 128ms/step - loss: 0.0311 - mae: 0.0661 - val_loss: 0.0706 - val_mae: 0.0888\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.0400 - mae: 0.0681 - val_loss: 0.1576 - val_mae: 0.1386\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.0377 - mae: 0.0719 - val_loss: 0.0740 - val_mae: 0.0874\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.0456 - mae: 0.0687 - val_loss: 0.0758 - val_mae: 0.0919\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.0314 - mae: 0.0650 - val_loss: 0.2561 - val_mae: 0.1825\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 119ms/step - loss: 0.0636 - mae: 0.0841 - val_loss: 0.0791 - val_mae: 0.0926\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 7s 437ms/step - loss: 0.0557 - mae: 0.0750 - val_loss: 0.0423 - val_mae: 0.0647\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 133ms/step - loss: 0.0354 - mae: 0.0661 - val_loss: 0.0422 - val_mae: 0.0642\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.0361 - mae: 0.0655 - val_loss: 0.0456 - val_mae: 0.0702\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 129ms/step - loss: 0.0351 - mae: 0.0661 - val_loss: 0.0459 - val_mae: 0.0705\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 116ms/step - loss: 0.0349 - mae: 0.0656 - val_loss: 0.0421 - val_mae: 0.0637\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 132ms/step - loss: 0.0409 - mae: 0.0671 - val_loss: 0.0477 - val_mae: 0.0725\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 1s 138ms/step - loss: 0.0355 - mae: 0.0665 - val_loss: 0.0443 - val_mae: 0.0685\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.0480 - mae: 0.0739 - val_loss: 0.0480 - val_mae: 0.0729\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.0428 - mae: 0.0705 - val_loss: 0.0502 - val_mae: 0.0748\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 1s 127ms/step - loss: 0.0326 - mae: 0.0655 - val_loss: 0.0496 - val_mae: 0.0743\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 7s 441ms/step - loss: 0.1255 - mae: 0.1260 - val_loss: 0.0975 - val_mae: 0.0869\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 131ms/step - loss: 0.0395 - mae: 0.0726 - val_loss: 0.0875 - val_mae: 0.0802\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 133ms/step - loss: 0.0374 - mae: 0.0731 - val_loss: 0.0702 - val_mae: 0.0667\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 127ms/step - loss: 0.0385 - mae: 0.0713 - val_loss: 0.1656 - val_mae: 0.1266\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 1s 129ms/step - loss: 0.0426 - mae: 0.0760 - val_loss: 0.0692 - val_mae: 0.0660\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 204ms/step - loss: 0.0378 - mae: 0.0712 - val_loss: 0.0733 - val_mae: 0.0695\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 128ms/step - loss: 0.0372 - mae: 0.0712 - val_loss: 0.0740 - val_mae: 0.0701\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 1s 131ms/step - loss: 0.0397 - mae: 0.0713 - val_loss: 0.0738 - val_mae: 0.0699\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 1s 162ms/step - loss: 0.0380 - mae: 0.0714 - val_loss: 0.0734 - val_mae: 0.0696\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 1s 143ms/step - loss: 0.0375 - mae: 0.0712 - val_loss: 0.0788 - val_mae: 0.0738\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 8s 459ms/step - loss: 0.1332 - mae: 0.1242 - val_loss: 0.0562 - val_mae: 0.0803\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 127ms/step - loss: 0.0508 - mae: 0.0819 - val_loss: 0.0558 - val_mae: 0.0799\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 125ms/step - loss: 0.0701 - mae: 0.0860 - val_loss: 0.0788 - val_mae: 0.0978\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 131ms/step - loss: 0.0548 - mae: 0.0827 - val_loss: 0.0411 - val_mae: 0.0636\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 1s 129ms/step - loss: 0.0475 - mae: 0.0770 - val_loss: 0.0370 - val_mae: 0.0572\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 127ms/step - loss: 0.0470 - mae: 0.0758 - val_loss: 0.0368 - val_mae: 0.0571\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 1s 136ms/step - loss: 0.0486 - mae: 0.0781 - val_loss: 0.0368 - val_mae: 0.0569\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.0473 - mae: 0.0770 - val_loss: 0.0358 - val_mae: 0.0555\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.0453 - mae: 0.0744 - val_loss: 0.0380 - val_mae: 0.0592\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.0500 - mae: 0.0779 - val_loss: 0.0361 - val_mae: 0.0557\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 0.1440 - mae: 0.1152 - val_loss: 0.0607 - val_mae: 0.0843\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 1s 301ms/step - loss: 0.0567 - mae: 0.0870 - val_loss: 0.0354 - val_mae: 0.0544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.0410 - mae: 0.0739 - val_loss: 0.0219 - val_mae: 0.0536\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.0341 - mae: 0.0745 - val_loss: 0.0218 - val_mae: 0.0524\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 1s 211ms/step - loss: 0.0345 - mae: 0.0740 - val_loss: 0.0218 - val_mae: 0.0519\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 1s 197ms/step - loss: 0.0392 - mae: 0.0765 - val_loss: 0.0217 - val_mae: 0.0516\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 1s 196ms/step - loss: 0.0335 - mae: 0.0729 - val_loss: 0.0221 - val_mae: 0.0517\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 0.0345 - mae: 0.0736 - val_loss: 0.0226 - val_mae: 0.0521\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 1s 215ms/step - loss: 0.0358 - mae: 0.0740 - val_loss: 0.0216 - val_mae: 0.0518\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 0.0364 - mae: 0.0757 - val_loss: 0.0220 - val_mae: 0.0516\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 9s 540ms/step - loss: 0.5039 - mae: 0.2153 - val_loss: 0.0516 - val_mae: 0.0634\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 159ms/step - loss: 0.0545 - mae: 0.0817 - val_loss: 0.0179 - val_mae: 0.0512\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 157ms/step - loss: 0.0745 - mae: 0.0863 - val_loss: 0.0569 - val_mae: 0.0687\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 152ms/step - loss: 0.0547 - mae: 0.0803 - val_loss: 0.0172 - val_mae: 0.0495\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 1s 149ms/step - loss: 0.0566 - mae: 0.0810 - val_loss: 0.0687 - val_mae: 0.0790\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 148ms/step - loss: 0.0615 - mae: 0.0831 - val_loss: 0.0428 - val_mae: 0.0564\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 1s 148ms/step - loss: 0.0445 - mae: 0.0770 - val_loss: 0.0188 - val_mae: 0.0550\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 1s 140ms/step - loss: 0.0523 - mae: 0.0838 - val_loss: 0.0671 - val_mae: 0.0776\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 1s 142ms/step - loss: 0.0453 - mae: 0.0785 - val_loss: 0.1033 - val_mae: 0.1035\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 8s 431ms/step - loss: 0.1225 - mae: 0.1235 - val_loss: 0.0130 - val_mae: 0.0458\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 0.1118 - mae: 0.1174 - val_loss: 0.0229 - val_mae: 0.0459\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 126ms/step - loss: 0.0416 - mae: 0.0788 - val_loss: 0.0111 - val_mae: 0.0415\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.0561 - mae: 0.0814 - val_loss: 0.0264 - val_mae: 0.0501\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 0.0383 - mae: 0.0755 - val_loss: 0.0228 - val_mae: 0.0460\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 117ms/step - loss: 0.0369 - mae: 0.0736 - val_loss: 0.0407 - val_mae: 0.0655\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.0384 - mae: 0.0744 - val_loss: 0.0427 - val_mae: 0.0679\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.0524 - mae: 0.0825 - val_loss: 0.0211 - val_mae: 0.0438\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 7s 471ms/step - loss: 0.1944 - mae: 0.1462 - val_loss: 0.0298 - val_mae: 0.0695\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 162ms/step - loss: 0.0870 - mae: 0.0946 - val_loss: 0.0624 - val_mae: 0.0807\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 118ms/step - loss: 0.0480 - mae: 0.0747 - val_loss: 0.0131 - val_mae: 0.0507\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 127ms/step - loss: 0.0468 - mae: 0.0727 - val_loss: 0.0457 - val_mae: 0.0673\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 1s 129ms/step - loss: 0.0437 - mae: 0.0730 - val_loss: 0.0137 - val_mae: 0.0515\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 129ms/step - loss: 0.0464 - mae: 0.0726 - val_loss: 0.0468 - val_mae: 0.0684\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 127ms/step - loss: 0.0440 - mae: 0.0722 - val_loss: 0.0346 - val_mae: 0.0581\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.0572 - mae: 0.0777 - val_loss: 0.0219 - val_mae: 0.0553\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 8s 437ms/step - loss: 0.9599 - mae: 0.2810 - val_loss: 0.3774 - val_mae: 0.1445\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.0470 - mae: 0.0663 - val_loss: 0.2845 - val_mae: 0.1408\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.0352 - mae: 0.0636 - val_loss: 0.2773 - val_mae: 0.1407\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 0.0357 - mae: 0.0635 - val_loss: 0.2755 - val_mae: 0.1407\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 1s 129ms/step - loss: 0.0365 - mae: 0.0637 - val_loss: 0.2751 - val_mae: 0.1408\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.0361 - mae: 0.0639 - val_loss: 0.2753 - val_mae: 0.1407\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.0359 - mae: 0.0637 - val_loss: 0.2761 - val_mae: 0.1407\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 1s 127ms/step - loss: 0.0356 - mae: 0.0636 - val_loss: 0.2773 - val_mae: 0.1407\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.0357 - mae: 0.0635 - val_loss: 0.2813 - val_mae: 0.1406\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 1s 129ms/step - loss: 0.0359 - mae: 0.0633 - val_loss: 0.2784 - val_mae: 0.1406\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 8s 698ms/step - loss: 0.0455 - mae: 0.0731 - val_loss: 0.3594 - val_mae: 0.1488\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 155ms/step - loss: 0.0386 - mae: 0.0598 - val_loss: 0.3574 - val_mae: 0.1492\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 125ms/step - loss: 0.0330 - mae: 0.0595 - val_loss: 0.3585 - val_mae: 0.1490\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 139ms/step - loss: 0.0326 - mae: 0.0595 - val_loss: 0.3600 - val_mae: 0.1487\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.0331 - mae: 0.0597 - val_loss: 0.3560 - val_mae: 0.1495\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 213ms/step - loss: 0.0329 - mae: 0.0596 - val_loss: 0.3557 - val_mae: 0.1495\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 1s 125ms/step - loss: 0.0335 - mae: 0.0607 - val_loss: 0.3576 - val_mae: 0.1492\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 1s 148ms/step - loss: 0.0327 - mae: 0.0594 - val_loss: 0.3589 - val_mae: 0.1489\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 1s 156ms/step - loss: 0.0328 - mae: 0.0595 - val_loss: 0.3565 - val_mae: 0.1494\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 1s 132ms/step - loss: 0.0331 - mae: 0.0597 - val_loss: 0.3106 - val_mae: 0.1483\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 1s 145ms/step - loss: 0.0351 - mae: 0.0597 - val_loss: 0.3132 - val_mae: 0.1481\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.0342 - mae: 0.0600 - val_loss: 0.3577 - val_mae: 0.1491\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 1s 133ms/step - loss: 0.0370 - mae: 0.0597 - val_loss: 0.3573 - val_mae: 0.1492\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 1s 137ms/step - loss: 0.0324 - mae: 0.0595 - val_loss: 0.3597 - val_mae: 0.1487\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 120ms/step - loss: 0.0325 - mae: 0.0593 - val_loss: 0.3117 - val_mae: 0.1482\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 8s 459ms/step - loss: 0.4088 - mae: 0.1892 - val_loss: 0.0157 - val_mae: 0.0578\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 128ms/step - loss: 0.1300 - mae: 0.0845 - val_loss: 0.0194 - val_mae: 0.0632\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.1166 - mae: 0.0811 - val_loss: 0.0211 - val_mae: 0.0656\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 127ms/step - loss: 0.1165 - mae: 0.0804 - val_loss: 0.0557 - val_mae: 0.0686\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.1023 - mae: 0.0799 - val_loss: 0.0611 - val_mae: 0.0720\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 129ms/step - loss: 0.0971 - mae: 0.0803 - val_loss: 0.0628 - val_mae: 0.0731\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 9s 437ms/step - loss: 0.1433 - mae: 0.1053 - val_loss: 0.0477 - val_mae: 0.0667\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 133ms/step - loss: 0.1735 - mae: 0.1205 - val_loss: 0.0263 - val_mae: 0.0610\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 127ms/step - loss: 0.1013 - mae: 0.0782 - val_loss: 0.0381 - val_mae: 0.0629\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 126ms/step - loss: 0.1044 - mae: 0.0778 - val_loss: 0.0279 - val_mae: 0.0617\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 1s 125ms/step - loss: 0.1008 - mae: 0.0768 - val_loss: 0.0269 - val_mae: 0.0626\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.0990 - mae: 0.0773 - val_loss: 0.0270 - val_mae: 0.0613\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.1083 - mae: 0.0785 - val_loss: 0.0259 - val_mae: 0.0608\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.0925 - mae: 0.0774 - val_loss: 0.0271 - val_mae: 0.0613\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.0868 - mae: 0.0759 - val_loss: 0.0265 - val_mae: 0.0632\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 1s 129ms/step - loss: 0.1095 - mae: 0.0821 - val_loss: 0.0419 - val_mae: 0.0641\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 1s 127ms/step - loss: 0.1021 - mae: 0.0782 - val_loss: 0.0612 - val_mae: 0.0783\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.1048 - mae: 0.0832 - val_loss: 0.0259 - val_mae: 0.0606\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 8s 593ms/step - loss: 0.1071 - mae: 0.0840 - val_loss: 0.0350 - val_mae: 0.0776\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 133ms/step - loss: 0.1237 - mae: 0.0955 - val_loss: 0.0059 - val_mae: 0.0255\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.1175 - mae: 0.0816 - val_loss: 0.0063 - val_mae: 0.0258\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.1150 - mae: 0.0822 - val_loss: 0.0089 - val_mae: 0.0318\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 1s 274ms/step - loss: 0.1095 - mae: 0.0841 - val_loss: 0.0277 - val_mae: 0.0621\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.1169 - mae: 0.0824 - val_loss: 0.0075 - val_mae: 0.0282\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.1098 - mae: 0.0823 - val_loss: 0.0055 - val_mae: 0.0254\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 1s 221ms/step - loss: 0.0962 - mae: 0.0808 - val_loss: 0.0069 - val_mae: 0.0267\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.1151 - mae: 0.0815 - val_loss: 0.0056 - val_mae: 0.0257\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 1s 252ms/step - loss: 0.1120 - mae: 0.0816 - val_loss: 0.0057 - val_mae: 0.0255\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 0.1139 - mae: 0.0817 - val_loss: 0.0061 - val_mae: 0.0255\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 1s 213ms/step - loss: 0.1085 - mae: 0.0820 - val_loss: 0.0061 - val_mae: 0.0255\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 7s 447ms/step - loss: 0.2764 - mae: 0.1783 - val_loss: 0.0286 - val_mae: 0.0432\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 129ms/step - loss: 0.1304 - mae: 0.0978 - val_loss: 0.0117 - val_mae: 0.0373\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 129ms/step - loss: 0.1060 - mae: 0.0759 - val_loss: 0.0115 - val_mae: 0.0403\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 129ms/step - loss: 0.0880 - mae: 0.0739 - val_loss: 0.0290 - val_mae: 0.0439\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 1s 137ms/step - loss: 0.0836 - mae: 0.0739 - val_loss: 0.0121 - val_mae: 0.0381\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 131ms/step - loss: 0.0728 - mae: 0.0715 - val_loss: 0.0328 - val_mae: 0.0480\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 1s 129ms/step - loss: 0.0841 - mae: 0.0723 - val_loss: 0.0770 - val_mae: 0.0906\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 1s 129ms/step - loss: 0.1046 - mae: 0.0812 - val_loss: 0.0123 - val_mae: 0.0391\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 8s 439ms/step - loss: 0.2219 - mae: 0.1450 - val_loss: 0.0404 - val_mae: 0.0598\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 128ms/step - loss: 0.1041 - mae: 0.0748 - val_loss: 0.0434 - val_mae: 0.0629\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 128ms/step - loss: 0.1056 - mae: 0.0779 - val_loss: 0.0282 - val_mae: 0.0572\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 138ms/step - loss: 0.0922 - mae: 0.0742 - val_loss: 0.0267 - val_mae: 0.0549\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.0896 - mae: 0.0726 - val_loss: 0.0430 - val_mae: 0.0619\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 142ms/step - loss: 0.0994 - mae: 0.0769 - val_loss: 0.0617 - val_mae: 0.0826\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 1s 141ms/step - loss: 0.0975 - mae: 0.0791 - val_loss: 0.0568 - val_mae: 0.0784\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 1s 136ms/step - loss: 0.1025 - mae: 0.0825 - val_loss: 0.0286 - val_mae: 0.0580\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 1s 148ms/step - loss: 0.0950 - mae: 0.0735 - val_loss: 0.0482 - val_mae: 0.0695\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 7s 440ms/step - loss: 0.1180 - mae: 0.0900 - val_loss: 0.0281 - val_mae: 0.0524\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 136ms/step - loss: 0.1084 - mae: 0.0755 - val_loss: 0.0209 - val_mae: 0.0491\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.1017 - mae: 0.0776 - val_loss: 0.0369 - val_mae: 0.0601\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 127ms/step - loss: 0.1360 - mae: 0.1105 - val_loss: 0.0197 - val_mae: 0.0453\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 1s 128ms/step - loss: 0.1160 - mae: 0.0766 - val_loss: 0.0209 - val_mae: 0.0456\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.0885 - mae: 0.0735 - val_loss: 0.0204 - val_mae: 0.0450\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 1s 126ms/step - loss: 0.0908 - mae: 0.0737 - val_loss: 0.0236 - val_mae: 0.0480\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 1s 127ms/step - loss: 0.0960 - mae: 0.0756 - val_loss: 0.0231 - val_mae: 0.0476\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.0900 - mae: 0.0736 - val_loss: 0.0205 - val_mae: 0.0451\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 8s 429ms/step - loss: 0.1266 - mae: 0.0982 - val_loss: 0.0056 - val_mae: 0.0382\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 127ms/step - loss: 0.1209 - mae: 0.1012 - val_loss: 0.0064 - val_mae: 0.0406\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 0.0931 - mae: 0.0751 - val_loss: 0.2350 - val_mae: 0.1598\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.1186 - mae: 0.0942 - val_loss: 0.0527 - val_mae: 0.0655\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.0995 - mae: 0.0750 - val_loss: 0.0081 - val_mae: 0.0459\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 128ms/step - loss: 0.0874 - mae: 0.0742 - val_loss: 0.0521 - val_mae: 0.0650\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 7s 589ms/step - loss: 0.5365 - mae: 0.2234 - val_loss: 0.0108 - val_mae: 0.0501\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 0.0247 - mae: 0.0538 - val_loss: 0.0131 - val_mae: 0.0564\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 128ms/step - loss: 0.0181 - mae: 0.0479 - val_loss: 0.0242 - val_mae: 0.0684\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.0187 - mae: 0.0483 - val_loss: 0.0158 - val_mae: 0.0628\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.0179 - mae: 0.0470 - val_loss: 0.0148 - val_mae: 0.0606\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.0173 - mae: 0.0469 - val_loss: 0.0473 - val_mae: 0.0713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 7s 437ms/step - loss: 0.2612 - mae: 0.1600 - val_loss: 0.2332 - val_mae: 0.1499\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.1111 - mae: 0.1177 - val_loss: 0.0471 - val_mae: 0.0966\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.0191 - mae: 0.0515 - val_loss: 0.0420 - val_mae: 0.0923\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 127ms/step - loss: 0.0184 - mae: 0.0517 - val_loss: 0.0567 - val_mae: 0.1036\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 127ms/step - loss: 0.0194 - mae: 0.0515 - val_loss: 0.0489 - val_mae: 0.0980\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 0.0178 - mae: 0.0500 - val_loss: 0.0371 - val_mae: 0.0872\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.0179 - mae: 0.0508 - val_loss: 0.1333 - val_mae: 0.1075\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 127ms/step - loss: 0.0193 - mae: 0.0512 - val_loss: 0.0410 - val_mae: 0.0912\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 120ms/step - loss: 0.0189 - mae: 0.0508 - val_loss: 0.0387 - val_mae: 0.0889\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.0178 - mae: 0.0496 - val_loss: 0.0401 - val_mae: 0.0905\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 0.0280 - mae: 0.0597 - val_loss: 0.0390 - val_mae: 0.0893\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 8s 432ms/step - loss: 0.1216 - mae: 0.1199 - val_loss: 0.0565 - val_mae: 0.1058\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 127ms/step - loss: 0.0303 - mae: 0.0577 - val_loss: 0.0585 - val_mae: 0.1155\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 129ms/step - loss: 0.0177 - mae: 0.0483 - val_loss: 0.0544 - val_mae: 0.1090\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.0195 - mae: 0.0524 - val_loss: 0.0588 - val_mae: 0.1158\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 127ms/step - loss: 0.0168 - mae: 0.0482 - val_loss: 0.0666 - val_mae: 0.1254\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 0.0199 - mae: 0.0519 - val_loss: 0.1025 - val_mae: 0.1313\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 1s 131ms/step - loss: 0.0324 - mae: 0.0608 - val_loss: 0.0538 - val_mae: 0.1071\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.0198 - mae: 0.0526 - val_loss: 0.0671 - val_mae: 0.1260\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 1s 128ms/step - loss: 0.0185 - mae: 0.0494 - val_loss: 0.0573 - val_mae: 0.1137\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 127ms/step - loss: 0.0181 - mae: 0.0502 - val_loss: 0.0565 - val_mae: 0.1126\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 1s 129ms/step - loss: 0.0180 - mae: 0.0486 - val_loss: 0.0667 - val_mae: 0.1252\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 1s 127ms/step - loss: 0.0220 - mae: 0.0491 - val_loss: 0.0567 - val_mae: 0.1131\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 7s 439ms/step - loss: 0.1715 - mae: 0.1569 - val_loss: 0.1586 - val_mae: 0.1258\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 139ms/step - loss: 0.0379 - mae: 0.0660 - val_loss: 0.0507 - val_mae: 0.1017\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 125ms/step - loss: 0.0274 - mae: 0.0619 - val_loss: 0.0495 - val_mae: 0.0981\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.0281 - mae: 0.0620 - val_loss: 0.0572 - val_mae: 0.1145\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 0.0338 - mae: 0.0641 - val_loss: 0.0543 - val_mae: 0.1096\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.0280 - mae: 0.0619 - val_loss: 0.0491 - val_mae: 0.0967\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 120ms/step - loss: 0.0247 - mae: 0.0596 - val_loss: 0.0510 - val_mae: 0.0958\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.0324 - mae: 0.0664 - val_loss: 0.0489 - val_mae: 0.0964\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 1s 126ms/step - loss: 0.0257 - mae: 0.0604 - val_loss: 0.0490 - val_mae: 0.0955\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 1s 128ms/step - loss: 0.0254 - mae: 0.0596 - val_loss: 0.0515 - val_mae: 0.0959\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 1s 129ms/step - loss: 0.0251 - mae: 0.0609 - val_loss: 0.0502 - val_mae: 0.0956\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.0329 - mae: 0.0651 - val_loss: 0.0640 - val_mae: 0.1037\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 1s 137ms/step - loss: 0.0265 - mae: 0.0636 - val_loss: 0.0488 - val_mae: 0.0968\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.0243 - mae: 0.0568 - val_loss: 0.0500 - val_mae: 0.0955\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.0243 - mae: 0.0577 - val_loss: 0.0572 - val_mae: 0.0985\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.0251 - mae: 0.0593 - val_loss: 0.1591 - val_mae: 0.1251\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 1s 246ms/step - loss: 0.0380 - mae: 0.0656 - val_loss: 0.0518 - val_mae: 0.1038\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 0.0243 - mae: 0.0589 - val_loss: 0.0542 - val_mae: 0.1094\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 9s 473ms/step - loss: 0.7060 - mae: 0.2948 - val_loss: 0.0932 - val_mae: 0.1140\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 175ms/step - loss: 0.0763 - mae: 0.0997 - val_loss: 0.0783 - val_mae: 0.1022\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 120ms/step - loss: 0.0317 - mae: 0.0741 - val_loss: 0.0481 - val_mae: 0.0762\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 167ms/step - loss: 0.0299 - mae: 0.0708 - val_loss: 0.0628 - val_mae: 0.0900\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 1s 134ms/step - loss: 0.0288 - mae: 0.0693 - val_loss: 0.1055 - val_mae: 0.1240\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 123ms/step - loss: 0.0301 - mae: 0.0712 - val_loss: 0.0915 - val_mae: 0.1129\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 118ms/step - loss: 0.0315 - mae: 0.0723 - val_loss: 0.0535 - val_mae: 0.0812\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 127ms/step - loss: 0.0289 - mae: 0.0703 - val_loss: 0.0876 - val_mae: 0.1104\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 7s 435ms/step - loss: 0.1371 - mae: 0.1474 - val_loss: 0.0561 - val_mae: 0.0780\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.0812 - mae: 0.1068 - val_loss: 0.0908 - val_mae: 0.0979\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 117ms/step - loss: 0.0405 - mae: 0.0779 - val_loss: 0.0478 - val_mae: 0.0778\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.0522 - mae: 0.0822 - val_loss: 0.0764 - val_mae: 0.0880\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 127ms/step - loss: 0.0369 - mae: 0.0773 - val_loss: 0.0608 - val_mae: 0.0788\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 0.0379 - mae: 0.0783 - val_loss: 0.0591 - val_mae: 0.0781\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 0.0379 - mae: 0.0780 - val_loss: 0.0780 - val_mae: 0.0891\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 1s 129ms/step - loss: 0.0358 - mae: 0.0749 - val_loss: 0.1024 - val_mae: 0.1060\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 7s 429ms/step - loss: 0.1693 - mae: 0.1292 - val_loss: 2.4682 - val_mae: 0.5917\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.2989 - mae: 0.2153 - val_loss: 0.2307 - val_mae: 0.1436\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 116ms/step - loss: 0.0350 - mae: 0.0759 - val_loss: 0.1837 - val_mae: 0.1229\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.0339 - mae: 0.0743 - val_loss: 0.0891 - val_mae: 0.1057\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.0458 - mae: 0.0799 - val_loss: 0.3043 - val_mae: 0.1748\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.0379 - mae: 0.0788 - val_loss: 0.1670 - val_mae: 0.1165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 120ms/step - loss: 0.0332 - mae: 0.0741 - val_loss: 0.2719 - val_mae: 0.1594\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 120ms/step - loss: 0.0343 - mae: 0.0759 - val_loss: 0.1161 - val_mae: 0.1084\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 0.0327 - mae: 0.0760 - val_loss: 0.1917 - val_mae: 0.1293\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 7s 430ms/step - loss: 0.2538 - mae: 0.1538 - val_loss: 0.3317 - val_mae: 0.2004\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.3390 - mae: 0.1801 - val_loss: 0.0767 - val_mae: 0.0781\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.0586 - mae: 0.0941 - val_loss: 0.0959 - val_mae: 0.0916\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 119ms/step - loss: 0.0629 - mae: 0.0922 - val_loss: 0.0362 - val_mae: 0.0657\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.0701 - mae: 0.0952 - val_loss: 0.0658 - val_mae: 0.0704\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 128ms/step - loss: 0.0581 - mae: 0.0905 - val_loss: 0.0752 - val_mae: 0.0767\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 1s 128ms/step - loss: 0.0595 - mae: 0.0902 - val_loss: 0.0693 - val_mae: 0.0730\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.0641 - mae: 0.0918 - val_loss: 0.1165 - val_mae: 0.1045\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.0791 - mae: 0.0982 - val_loss: 0.0705 - val_mae: 0.0739\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 7s 425ms/step - loss: 0.3087 - mae: 0.2072 - val_loss: 0.0547 - val_mae: 0.0822\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 124ms/step - loss: 0.0771 - mae: 0.0988 - val_loss: 0.0644 - val_mae: 0.0824\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.0787 - mae: 0.0994 - val_loss: 0.0547 - val_mae: 0.0821\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.0773 - mae: 0.0994 - val_loss: 0.0551 - val_mae: 0.0840\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.0737 - mae: 0.0965 - val_loss: 0.1519 - val_mae: 0.1382\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.1272 - mae: 0.1208 - val_loss: 0.0828 - val_mae: 0.1027\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m RnnDlModel_test(epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mcv_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mApiCall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_local\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m read_result()\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/code/AlexandreLaizet/bitcoin_deep_learning/bitcoin_deep_learning/trainer.py:66\u001b[0m, in \u001b[0;36mcv_train\u001b[0;34m(model, df, metric, save, precision, with_trader)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# Append a new line with current CV results\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_path , \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m, newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m csvfile:\n\u001b[1;32m     64\u001b[0m     (roi_hodler, roi_trader, roi_whale, roi_hodler_whale, roi_charles,\n\u001b[1;32m     65\u001b[0m      sharpe_hodler, sharpe_trader, sharpe_whale, sharpe_hodler_whale,\n\u001b[0;32m---> 66\u001b[0m      sharpe_charles) \u001b[38;5;241m=\u001b[39m \u001b[43miterate_cross_val_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m     writer \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mDictWriter(csvfile, fieldnames\u001b[38;5;241m=\u001b[39mfieldnames)\n\u001b[1;32m     69\u001b[0m     writer\u001b[38;5;241m.\u001b[39mwriterow({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m:model\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfold_score\u001b[39m\u001b[38;5;124m\"\u001b[39m:fold_score,\n\u001b[1;32m     70\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean_score\u001b[39m\u001b[38;5;124m\"\u001b[39m:score,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin_score\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;28mmin\u001b[39m(fold_score),\n\u001b[1;32m     71\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_score\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;28mmax\u001b[39m(fold_score),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     82\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroi_charles\u001b[39m\u001b[38;5;124m\"\u001b[39m: roi_charles,\n\u001b[1;32m     83\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msharpe_charles\u001b[39m\u001b[38;5;124m\"\u001b[39m:sharpe_charles})\n",
      "File \u001b[0;32m~/code/AlexandreLaizet/bitcoin_deep_learning/bitcoin_deep_learning/metrics.py:711\u001b[0m, in \u001b[0;36miterate_cross_val_results\u001b[0;34m(model, df)\u001b[0m\n\u001b[1;32m    708\u001b[0m y_true, y_pred \u001b[38;5;241m=\u001b[39m reality, prediction\n\u001b[1;32m    710\u001b[0m roi_hodler\u001b[38;5;241m.\u001b[39mappend(compute_roi(play_hodler_strategy(y_true, y_pred)))\n\u001b[0;32m--> 711\u001b[0m roi_trader\u001b[38;5;241m.\u001b[39mappend(compute_roi(\u001b[43mplay_trader_strategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[1;32m    712\u001b[0m roi_whale\u001b[38;5;241m.\u001b[39mappend(compute_roi(play_whale_strategy(y_true, y_pred)))\n\u001b[1;32m    713\u001b[0m roi_hodler_whale\u001b[38;5;241m.\u001b[39mappend(compute_roi(play_hodler_whale_strategy(y_true, y_pred)))\n",
      "File \u001b[0;32m~/code/AlexandreLaizet/bitcoin_deep_learning/bitcoin_deep_learning/metrics.py:188\u001b[0m, in \u001b[0;36mplay_trader_strategy\u001b[0;34m(y_true, y_pred, total_investment, investment_horizon, buy_threshold, sell_threshold, exchange_fee, tax_rate)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(y_true):\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mlist\u001b[39m(y_pred)) \u001b[38;5;241m>\u001b[39m counter \u001b[38;5;241m+\u001b[39m investment_horizon:\n\u001b[0;32m--> 188\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlist\u001b[39m(y_pred)[counter \u001b[38;5;241m+\u001b[39m investment_horizon] \u001b[38;5;241m/\u001b[39m value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m>\u001b[39m buy_threshold:\n\u001b[1;32m    189\u001b[0m         \u001b[38;5;66;03m#if list(y_pred)[counter + investment_horizon] > buy_threshold:\u001b[39;00m\n\u001b[1;32m    191\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m usd_balance \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    193\u001b[0m                 investment \u001b[38;5;241m=\u001b[39m usd_balance \u001b[38;5;241m-\u001b[39m (usd_balance \u001b[38;5;241m*\u001b[39m exchange_fee)\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "model = RnnDlModel_test(epochs=20, patience=5)\n",
    "cv_train(model,ApiCall().read_local(data=\"train\"))\n",
    "read_result().sort_values(by=\"date\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442d27ba",
   "metadata": {},
   "source": [
    "# Test last 3 months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b609a707",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bitcoin_deep_learning.cross_val import cross_val_trade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7d10ed2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1408, 32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexandrelaizet/.pyenv/versions/3.8.12/envs/bitcoin/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.908e+00, tolerance: 1.509e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1408, 32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexandrelaizet/.pyenv/versions/3.8.12/envs/bitcoin/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.908e+00, tolerance: 1.509e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[47262.237443   49354.08716868 50118.92095928 46762.48252806\n",
      " 48413.70564739 48819.84934723 47695.2803949  46326.9195957\n",
      " 46962.91334059 46791.89605595 46853.71063455 48957.19391098\n",
      " 48646.43337567 50770.61418965 50864.32895235 50649.92614866\n",
      " 50806.44217533 50610.95680294 47669.74037208 46407.59548964\n",
      " 47188.32055009 46328.94313809 47620.42381093 47344.84340974\n",
      " 46467.61579525 45926.76178657 43589.35568307 43154.45522485\n",
      " 41564.23901044 41744.05783199 41910.51226779 41820.01786922\n",
      " 42721.69548372 43935.64398491 42596.12337644 43101.33599626\n",
      " 43198.86986181 43122.78741443 42235.1848487  42372.5532734\n",
      " 41731.94792084 40706.93154832 36440.2657686  35036.9447362\n",
      " 36254.87985724 36656.19382217 36946.23828322 36851.36987997\n",
      " 37148.32227909 37789.47882002 38137.47269687 37936.32877744\n",
      " 38455.68966346 38784.50229871 36924.10239442 37018.58700268\n",
      " 41516.07281916 41421.47643291 42411.10429027 43921.96437825\n",
      " 44110.31669061 44347.12092966 43548.07188871 42407.68766215\n",
      " 42198.7514316  42242.10014713 42601.71507212 44600.78417382\n",
      " 43980.51455924 40548.83984707 40031.59053806 40127.36921663\n",
      " 38460.39121722 37012.56063945 38314.64973454 37311.62561222\n",
      " 38305.92776288 39216.70043785 39048.12227488 37721.43341561\n",
      " 43204.6016303  44348.19642695 43936.40971009 42459.60376591\n",
      " 39146.8844694  39416.46268754 38423.61893606 38018.64950493\n",
      " 38726.30210219 41977.38346187]\n",
      "(1408, 32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexandrelaizet/.pyenv/versions/3.8.12/envs/bitcoin/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.683e+00, tolerance: 1.509e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[47262.237443   49354.08716868 50118.92095928 46762.48252806\n",
      " 48413.70564739 48819.84934723 47695.2803949  46326.9195957\n",
      " 46962.91334059 46791.89605595 46853.71063455 48957.19391098\n",
      " 48646.43337567 50770.61418965 50864.32895235 50649.92614866\n",
      " 50806.44217533 50610.95680294 47669.74037208 46407.59548964\n",
      " 47188.32055009 46328.94313809 47620.42381093 47344.84340974\n",
      " 46467.61579525 45926.76178657 43589.35568307 43154.45522485\n",
      " 41564.23901044 41744.05783199 41910.51226779 41820.01786922\n",
      " 42721.69548372 43935.64398491 42596.12337644 43101.33599626\n",
      " 43198.86986181 43122.78741443 42235.1848487  42372.5532734\n",
      " 41731.94792084 40706.93154832 36440.2657686  35036.9447362\n",
      " 36254.87985724 36656.19382217 36946.23828322 36851.36987997\n",
      " 37148.32227909 37789.47882002 38137.47269687 37936.32877744\n",
      " 38455.68966346 38784.50229871 36924.10239442 37018.58700268\n",
      " 41516.07281916 41421.47643291 42411.10429027 43921.96437825\n",
      " 44110.31669061 44347.12092966 43548.07188871 42407.68766215\n",
      " 42198.7514316  42242.10014713 42601.71507212 44600.78417382\n",
      " 43980.51455924 40548.83984707 40031.59053806 40127.36921663\n",
      " 38460.39121722 37012.56063945 38314.64973454 37311.62561222\n",
      " 38305.92776288 39216.70043785 39048.12227488 37721.43341561\n",
      " 43204.6016303  44348.19642695 43936.40971009 42459.60376591\n",
      " 39146.8844694  39416.46268754 38423.61893606 38018.64950493\n",
      " 38726.30210219 41977.38346187]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = LinearRegressionBaselineModel()\n",
    "df = ApiCall().read_local(data=\"all\")\n",
    "\n",
    "Y_true_past, Y_true, Y_test, Y_pred = cross_val_trade(model,df,cv=False,verbose=True)\n",
    "positions = iterate_portfolio_positions(model, df = df, cv=False,verbose=True)\n",
    "plot_portolio_positions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7af20ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1408, 32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexandrelaizet/.pyenv/versions/3.8.12/envs/bitcoin/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.908e+00, tolerance: 1.509e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1557fa670>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = LinearRegressionBaselineModel()\n",
    "df = ApiCall().read_local(data=\"all\")\n",
    "Y_true_past, Y_true, Y_test, Y_pred = cross_val_trade(model,df,cv=False,verbose=True)\n",
    "fig,axs = plt.subplots(2,1)\n",
    "axs[0].plot(Y_test)\n",
    "\n",
    "axs[0].plot(Y_pred, c= \"r\")\n",
    "plt.show\n",
    "#axs[1].plot(Y_true)\n",
    "axs[1].plot(Y_true_past + Y_true_past* Y_pred, c= \"r\")\n",
    "axs[1].plot(Y_true_past + Y_true_past* Y_test, c= \"b\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "621bb7f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.06770293911664738"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "40ecc81a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43936.409710091975 -0.09294297210022895 39852.82920822267\n"
     ]
    }
   ],
   "source": [
    "index = 89\n",
    "print(Y_true_past[index],Y_pred[index],Y_true_past[index] + Y_true_past[index]* Y_pred[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29b0d55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
