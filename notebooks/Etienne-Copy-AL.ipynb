{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86a7b326",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T10:20:38.601435Z",
     "start_time": "2022-03-10T10:20:27.408185Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import requests \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys; sys.path\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from datetime import datetime\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from bitcoin_deep_learning.call_api import ApiCall\n",
    "from bitcoin_deep_learning.model import LinearRegressionBaselineModel, RnnDlModel,RandomForestReg, DummyModel, RnnDlModel_test\n",
    "from bitcoin_deep_learning.trainer import cv_train, read_result\n",
    "from bitcoin_deep_learning.cross_val import cross_val, get_cross_XY, cross_val_trade\n",
    "api = ApiCall()\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67db4bac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T10:44:17.163064Z",
     "start_time": "2022-03-10T10:44:16.211055Z"
    }
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "train_df= ApiCall().read_local()\n",
    "for i in range(1,len(list(train_df.columns))-1):\n",
    "    train_df[list(train_df.columns)[i]] = scaler.fit_transform(np.array(train_df[train_df.columns[1]]).reshape(-1, 1))\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab32b96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T10:30:29.239356Z",
     "start_time": "2022-03-10T10:30:14.646435Z"
    }
   },
   "outputs": [],
   "source": [
    "model = RandomForestReg()\n",
    "cv_train(model,train_df)\n",
    "read_result().sort_values(by=\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1050ccf2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T11:44:34.629111Z",
     "start_time": "2022-03-10T11:44:34.606586Z"
    }
   },
   "outputs": [],
   "source": [
    "\"yolo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ef4a70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T11:18:40.522116Z",
     "start_time": "2022-03-10T11:01:30.760235Z"
    }
   },
   "outputs": [],
   "source": [
    "for n_estimators in [100,500,700,1000,1500,3000]:\n",
    "    for warm_start in  [True,False]:\n",
    "        for bootstrap in [True,False]:\n",
    "            for criterion in [\"squared_error\", \"absolute_error\", \"poisson\"]:\n",
    "                for min_samples_leaf in [1,5,10,20]:\n",
    "                    model = RandomForestReg(warm_start=warm_start,\n",
    "                                            n_estimators=n_estimators,\n",
    "                                           bootstrap=bootstrap,\n",
    "                                           criterion=criterion,\n",
    "                                           min_samples_leaf=min_samples_leaf)\n",
    "\n",
    "                    cv_train(model,train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3616cc2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T10:27:39.434122Z",
     "start_time": "2022-03-10T10:27:39.434082Z"
    }
   },
   "outputs": [],
   "source": [
    "X0 = [[i+5,-2*i]for i in range(1001)]\n",
    "X1 = np.sin(np.arange(1001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638826b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T16:59:21.879685Z",
     "start_time": "2022-03-09T16:59:21.742616Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(X0)\n",
    "df[\"date\"] = X1\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be498d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T16:59:23.604949Z",
     "start_time": "2022-03-09T16:59:22.410190Z"
    }
   },
   "outputs": [],
   "source": [
    "model = LinearRegressionBaselineModel()\n",
    "#model = RnnDlModel(epochs=10,patience=2)\n",
    "past_reality, reality,reality_diff, prediction_diff = cross_val_trade(model,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661fbc00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T16:59:23.796539Z",
     "start_time": "2022-03-09T16:59:23.617223Z"
    }
   },
   "outputs": [],
   "source": [
    "past_reality[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a71cbc9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T16:59:24.300710Z",
     "start_time": "2022-03-09T16:59:23.806693Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(reality[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59aa718",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T16:59:25.305410Z",
     "start_time": "2022-03-09T16:59:24.977799Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(prediction_diff[0],c=\"r\")\n",
    "plt.plot(reality_diff[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f3a3d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T16:59:29.429191Z",
     "start_time": "2022-03-09T16:59:27.980345Z"
    }
   },
   "outputs": [],
   "source": [
    "model = LinearRegressionBaselineModel()\n",
    "#model = RnnDlModel(epochs=10,patience=2)\n",
    "past_reality, reality,reality_diff, prediction_diff = cross_val_trade(model,df)\n",
    "plt.plot(prediction_diff[0],c=\"r\")\n",
    "plt.plot(reality_diff[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3603a08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T16:52:39.686158Z",
     "start_time": "2022-03-09T16:52:39.543063Z"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cc3bed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T16:54:14.625068Z",
     "start_time": "2022-03-09T16:54:13.512900Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_list, Y_train_list, X_test_list,Y_test_list = get_cross_XY(df.drop(columns=\"date\"),data=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad51d86c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T16:54:14.762448Z",
     "start_time": "2022-03-09T16:54:14.632659Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, Y_train, X_test,Y_test = X_train_list[0], Y_train_list[0], X_test_list[0],Y_test_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b1c728",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T16:54:42.591675Z",
     "start_time": "2022-03-09T16:54:42.461813Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "scaler = StandardScaler()\n",
    "#X_train_scaled =  scaler.fit_transform(X_train[:,-1,:])\n",
    "#X_test_scaled = scaler.transform(X_test[:,-1,:])\n",
    "X_train_scaled =  (X_train[:,-1,:])\n",
    "X_test_scaled = (X_test[:,-1,:])\n",
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0e31f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T16:54:43.329373Z",
     "start_time": "2022-03-09T16:54:42.981451Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "model = ElasticNet()\n",
    "model.fit(X_train_scaled,Y_train)\n",
    "Y_pred = model.predict(X_test_scaled)\n",
    "plt.plot(Y_pred)\n",
    "plt.plot(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254814c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T16:54:15.529568Z",
     "start_time": "2022-03-09T16:54:15.350092Z"
    }
   },
   "outputs": [],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a73db8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T16:54:15.713904Z",
     "start_time": "2022-03-09T16:54:15.542868Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train[:,-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6298ed9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T15:39:33.674825Z",
     "start_time": "2022-03-09T15:39:33.537909Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train[:,-1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ca6d99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T14:54:05.248499Z",
     "start_time": "2022-03-09T14:54:05.021024Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0fa236",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T15:39:33.832071Z",
     "start_time": "2022-03-09T15:39:33.688143Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train[:,-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d98795d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T15:44:53.023640Z",
     "start_time": "2022-03-09T15:44:45.930468Z"
    }
   },
   "outputs": [],
   "source": [
    "model = LinearRegressionBaselineModel(alpha=0.1,l1_ratio=0.001)\n",
    "df = ApiCall().read_local()\n",
    "X_train_list, Y_train_list, X_test_list,Y_test_list = get_cross_XY(df,data=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffce926",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T15:45:07.391989Z",
     "start_time": "2022-03-09T15:44:58.984581Z"
    }
   },
   "outputs": [],
   "source": [
    "cross_val_trade(model,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454232ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T15:47:30.179538Z",
     "start_time": "2022-03-09T15:47:26.175042Z"
    }
   },
   "outputs": [],
   "source": [
    "past_reality, reality,reality_diff, prediction_diff = cross_val_trade(model,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5d9b8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T16:28:26.745583Z",
     "start_time": "2022-03-09T16:28:26.561663Z"
    }
   },
   "outputs": [],
   "source": [
    "ct = 0\n",
    "preds = []\n",
    "computed_reality = []\n",
    "for past_prices, diffs in zip(past_reality,prediction_diff):\n",
    "    preds.append(past_prices * diffs+ past_prices)\n",
    "preds  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcb48e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T17:03:14.025454Z",
     "start_time": "2022-03-09T17:03:13.903822Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a42f71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T17:03:05.746462Z",
     "start_time": "2022-03-09T17:03:05.610887Z"
    }
   },
   "outputs": [],
   "source": [
    "df = api.read_local()\n",
    "scaler = MinMaxScaler()\n",
    "#df  =scaler.fit_transform(df.drop(columns=\"date\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33afb8e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T17:05:18.570310Z",
     "start_time": "2022-03-09T17:05:18.439994Z"
    }
   },
   "outputs": [],
   "source": [
    "df[df.columns[1]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9652d735",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T17:05:55.466306Z",
     "start_time": "2022-03-09T17:05:55.336089Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8616a701",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T17:08:48.818805Z",
     "start_time": "2022-03-09T17:08:48.656506Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360c1fe3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T17:08:49.756169Z",
     "start_time": "2022-03-09T17:08:49.535475Z"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7fa4f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T17:14:27.791406Z",
     "start_time": "2022-03-09T17:14:23.473082Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df = api.read_local()\n",
    "scaler = MinMaxScaler()\n",
    "for i in range(1,len(list(df.columns))):\n",
    "    df[list(df.columns)[i]] = scaler.fit_transform(np.array(df[df.columns[1]]).reshape(-1, 1))\n",
    "\n",
    "model = LinearRegressionBaselineModel(alpha=0.5,l1_ratio=0.001)\n",
    "#model = RnnDlModel(epochs=10,patience=2)\n",
    "past_reality, reality,reality_diff, prediction_diff = cross_val_trade(model,df)\n",
    "for i in range(10):\n",
    "    plt.plot(prediction_diff[i],c=\"r\")\n",
    "    plt.plot(reality_diff[i])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3accc8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T17:14:28.010131Z",
     "start_time": "2022-03-09T17:14:27.798627Z"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8e1678",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T17:14:30.525658Z",
     "start_time": "2022-03-09T17:14:28.024636Z"
    }
   },
   "outputs": [],
   "source": [
    "fold_score, score= train(model,df)\n",
    "print(fold_score,score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613ccd8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T17:23:46.544656Z",
     "start_time": "2022-03-09T17:19:17.670903Z"
    }
   },
   "outputs": [],
   "source": [
    "for counter in range(20):\n",
    "    alpha = 0.015 * random.random()\n",
    "    l1 = random.random()*0.01\n",
    "    # Instanciate model\n",
    "    regression_model = LinearRegressionBaselineModel(alpha = alpha, l1_ratio = l1)\n",
    "    # Train and Fit data using the crossval\n",
    "    val_score, score = train(regression_model,df);\n",
    "    print(val_score,score)\n",
    "    past_reality, reality,reality_diff, prediction_diff = cross_val_trade(model,df)\n",
    "    for i in range(len(reality)):\n",
    "        plt.plot(prediction_diff[i],c=\"r\")\n",
    "        plt.plot(reality_diff[i])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99cef92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T17:23:46.730289Z",
     "start_time": "2022-03-09T17:23:46.561158Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from bitcoin_deep_learning.trainer import read_result\n",
    "read_result().sort_values(by=\"date\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a626c8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T17:52:26.052552Z",
     "start_time": "2022-03-09T17:36:07.704082Z"
    }
   },
   "outputs": [],
   "source": [
    "df = api.read_local()\n",
    "scaler = MinMaxScaler()\n",
    "for i in range(1,len(list(df.columns))-1):\n",
    "    df[list(df.columns)[i]] = scaler.fit_transform(np.array(df[df.columns[1]]).reshape(-1, 1))\n",
    "\n",
    "model = LinearRegressionBaselineModel(alpha=0.5,l1_ratio=0.001)\n",
    "#model = RnnDlModel(epochs=10,patience=2)\n",
    "past_reality, reality,reality_diff, prediction_diff = cross_val_trade(model,df)\n",
    "ALPHA = [0.001,0.005,0.01,0.1,5,1,10,100]\n",
    "L1 = [0.0001,0.0005,0.001,0.005,0.001,0.005,0.01,0.1,0.5,1]\n",
    "for alpha in ALPHA :\n",
    "    for l1 in L1 : \n",
    "        # Instanciate model\n",
    "        regression_model = LinearRegressionBaselineModel(alpha = alpha, l1_ratio = l1)\n",
    "        # Train and Fit data using the crossval\n",
    "        val_score, score = train(regression_model,df);\n",
    "        print(val_score,score)\n",
    "        past_reality, reality,reality_diff, prediction_diff = cross_val_trade(model,df)\n",
    "        for i in range(len(reality)):\n",
    "            plt.plot(prediction_diff[i],c=\"r\")\n",
    "            plt.plot(reality_diff[i])\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f11863",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T17:52:26.245981Z",
     "start_time": "2022-03-09T17:52:26.065419Z"
    }
   },
   "outputs": [],
   "source": [
    "read_result().sort_values(by=\"date\",ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8690ed32",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-03-09T18:31:31.901Z"
    }
   },
   "outputs": [],
   "source": [
    "df = api.read_local()\n",
    "scaler = MinMaxScaler()\n",
    "for i in range(1,len(list(df.columns))):\n",
    "    df[list(df.columns)[i]] = scaler.fit_transform(np.array(df[df.columns[1]]).reshape(-1, 1))\n",
    "\n",
    "model = LinearRegressionBaselineModel(alpha=0.5,l1_ratio=0.001)\n",
    "#model = RnnDlModel(epochs=10,patience=2)\n",
    "past_reality, reality,reality_diff, prediction_diff = cross_val_trade(model,df)\n",
    "ALPHA = [0.001,0.005,0.01,0.1,5,1,10,100]\n",
    "L1 = [0.0001,0.0005,0.001,0.005,0.001,0.005,0.01,0.1,0.5,1]\n",
    "for alpha in ALPHA :\n",
    "    for l1 in L1 : \n",
    "        # Instanciate model\n",
    "        regression_model = LinearRegressionBaselineModel(alpha = alpha, l1_ratio = l1)\n",
    "        # Train and Fit data using the crossval\n",
    "        val_score, score = train(regression_model,df);\n",
    "        print(val_score,score)\n",
    "        past_reality, reality,reality_diff, prediction_diff = cross_val_trade(model,df)\n",
    "        for i in range(len(reality)):\n",
    "            plt.plot(reality[i])\n",
    "            plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf83a68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T18:34:24.142241Z",
     "start_time": "2022-03-09T18:34:24.013993Z"
    }
   },
   "outputs": [],
   "source": [
    "x = np.eye(260,3,31)\n",
    "x.reshape(260,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06390c76",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T18:29:04.773254Z",
     "start_time": "2022-03-09T18:28:59.474360Z"
    }
   },
   "outputs": [],
   "source": [
    "read_result().sort_values(by=\"mean_score\",ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c1510c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T08:46:55.653991Z",
     "start_time": "2022-03-10T08:46:55.513440Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "def train(model,\n",
    "          df,\n",
    "          save:bool=True,\n",
    "          precision:int=5\n",
    "          ):\n",
    "    reality,prediction = cross_val(model,df)\n",
    "    fold_score = [round(mean_absolute_error(Y_true,Y_pred),precision)\n",
    "                            for Y_true,Y_pred in zip(reality,prediction)]\n",
    "    score =round(np.mean(np.array(fold_score)),precision)\n",
    "    # Option to save results\n",
    "    if save == True :\n",
    "        file_path = os.path.join(ROOT_DIR,\n",
    "                                        \"cross_val_data\",\n",
    "                                        'test.csv')\n",
    "        # Check if file is there and create it otherwise\n",
    "        if not os.path.isfile(file_path):\n",
    "            fieldnames = [\"name\",'fold_score',\"mean_score\",\"min_score\",\"max_score\",'hyperparams','date']\n",
    "            pd.DataFrame(columns=fieldnames).to_csv(file_path,index=False)\n",
    "        # Append a new line with current CV results\n",
    "        with open(file_path , 'a', newline='') as csvfile:\n",
    "            fieldnames = [\"name\",'fold_score',\"mean_score\",\"min_score\",\"max_score\",'hyperparams','date']\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "            writer.writerow({\"name\":model.name, \"fold_score\":fold_score,\n",
    "                            \"mean_score\":score,\"min_score\":min(fold_score),\n",
    "                            \"max_score\":max(fold_score),\n",
    "                            \"hyperparams\":model.hyperparams,\n",
    "                            'date':datetime.now().strftime(\"%d-%m %H:%M:%S\")})\n",
    "            print(\"Training done\")\n",
    "        return fold_score, score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be304499",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T08:46:56.167435Z",
     "start_time": "2022-03-10T08:46:56.011474Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = ApiCall().read_local()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c1e567",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T09:10:57.769630Z",
     "start_time": "2022-03-10T09:10:57.618451Z"
    }
   },
   "outputs": [],
   "source": [
    "read_result(file=\"CV_trader.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01e5590",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T08:47:34.381188Z",
     "start_time": "2022-03-10T08:47:30.526438Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "model = LinearRegressionBaselineModel()\n",
    "train(model,train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6afa5c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T09:14:33.839416Z",
     "start_time": "2022-03-10T09:14:33.690768Z"
    }
   },
   "outputs": [],
   "source": [
    "ROOT_DIR = \"/Users/Zalo/code/AlexandreLaizet/bitcoin_deep_learning\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d920d59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T09:15:44.039668Z",
     "start_time": "2022-03-10T09:15:43.881272Z"
    }
   },
   "outputs": [],
   "source": [
    "file_path = os.path.join(ROOT_DIR,\n",
    "                        \"cross_val_data\",\n",
    "                        'CV_trader.csv')\n",
    "fieldnames = [\"name\",'fold_score',\"mean_score\",\"min_score\",\"max_score\",'hyperparams','date',\n",
    "             \"roi_hodler\", \"sharpe_hodler\", \"roi_trader\", \"sharpe_trader\",\"roi_whale\", \"sharpe_whale\",\n",
    "              \"roi_hodler_whale\",  \"sharpe_hodler_whale\", \"roi_charles\", \n",
    "                \"sharpe_charles\"]\n",
    "pd.DataFrame(columns=fieldnames).to_csv(file_path,index=False)\n",
    "read_result(file=\"CV_trader.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a0a6ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T08:56:00.298685Z",
     "start_time": "2022-03-10T08:55:55.872938Z"
    }
   },
   "outputs": [],
   "source": [
    "from bitcoin_deep_learning.metrics import iterate_cross_val_results\n",
    "iterate_cross_val_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904352b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T08:58:25.380019Z",
     "start_time": "2022-03-10T08:58:20.477232Z"
    }
   },
   "outputs": [],
   "source": [
    "roi_hodler, roi_trader, roi_whale, roi_hodler_whale, roi_charles, sharpe_hodler, sharpe_trader, sharpe_whale, sharpe_hodler_whale, sharpe_charles = iterate_cross_val_results()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f8a684",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_path , 'a', newline='') as csvfile:\n",
    "            #fieldnames = [\"name\",'fold_score',\"mean_score\",\"min_score\",\"max_score\",'hyperparams','date']\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "            writer.writerow({\"name\":model.name, \"fold_score\":fold_score,\n",
    "                            \"mean_score\":score,\"min_score\":min(fold_score),\n",
    "                            \"max_score\":max(fold_score),\n",
    "                            \"hyperparams\":model.hyperparams,\n",
    "                            'date':datetime.now().strftime(\"%d-%m %H:%M:%S\"),\n",
    "                            \"roi_hodler\":roi_hodler\n",
    "                            \"sharpe_hodler\": sharpe_hodler\n",
    "                            \"roi_trader\": roi_trader\n",
    "                            \"sharpe_trader\": sharpe_trader\n",
    "                            \"roi_whale\": roi_whale\n",
    "                            \"sharpe_whale\": sharpe_whale\n",
    "                            \"roi_hodler_whale\": roi_hodler_whale\n",
    "                            \"sharpe_hodler_whale\": sharpe_hodler_whale\n",
    "                            \"roi_charles\": roi_charles\n",
    "                            \"sharpe_charles\":sharpe_charles})\n",
    "            print(\"Training done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c339f31b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T10:03:05.174992Z",
     "start_time": "2022-03-10T10:03:05.031502Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df= ApiCall().read_local()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf7529a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T10:03:32.173858Z",
     "start_time": "2022-03-10T10:03:31.982100Z"
    }
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "train_df= ApiCall().read_local()\n",
    "for i in range(1,len(list(train_df.columns))-1):\n",
    "    train_df[list(train_df.columns)[i]] = scaler.fit_transform(np.array(train_df[train_df.columns[1]]).reshape(-1, 1))\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf31bc7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T10:03:36.052997Z",
     "start_time": "2022-03-10T10:03:33.990322Z"
    }
   },
   "outputs": [],
   "source": [
    "for warm_start in  [True,False]:\n",
    "    for max_features in [\"auto\", \"sqrt\", \"log2\"]:\n",
    "        for bootstrap in [True,False]:\n",
    "            for criterion in [\"squared_error\", \"absolute_error\", \"poisson\"]:\n",
    "                    for max_depht in [None,True]:\n",
    "                        if max_depht :\n",
    "                            max_depht = np.random.randint(1,1000)\n",
    "                        print(\"oui\")\n",
    "                        min_samples_split = random.randint(2,100)\n",
    "                        min_samples_leaf = random.randint(2,100)\n",
    "                        model = RandomForestReg(warm_start=warm_start,\n",
    "                                               max_features=max_features,\n",
    "                                               bootstrap=bootstrap,\n",
    "                                               criterion=criterion,\n",
    "                                               max_depht=max_depht,\n",
    "                                               min_samples_split=min_samples_split,\n",
    "                                               min_samples_leaf=min_samples_leaf)\n",
    "\n",
    "                        cv_train(model,train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a195f794",
   "metadata": {},
   "source": [
    "# Dummy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b576df85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [00:02<00:00, 13.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.23901045179407965, 0.3477205291545489, 0.33400412784029365, 0.32553008918894033, -0.005360588130910227, -0.38389642791425205, -0.3141090385585297, -0.30868398804863684, -0.2126595928196786, -0.060139076467191965, 0.16689361278589554, -0.3036397556129774, -0.34790184987238437, 0.24942335583166275, 0.2076396206086819, 0.1080712096662022, 0.09101817200523654, 0.059394731120385735, 0.023539343735346607, 0.3021824268229776, 0.39415030197918854, 0.2890920102664558, 0.3651169244895911, 0.37344415648179985, 0.35332358768821837, -0.14638556686848347, -0.3547472325526173, -0.48224192315571035, 0.12942813901731598, 0.14667686299033966, 0.32234273596290053, 0.19428169383617955]\n",
      "Training with trader done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>fold_score</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>min_score</th>\n",
       "      <th>max_score</th>\n",
       "      <th>hyperparams</th>\n",
       "      <th>date</th>\n",
       "      <th>roi_hodler</th>\n",
       "      <th>sharpe_hodler</th>\n",
       "      <th>roi_trader</th>\n",
       "      <th>sharpe_trader</th>\n",
       "      <th>roi_whale</th>\n",
       "      <th>sharpe_whale</th>\n",
       "      <th>roi_hodler_whale</th>\n",
       "      <th>sharpe_hodler_whale</th>\n",
       "      <th>roi_charles</th>\n",
       "      <th>sharpe_charles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dummy</td>\n",
       "      <td>[0.06752, 0.08603, 0.11788, 0.13216, 0.14218, ...</td>\n",
       "      <td>0.11057</td>\n",
       "      <td>0.05455</td>\n",
       "      <td>0.19172</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10-03 15:53:23</td>\n",
       "      <td>0.076063</td>\n",
       "      <td>2.692379</td>\n",
       "      <td>0.053090</td>\n",
       "      <td>0.637716</td>\n",
       "      <td>0.055913</td>\n",
       "      <td>0.458252</td>\n",
       "      <td>0.056260</td>\n",
       "      <td>0.510347</td>\n",
       "      <td>0.065704</td>\n",
       "      <td>1.186462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.20636, 0.26691, 0.91792, 0.5793, 0.12272, 0...</td>\n",
       "      <td>0.62972</td>\n",
       "      <td>0.07553</td>\n",
       "      <td>2.95176</td>\n",
       "      <td>{'alpha': 0.05, 'l1_ratio': 0.0001}</td>\n",
       "      <td>10-03 15:50:33</td>\n",
       "      <td>0.076063</td>\n",
       "      <td>2.692379</td>\n",
       "      <td>0.034135</td>\n",
       "      <td>1.414102</td>\n",
       "      <td>0.025962</td>\n",
       "      <td>1.131473</td>\n",
       "      <td>0.044834</td>\n",
       "      <td>0.932677</td>\n",
       "      <td>0.054169</td>\n",
       "      <td>1.510994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.20636, 0.26691, 0.91792, 0.5793, 0.12272, 0...</td>\n",
       "      <td>0.62972</td>\n",
       "      <td>0.07553</td>\n",
       "      <td>2.95176</td>\n",
       "      <td>{'alpha': 0.05, 'l1_ratio': 0.0001}</td>\n",
       "      <td>10-03 15:45:20</td>\n",
       "      <td>0.076063</td>\n",
       "      <td>2.692379</td>\n",
       "      <td>0.034135</td>\n",
       "      <td>1.414102</td>\n",
       "      <td>0.025962</td>\n",
       "      <td>1.131473</td>\n",
       "      <td>0.044834</td>\n",
       "      <td>0.932677</td>\n",
       "      <td>0.054169</td>\n",
       "      <td>1.510994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.13652, 0.3541, 0.89001, 0.09658, 0.24001, 0...</td>\n",
       "      <td>0.39088</td>\n",
       "      <td>0.07920</td>\n",
       "      <td>1.68089</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.5}</td>\n",
       "      <td>10-03 15:42:00</td>\n",
       "      <td>0.076063</td>\n",
       "      <td>2.692379</td>\n",
       "      <td>0.004387</td>\n",
       "      <td>0.530331</td>\n",
       "      <td>-0.012604</td>\n",
       "      <td>-0.949174</td>\n",
       "      <td>-0.012604</td>\n",
       "      <td>-0.949174</td>\n",
       "      <td>0.023209</td>\n",
       "      <td>0.649548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.13652, 0.3541, 0.89001, 0.09658, 0.24001, 0...</td>\n",
       "      <td>0.39088</td>\n",
       "      <td>0.07920</td>\n",
       "      <td>1.68089</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.5}</td>\n",
       "      <td>10-03 15:41:40</td>\n",
       "      <td>0.076063</td>\n",
       "      <td>2.692379</td>\n",
       "      <td>0.004387</td>\n",
       "      <td>0.530331</td>\n",
       "      <td>-0.012604</td>\n",
       "      <td>-0.949174</td>\n",
       "      <td>-0.012604</td>\n",
       "      <td>-0.949174</td>\n",
       "      <td>0.023209</td>\n",
       "      <td>0.649548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.13652, 0.3541, 0.89001, 0.09658, 0.24001, 0...</td>\n",
       "      <td>0.39088</td>\n",
       "      <td>0.07920</td>\n",
       "      <td>1.68089</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.5}</td>\n",
       "      <td>10-03 15:40:06</td>\n",
       "      <td>0.076063</td>\n",
       "      <td>2.692379</td>\n",
       "      <td>0.004387</td>\n",
       "      <td>0.530331</td>\n",
       "      <td>-0.012604</td>\n",
       "      <td>-0.949174</td>\n",
       "      <td>-0.012604</td>\n",
       "      <td>-0.949174</td>\n",
       "      <td>0.023209</td>\n",
       "      <td>0.649548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.13652, 0.3541, 0.89001, 0.09658, 0.24001, 0...</td>\n",
       "      <td>0.39088</td>\n",
       "      <td>0.07920</td>\n",
       "      <td>1.68089</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.5}</td>\n",
       "      <td>10-03 15:39:42</td>\n",
       "      <td>0.076063</td>\n",
       "      <td>2.692379</td>\n",
       "      <td>0.004387</td>\n",
       "      <td>0.530331</td>\n",
       "      <td>-0.012604</td>\n",
       "      <td>-0.949174</td>\n",
       "      <td>-0.012604</td>\n",
       "      <td>-0.949174</td>\n",
       "      <td>0.023209</td>\n",
       "      <td>0.649548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestReg</td>\n",
       "      <td>[0.19037, 0.07132, 0.12205, 0.15436, 0.11077, ...</td>\n",
       "      <td>0.13984</td>\n",
       "      <td>0.04739</td>\n",
       "      <td>0.35404</td>\n",
       "      <td>None</td>\n",
       "      <td>10-03 13:12:35</td>\n",
       "      <td>0.076063</td>\n",
       "      <td>2.692379</td>\n",
       "      <td>-0.022602</td>\n",
       "      <td>-0.603253</td>\n",
       "      <td>-0.003665</td>\n",
       "      <td>-0.027767</td>\n",
       "      <td>-0.003665</td>\n",
       "      <td>-0.027767</td>\n",
       "      <td>0.064577</td>\n",
       "      <td>1.047856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestReg</td>\n",
       "      <td>[0.07313, 0.07909, 0.10424, 0.12256, 0.11114, ...</td>\n",
       "      <td>0.10006</td>\n",
       "      <td>0.06343</td>\n",
       "      <td>0.17766</td>\n",
       "      <td>None</td>\n",
       "      <td>10-03 12:08:28</td>\n",
       "      <td>0.076063</td>\n",
       "      <td>2.692379</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.099678</td>\n",
       "      <td>2.089733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.06979, 0.08286, 0.09448, 0.10667, 0.08963, ...</td>\n",
       "      <td>0.07873</td>\n",
       "      <td>0.03510</td>\n",
       "      <td>0.11721</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.5}</td>\n",
       "      <td>10-03 12:04:27</td>\n",
       "      <td>0.076063</td>\n",
       "      <td>2.692379</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.099678</td>\n",
       "      <td>2.089733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              name                                         fold_score  \\\n",
       "9            Dummy  [0.06752, 0.08603, 0.11788, 0.13216, 0.14218, ...   \n",
       "8        LinearReg  [0.20636, 0.26691, 0.91792, 0.5793, 0.12272, 0...   \n",
       "7        LinearReg  [0.20636, 0.26691, 0.91792, 0.5793, 0.12272, 0...   \n",
       "6        LinearReg  [0.13652, 0.3541, 0.89001, 0.09658, 0.24001, 0...   \n",
       "5        LinearReg  [0.13652, 0.3541, 0.89001, 0.09658, 0.24001, 0...   \n",
       "4        LinearReg  [0.13652, 0.3541, 0.89001, 0.09658, 0.24001, 0...   \n",
       "3        LinearReg  [0.13652, 0.3541, 0.89001, 0.09658, 0.24001, 0...   \n",
       "2  RandomForestReg  [0.19037, 0.07132, 0.12205, 0.15436, 0.11077, ...   \n",
       "1  RandomForestReg  [0.07313, 0.07909, 0.10424, 0.12256, 0.11114, ...   \n",
       "0        LinearReg  [0.06979, 0.08286, 0.09448, 0.10667, 0.08963, ...   \n",
       "\n",
       "   mean_score  min_score  max_score                          hyperparams  \\\n",
       "9     0.11057    0.05455    0.19172                                  NaN   \n",
       "8     0.62972    0.07553    2.95176  {'alpha': 0.05, 'l1_ratio': 0.0001}   \n",
       "7     0.62972    0.07553    2.95176  {'alpha': 0.05, 'l1_ratio': 0.0001}   \n",
       "6     0.39088    0.07920    1.68089        {'alpha': 1, 'l1_ratio': 0.5}   \n",
       "5     0.39088    0.07920    1.68089        {'alpha': 1, 'l1_ratio': 0.5}   \n",
       "4     0.39088    0.07920    1.68089        {'alpha': 1, 'l1_ratio': 0.5}   \n",
       "3     0.39088    0.07920    1.68089        {'alpha': 1, 'l1_ratio': 0.5}   \n",
       "2     0.13984    0.04739    0.35404                                 None   \n",
       "1     0.10006    0.06343    0.17766                                 None   \n",
       "0     0.07873    0.03510    0.11721        {'alpha': 1, 'l1_ratio': 0.5}   \n",
       "\n",
       "             date  roi_hodler  sharpe_hodler  roi_trader  sharpe_trader  \\\n",
       "9  10-03 15:53:23    0.076063       2.692379    0.053090       0.637716   \n",
       "8  10-03 15:50:33    0.076063       2.692379    0.034135       1.414102   \n",
       "7  10-03 15:45:20    0.076063       2.692379    0.034135       1.414102   \n",
       "6  10-03 15:42:00    0.076063       2.692379    0.004387       0.530331   \n",
       "5  10-03 15:41:40    0.076063       2.692379    0.004387       0.530331   \n",
       "4  10-03 15:40:06    0.076063       2.692379    0.004387       0.530331   \n",
       "3  10-03 15:39:42    0.076063       2.692379    0.004387       0.530331   \n",
       "2  10-03 13:12:35    0.076063       2.692379   -0.022602      -0.603253   \n",
       "1  10-03 12:08:28    0.076063       2.692379    0.000000       0.000000   \n",
       "0  10-03 12:04:27    0.076063       2.692379    0.000000       0.000000   \n",
       "\n",
       "   roi_whale  sharpe_whale  roi_hodler_whale  sharpe_hodler_whale  \\\n",
       "9   0.055913      0.458252          0.056260             0.510347   \n",
       "8   0.025962      1.131473          0.044834             0.932677   \n",
       "7   0.025962      1.131473          0.044834             0.932677   \n",
       "6  -0.012604     -0.949174         -0.012604            -0.949174   \n",
       "5  -0.012604     -0.949174         -0.012604            -0.949174   \n",
       "4  -0.012604     -0.949174         -0.012604            -0.949174   \n",
       "3  -0.012604     -0.949174         -0.012604            -0.949174   \n",
       "2  -0.003665     -0.027767         -0.003665            -0.027767   \n",
       "1   0.000000      0.000000          0.000000             0.000000   \n",
       "0   0.000000      0.000000          0.000000             0.000000   \n",
       "\n",
       "   roi_charles  sharpe_charles  \n",
       "9     0.065704        1.186462  \n",
       "8     0.054169        1.510994  \n",
       "7     0.054169        1.510994  \n",
       "6     0.023209        0.649548  \n",
       "5     0.023209        0.649548  \n",
       "4     0.023209        0.649548  \n",
       "3     0.023209        0.649548  \n",
       "2     0.064577        1.047856  \n",
       "1     0.099678        2.089733  \n",
       "0     0.099678        2.089733  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DummyModel()\n",
    "cv_train(model,ApiCall().read_local(data=\"train\"))\n",
    "read_result().sort_values(by=\"date\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec82bf3",
   "metadata": {},
   "source": [
    "# Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cd23d26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T11:22:37.446679Z",
     "start_time": "2022-03-10T11:19:30.119973Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██████████████████████████▎                                                                                             | 7/32 [00:00<00:02,  9.35it/s]/Users/alexandrelaizet/.pyenv/versions/3.8.12/envs/bitcoin/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.588e-01, tolerance: 2.421e-04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      " 25%|██████████████████████████████                                                                                          | 8/32 [00:00<00:02,  8.97it/s]/Users/alexandrelaizet/.pyenv/versions/3.8.12/envs/bitcoin/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.542e-01, tolerance: 2.041e-04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      " 28%|█████████████████████████████████▊                                                                                      | 9/32 [00:00<00:02,  8.39it/s]/Users/alexandrelaizet/.pyenv/versions/3.8.12/envs/bitcoin/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.327e-01, tolerance: 2.361e-04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      " 31%|█████████████████████████████████████▏                                                                                 | 10/32 [00:01<00:02,  8.05it/s]/Users/alexandrelaizet/.pyenv/versions/3.8.12/envs/bitcoin/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.594e-01, tolerance: 2.550e-04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      " 69%|█████████████████████████████████████████████████████████████████████████████████▊                                     | 22/32 [00:02<00:01,  9.28it/s]/Users/alexandrelaizet/.pyenv/versions/3.8.12/envs/bitcoin/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.663e-01, tolerance: 4.180e-04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      " 78%|████████████████████████████████████████████████████████████████████████████████████████████▉                          | 25/32 [00:02<00:00,  8.70it/s]/Users/alexandrelaizet/.pyenv/versions/3.8.12/envs/bitcoin/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.060e-01, tolerance: 1.876e-04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      " 81%|████████████████████████████████████████████████████████████████████████████████████████████████▋                      | 26/32 [00:02<00:00,  8.01it/s]/Users/alexandrelaizet/.pyenv/versions/3.8.12/envs/bitcoin/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.161e-01, tolerance: 2.200e-04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      " 84%|████████████████████████████████████████████████████████████████████████████████████████████████████▍                  | 27/32 [00:03<00:00,  7.88it/s]/Users/alexandrelaizet/.pyenv/versions/3.8.12/envs/bitcoin/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.681e-01, tolerance: 2.269e-04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      " 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████▏              | 28/32 [00:03<00:00,  7.79it/s]/Users/alexandrelaizet/.pyenv/versions/3.8.12/envs/bitcoin/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.957e-01, tolerance: 2.707e-04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      " 91%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▊           | 29/32 [00:03<00:00,  7.45it/s]/Users/alexandrelaizet/.pyenv/versions/3.8.12/envs/bitcoin/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.600e-01, tolerance: 3.494e-04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      " 94%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▌       | 30/32 [00:03<00:00,  7.28it/s]/Users/alexandrelaizet/.pyenv/versions/3.8.12/envs/bitcoin/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.573e-01, tolerance: 3.760e-04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      " 97%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎   | 31/32 [00:03<00:00,  7.18it/s]/Users/alexandrelaizet/.pyenv/versions/3.8.12/envs/bitcoin/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.850e-01, tolerance: 3.928e-04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [00:03<00:00,  8.43it/s]\n",
      "/Users/alexandrelaizet/.pyenv/versions/3.8.12/envs/bitcoin/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.588e-01, tolerance: 2.421e-04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/alexandrelaizet/.pyenv/versions/3.8.12/envs/bitcoin/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.542e-01, tolerance: 2.041e-04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/alexandrelaizet/.pyenv/versions/3.8.12/envs/bitcoin/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.327e-01, tolerance: 2.361e-04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/alexandrelaizet/.pyenv/versions/3.8.12/envs/bitcoin/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.594e-01, tolerance: 2.550e-04\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexandrelaizet/.pyenv/versions/3.8.12/envs/bitcoin/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.663e-01, tolerance: 4.180e-04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/alexandrelaizet/.pyenv/versions/3.8.12/envs/bitcoin/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.060e-01, tolerance: 1.876e-04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/alexandrelaizet/.pyenv/versions/3.8.12/envs/bitcoin/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.161e-01, tolerance: 2.200e-04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/alexandrelaizet/.pyenv/versions/3.8.12/envs/bitcoin/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.681e-01, tolerance: 2.269e-04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/alexandrelaizet/.pyenv/versions/3.8.12/envs/bitcoin/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.957e-01, tolerance: 2.707e-04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/alexandrelaizet/.pyenv/versions/3.8.12/envs/bitcoin/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.600e-01, tolerance: 3.494e-04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/alexandrelaizet/.pyenv/versions/3.8.12/envs/bitcoin/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.573e-01, tolerance: 3.760e-04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/alexandrelaizet/.pyenv/versions/3.8.12/envs/bitcoin/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.850e-01, tolerance: 3.928e-04\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2172702355097862, 0.1773772102797484, 0.0, 0.1514171292931079, 0.1801592210272307, -0.2777363797714766, -0.29076824191104333, -0.1519077596832361, -0.12283953354687571, 0.0, 0.0, 0.025019800333978326, -0.3098439858605323, 0.025969350391875423, 0.0, 0.010580015231917095, 0.0, 0.10367793770043066, 0.0, 0.0, 0.0, 0.24950755221124288, 0.3816146715351807, 0.0, 0.38341082597163556, -0.07469147054300573, -0.24133489844179024, -0.38243218377026755, 0.20217003805619904, -0.053894493234533325, 0.3554664065473805, 0.18448470378028614]\n",
      "Training with trader done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>fold_score</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>min_score</th>\n",
       "      <th>max_score</th>\n",
       "      <th>hyperparams</th>\n",
       "      <th>date</th>\n",
       "      <th>roi_hodler</th>\n",
       "      <th>sharpe_hodler</th>\n",
       "      <th>roi_trader</th>\n",
       "      <th>sharpe_trader</th>\n",
       "      <th>roi_whale</th>\n",
       "      <th>sharpe_whale</th>\n",
       "      <th>roi_hodler_whale</th>\n",
       "      <th>sharpe_hodler_whale</th>\n",
       "      <th>roi_charles</th>\n",
       "      <th>sharpe_charles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.13652, 0.3541, 0.89001, 0.09658, 0.24001, 0...</td>\n",
       "      <td>0.39088</td>\n",
       "      <td>0.07920</td>\n",
       "      <td>1.68089</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.5}</td>\n",
       "      <td>10-03 15:54:12</td>\n",
       "      <td>0.076063</td>\n",
       "      <td>2.692379</td>\n",
       "      <td>0.004387</td>\n",
       "      <td>0.530331</td>\n",
       "      <td>-0.012604</td>\n",
       "      <td>-0.949174</td>\n",
       "      <td>-0.012604</td>\n",
       "      <td>-0.949174</td>\n",
       "      <td>0.023209</td>\n",
       "      <td>0.649548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dummy</td>\n",
       "      <td>[0.06752, 0.08603, 0.11788, 0.13216, 0.14218, ...</td>\n",
       "      <td>0.11057</td>\n",
       "      <td>0.05455</td>\n",
       "      <td>0.19172</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10-03 15:53:23</td>\n",
       "      <td>0.076063</td>\n",
       "      <td>2.692379</td>\n",
       "      <td>0.053090</td>\n",
       "      <td>0.637716</td>\n",
       "      <td>0.055913</td>\n",
       "      <td>0.458252</td>\n",
       "      <td>0.056260</td>\n",
       "      <td>0.510347</td>\n",
       "      <td>0.065704</td>\n",
       "      <td>1.186462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.20636, 0.26691, 0.91792, 0.5793, 0.12272, 0...</td>\n",
       "      <td>0.62972</td>\n",
       "      <td>0.07553</td>\n",
       "      <td>2.95176</td>\n",
       "      <td>{'alpha': 0.05, 'l1_ratio': 0.0001}</td>\n",
       "      <td>10-03 15:50:33</td>\n",
       "      <td>0.076063</td>\n",
       "      <td>2.692379</td>\n",
       "      <td>0.034135</td>\n",
       "      <td>1.414102</td>\n",
       "      <td>0.025962</td>\n",
       "      <td>1.131473</td>\n",
       "      <td>0.044834</td>\n",
       "      <td>0.932677</td>\n",
       "      <td>0.054169</td>\n",
       "      <td>1.510994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.20636, 0.26691, 0.91792, 0.5793, 0.12272, 0...</td>\n",
       "      <td>0.62972</td>\n",
       "      <td>0.07553</td>\n",
       "      <td>2.95176</td>\n",
       "      <td>{'alpha': 0.05, 'l1_ratio': 0.0001}</td>\n",
       "      <td>10-03 15:45:20</td>\n",
       "      <td>0.076063</td>\n",
       "      <td>2.692379</td>\n",
       "      <td>0.034135</td>\n",
       "      <td>1.414102</td>\n",
       "      <td>0.025962</td>\n",
       "      <td>1.131473</td>\n",
       "      <td>0.044834</td>\n",
       "      <td>0.932677</td>\n",
       "      <td>0.054169</td>\n",
       "      <td>1.510994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.13652, 0.3541, 0.89001, 0.09658, 0.24001, 0...</td>\n",
       "      <td>0.39088</td>\n",
       "      <td>0.07920</td>\n",
       "      <td>1.68089</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.5}</td>\n",
       "      <td>10-03 15:42:00</td>\n",
       "      <td>0.076063</td>\n",
       "      <td>2.692379</td>\n",
       "      <td>0.004387</td>\n",
       "      <td>0.530331</td>\n",
       "      <td>-0.012604</td>\n",
       "      <td>-0.949174</td>\n",
       "      <td>-0.012604</td>\n",
       "      <td>-0.949174</td>\n",
       "      <td>0.023209</td>\n",
       "      <td>0.649548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.13652, 0.3541, 0.89001, 0.09658, 0.24001, 0...</td>\n",
       "      <td>0.39088</td>\n",
       "      <td>0.07920</td>\n",
       "      <td>1.68089</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.5}</td>\n",
       "      <td>10-03 15:41:40</td>\n",
       "      <td>0.076063</td>\n",
       "      <td>2.692379</td>\n",
       "      <td>0.004387</td>\n",
       "      <td>0.530331</td>\n",
       "      <td>-0.012604</td>\n",
       "      <td>-0.949174</td>\n",
       "      <td>-0.012604</td>\n",
       "      <td>-0.949174</td>\n",
       "      <td>0.023209</td>\n",
       "      <td>0.649548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.13652, 0.3541, 0.89001, 0.09658, 0.24001, 0...</td>\n",
       "      <td>0.39088</td>\n",
       "      <td>0.07920</td>\n",
       "      <td>1.68089</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.5}</td>\n",
       "      <td>10-03 15:40:06</td>\n",
       "      <td>0.076063</td>\n",
       "      <td>2.692379</td>\n",
       "      <td>0.004387</td>\n",
       "      <td>0.530331</td>\n",
       "      <td>-0.012604</td>\n",
       "      <td>-0.949174</td>\n",
       "      <td>-0.012604</td>\n",
       "      <td>-0.949174</td>\n",
       "      <td>0.023209</td>\n",
       "      <td>0.649548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.13652, 0.3541, 0.89001, 0.09658, 0.24001, 0...</td>\n",
       "      <td>0.39088</td>\n",
       "      <td>0.07920</td>\n",
       "      <td>1.68089</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.5}</td>\n",
       "      <td>10-03 15:39:42</td>\n",
       "      <td>0.076063</td>\n",
       "      <td>2.692379</td>\n",
       "      <td>0.004387</td>\n",
       "      <td>0.530331</td>\n",
       "      <td>-0.012604</td>\n",
       "      <td>-0.949174</td>\n",
       "      <td>-0.012604</td>\n",
       "      <td>-0.949174</td>\n",
       "      <td>0.023209</td>\n",
       "      <td>0.649548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestReg</td>\n",
       "      <td>[0.19037, 0.07132, 0.12205, 0.15436, 0.11077, ...</td>\n",
       "      <td>0.13984</td>\n",
       "      <td>0.04739</td>\n",
       "      <td>0.35404</td>\n",
       "      <td>None</td>\n",
       "      <td>10-03 13:12:35</td>\n",
       "      <td>0.076063</td>\n",
       "      <td>2.692379</td>\n",
       "      <td>-0.022602</td>\n",
       "      <td>-0.603253</td>\n",
       "      <td>-0.003665</td>\n",
       "      <td>-0.027767</td>\n",
       "      <td>-0.003665</td>\n",
       "      <td>-0.027767</td>\n",
       "      <td>0.064577</td>\n",
       "      <td>1.047856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestReg</td>\n",
       "      <td>[0.07313, 0.07909, 0.10424, 0.12256, 0.11114, ...</td>\n",
       "      <td>0.10006</td>\n",
       "      <td>0.06343</td>\n",
       "      <td>0.17766</td>\n",
       "      <td>None</td>\n",
       "      <td>10-03 12:08:28</td>\n",
       "      <td>0.076063</td>\n",
       "      <td>2.692379</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.099678</td>\n",
       "      <td>2.089733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.06979, 0.08286, 0.09448, 0.10667, 0.08963, ...</td>\n",
       "      <td>0.07873</td>\n",
       "      <td>0.03510</td>\n",
       "      <td>0.11721</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.5}</td>\n",
       "      <td>10-03 12:04:27</td>\n",
       "      <td>0.076063</td>\n",
       "      <td>2.692379</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.099678</td>\n",
       "      <td>2.089733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               name                                         fold_score  \\\n",
       "10        LinearReg  [0.13652, 0.3541, 0.89001, 0.09658, 0.24001, 0...   \n",
       "9             Dummy  [0.06752, 0.08603, 0.11788, 0.13216, 0.14218, ...   \n",
       "8         LinearReg  [0.20636, 0.26691, 0.91792, 0.5793, 0.12272, 0...   \n",
       "7         LinearReg  [0.20636, 0.26691, 0.91792, 0.5793, 0.12272, 0...   \n",
       "6         LinearReg  [0.13652, 0.3541, 0.89001, 0.09658, 0.24001, 0...   \n",
       "5         LinearReg  [0.13652, 0.3541, 0.89001, 0.09658, 0.24001, 0...   \n",
       "4         LinearReg  [0.13652, 0.3541, 0.89001, 0.09658, 0.24001, 0...   \n",
       "3         LinearReg  [0.13652, 0.3541, 0.89001, 0.09658, 0.24001, 0...   \n",
       "2   RandomForestReg  [0.19037, 0.07132, 0.12205, 0.15436, 0.11077, ...   \n",
       "1   RandomForestReg  [0.07313, 0.07909, 0.10424, 0.12256, 0.11114, ...   \n",
       "0         LinearReg  [0.06979, 0.08286, 0.09448, 0.10667, 0.08963, ...   \n",
       "\n",
       "    mean_score  min_score  max_score                          hyperparams  \\\n",
       "10     0.39088    0.07920    1.68089        {'alpha': 1, 'l1_ratio': 0.5}   \n",
       "9      0.11057    0.05455    0.19172                                  NaN   \n",
       "8      0.62972    0.07553    2.95176  {'alpha': 0.05, 'l1_ratio': 0.0001}   \n",
       "7      0.62972    0.07553    2.95176  {'alpha': 0.05, 'l1_ratio': 0.0001}   \n",
       "6      0.39088    0.07920    1.68089        {'alpha': 1, 'l1_ratio': 0.5}   \n",
       "5      0.39088    0.07920    1.68089        {'alpha': 1, 'l1_ratio': 0.5}   \n",
       "4      0.39088    0.07920    1.68089        {'alpha': 1, 'l1_ratio': 0.5}   \n",
       "3      0.39088    0.07920    1.68089        {'alpha': 1, 'l1_ratio': 0.5}   \n",
       "2      0.13984    0.04739    0.35404                                 None   \n",
       "1      0.10006    0.06343    0.17766                                 None   \n",
       "0      0.07873    0.03510    0.11721        {'alpha': 1, 'l1_ratio': 0.5}   \n",
       "\n",
       "              date  roi_hodler  sharpe_hodler  roi_trader  sharpe_trader  \\\n",
       "10  10-03 15:54:12    0.076063       2.692379    0.004387       0.530331   \n",
       "9   10-03 15:53:23    0.076063       2.692379    0.053090       0.637716   \n",
       "8   10-03 15:50:33    0.076063       2.692379    0.034135       1.414102   \n",
       "7   10-03 15:45:20    0.076063       2.692379    0.034135       1.414102   \n",
       "6   10-03 15:42:00    0.076063       2.692379    0.004387       0.530331   \n",
       "5   10-03 15:41:40    0.076063       2.692379    0.004387       0.530331   \n",
       "4   10-03 15:40:06    0.076063       2.692379    0.004387       0.530331   \n",
       "3   10-03 15:39:42    0.076063       2.692379    0.004387       0.530331   \n",
       "2   10-03 13:12:35    0.076063       2.692379   -0.022602      -0.603253   \n",
       "1   10-03 12:08:28    0.076063       2.692379    0.000000       0.000000   \n",
       "0   10-03 12:04:27    0.076063       2.692379    0.000000       0.000000   \n",
       "\n",
       "    roi_whale  sharpe_whale  roi_hodler_whale  sharpe_hodler_whale  \\\n",
       "10  -0.012604     -0.949174         -0.012604            -0.949174   \n",
       "9    0.055913      0.458252          0.056260             0.510347   \n",
       "8    0.025962      1.131473          0.044834             0.932677   \n",
       "7    0.025962      1.131473          0.044834             0.932677   \n",
       "6   -0.012604     -0.949174         -0.012604            -0.949174   \n",
       "5   -0.012604     -0.949174         -0.012604            -0.949174   \n",
       "4   -0.012604     -0.949174         -0.012604            -0.949174   \n",
       "3   -0.012604     -0.949174         -0.012604            -0.949174   \n",
       "2   -0.003665     -0.027767         -0.003665            -0.027767   \n",
       "1    0.000000      0.000000          0.000000             0.000000   \n",
       "0    0.000000      0.000000          0.000000             0.000000   \n",
       "\n",
       "    roi_charles  sharpe_charles  \n",
       "10     0.023209        0.649548  \n",
       "9      0.065704        1.186462  \n",
       "8      0.054169        1.510994  \n",
       "7      0.054169        1.510994  \n",
       "6      0.023209        0.649548  \n",
       "5      0.023209        0.649548  \n",
       "4      0.023209        0.649548  \n",
       "3      0.023209        0.649548  \n",
       "2      0.064577        1.047856  \n",
       "1      0.099678        2.089733  \n",
       "0      0.099678        2.089733  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearRegressionBaselineModel()\n",
    "cv_train(model,ApiCall().read_local(data=\"train\"))\n",
    "read_result().sort_values(by=\"date\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392d72aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T10:06:03.430091Z",
     "start_time": "2022-03-10T10:06:03.297699Z"
    }
   },
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7826bfc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [02:26<00:00,  4.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.39423765465400606, 0.0, 0.0, 0.14175623511513047, -0.2824240613868797, -0.3141090385585297, -0.24699767200798428, -0.022270976617830507, 0.03086579265353362, 0.1718204129251013, 0.025019800333978326, 0.13920950857719383, 0.31110708210274485, 0.0, 0.0031862182371953374, 0.0, 0.0, 0.0, 0.283302223859873, 0.0, 0.0, 0.0, 0.3000199366901142, 0.38341082597163556, -0.14638556686848347, -0.24133489844179024, -0.38243218377026755, 0.23476900945553636, 0.2192444658295618, 0.0, 0.0]\n",
      "Training with trader done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>fold_score</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>min_score</th>\n",
       "      <th>max_score</th>\n",
       "      <th>hyperparams</th>\n",
       "      <th>date</th>\n",
       "      <th>roi_hodler</th>\n",
       "      <th>sharpe_hodler</th>\n",
       "      <th>roi_trader</th>\n",
       "      <th>sharpe_trader</th>\n",
       "      <th>roi_whale</th>\n",
       "      <th>sharpe_whale</th>\n",
       "      <th>roi_hodler_whale</th>\n",
       "      <th>sharpe_hodler_whale</th>\n",
       "      <th>roi_charles</th>\n",
       "      <th>sharpe_charles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RandomForestReg</td>\n",
       "      <td>[0.19047, 0.07148, 0.1206, 0.15337, 0.11154, 0...</td>\n",
       "      <td>0.13959</td>\n",
       "      <td>0.04774</td>\n",
       "      <td>0.35085</td>\n",
       "      <td>None</td>\n",
       "      <td>10-03 16:00:37</td>\n",
       "      <td>0.076063</td>\n",
       "      <td>2.692379</td>\n",
       "      <td>-0.023732</td>\n",
       "      <td>-0.631008</td>\n",
       "      <td>-0.004575</td>\n",
       "      <td>-0.119665</td>\n",
       "      <td>-0.004575</td>\n",
       "      <td>-0.119665</td>\n",
       "      <td>0.031312</td>\n",
       "      <td>0.773876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.13652, 0.3541, 0.89001, 0.09658, 0.24001, 0...</td>\n",
       "      <td>0.39088</td>\n",
       "      <td>0.07920</td>\n",
       "      <td>1.68089</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.5}</td>\n",
       "      <td>10-03 15:54:12</td>\n",
       "      <td>0.076063</td>\n",
       "      <td>2.692379</td>\n",
       "      <td>0.004387</td>\n",
       "      <td>0.530331</td>\n",
       "      <td>-0.012604</td>\n",
       "      <td>-0.949174</td>\n",
       "      <td>-0.012604</td>\n",
       "      <td>-0.949174</td>\n",
       "      <td>0.023209</td>\n",
       "      <td>0.649548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dummy</td>\n",
       "      <td>[0.06752, 0.08603, 0.11788, 0.13216, 0.14218, ...</td>\n",
       "      <td>0.11057</td>\n",
       "      <td>0.05455</td>\n",
       "      <td>0.19172</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10-03 15:53:23</td>\n",
       "      <td>0.076063</td>\n",
       "      <td>2.692379</td>\n",
       "      <td>0.053090</td>\n",
       "      <td>0.637716</td>\n",
       "      <td>0.055913</td>\n",
       "      <td>0.458252</td>\n",
       "      <td>0.056260</td>\n",
       "      <td>0.510347</td>\n",
       "      <td>0.065704</td>\n",
       "      <td>1.186462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.20636, 0.26691, 0.91792, 0.5793, 0.12272, 0...</td>\n",
       "      <td>0.62972</td>\n",
       "      <td>0.07553</td>\n",
       "      <td>2.95176</td>\n",
       "      <td>{'alpha': 0.05, 'l1_ratio': 0.0001}</td>\n",
       "      <td>10-03 15:50:33</td>\n",
       "      <td>0.076063</td>\n",
       "      <td>2.692379</td>\n",
       "      <td>0.034135</td>\n",
       "      <td>1.414102</td>\n",
       "      <td>0.025962</td>\n",
       "      <td>1.131473</td>\n",
       "      <td>0.044834</td>\n",
       "      <td>0.932677</td>\n",
       "      <td>0.054169</td>\n",
       "      <td>1.510994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.20636, 0.26691, 0.91792, 0.5793, 0.12272, 0...</td>\n",
       "      <td>0.62972</td>\n",
       "      <td>0.07553</td>\n",
       "      <td>2.95176</td>\n",
       "      <td>{'alpha': 0.05, 'l1_ratio': 0.0001}</td>\n",
       "      <td>10-03 15:45:20</td>\n",
       "      <td>0.076063</td>\n",
       "      <td>2.692379</td>\n",
       "      <td>0.034135</td>\n",
       "      <td>1.414102</td>\n",
       "      <td>0.025962</td>\n",
       "      <td>1.131473</td>\n",
       "      <td>0.044834</td>\n",
       "      <td>0.932677</td>\n",
       "      <td>0.054169</td>\n",
       "      <td>1.510994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.13652, 0.3541, 0.89001, 0.09658, 0.24001, 0...</td>\n",
       "      <td>0.39088</td>\n",
       "      <td>0.07920</td>\n",
       "      <td>1.68089</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.5}</td>\n",
       "      <td>10-03 15:42:00</td>\n",
       "      <td>0.076063</td>\n",
       "      <td>2.692379</td>\n",
       "      <td>0.004387</td>\n",
       "      <td>0.530331</td>\n",
       "      <td>-0.012604</td>\n",
       "      <td>-0.949174</td>\n",
       "      <td>-0.012604</td>\n",
       "      <td>-0.949174</td>\n",
       "      <td>0.023209</td>\n",
       "      <td>0.649548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.13652, 0.3541, 0.89001, 0.09658, 0.24001, 0...</td>\n",
       "      <td>0.39088</td>\n",
       "      <td>0.07920</td>\n",
       "      <td>1.68089</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.5}</td>\n",
       "      <td>10-03 15:41:40</td>\n",
       "      <td>0.076063</td>\n",
       "      <td>2.692379</td>\n",
       "      <td>0.004387</td>\n",
       "      <td>0.530331</td>\n",
       "      <td>-0.012604</td>\n",
       "      <td>-0.949174</td>\n",
       "      <td>-0.012604</td>\n",
       "      <td>-0.949174</td>\n",
       "      <td>0.023209</td>\n",
       "      <td>0.649548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.13652, 0.3541, 0.89001, 0.09658, 0.24001, 0...</td>\n",
       "      <td>0.39088</td>\n",
       "      <td>0.07920</td>\n",
       "      <td>1.68089</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.5}</td>\n",
       "      <td>10-03 15:40:06</td>\n",
       "      <td>0.076063</td>\n",
       "      <td>2.692379</td>\n",
       "      <td>0.004387</td>\n",
       "      <td>0.530331</td>\n",
       "      <td>-0.012604</td>\n",
       "      <td>-0.949174</td>\n",
       "      <td>-0.012604</td>\n",
       "      <td>-0.949174</td>\n",
       "      <td>0.023209</td>\n",
       "      <td>0.649548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.13652, 0.3541, 0.89001, 0.09658, 0.24001, 0...</td>\n",
       "      <td>0.39088</td>\n",
       "      <td>0.07920</td>\n",
       "      <td>1.68089</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.5}</td>\n",
       "      <td>10-03 15:39:42</td>\n",
       "      <td>0.076063</td>\n",
       "      <td>2.692379</td>\n",
       "      <td>0.004387</td>\n",
       "      <td>0.530331</td>\n",
       "      <td>-0.012604</td>\n",
       "      <td>-0.949174</td>\n",
       "      <td>-0.012604</td>\n",
       "      <td>-0.949174</td>\n",
       "      <td>0.023209</td>\n",
       "      <td>0.649548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestReg</td>\n",
       "      <td>[0.19037, 0.07132, 0.12205, 0.15436, 0.11077, ...</td>\n",
       "      <td>0.13984</td>\n",
       "      <td>0.04739</td>\n",
       "      <td>0.35404</td>\n",
       "      <td>None</td>\n",
       "      <td>10-03 13:12:35</td>\n",
       "      <td>0.076063</td>\n",
       "      <td>2.692379</td>\n",
       "      <td>-0.022602</td>\n",
       "      <td>-0.603253</td>\n",
       "      <td>-0.003665</td>\n",
       "      <td>-0.027767</td>\n",
       "      <td>-0.003665</td>\n",
       "      <td>-0.027767</td>\n",
       "      <td>0.064577</td>\n",
       "      <td>1.047856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestReg</td>\n",
       "      <td>[0.07313, 0.07909, 0.10424, 0.12256, 0.11114, ...</td>\n",
       "      <td>0.10006</td>\n",
       "      <td>0.06343</td>\n",
       "      <td>0.17766</td>\n",
       "      <td>None</td>\n",
       "      <td>10-03 12:08:28</td>\n",
       "      <td>0.076063</td>\n",
       "      <td>2.692379</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.099678</td>\n",
       "      <td>2.089733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearReg</td>\n",
       "      <td>[0.06979, 0.08286, 0.09448, 0.10667, 0.08963, ...</td>\n",
       "      <td>0.07873</td>\n",
       "      <td>0.03510</td>\n",
       "      <td>0.11721</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.5}</td>\n",
       "      <td>10-03 12:04:27</td>\n",
       "      <td>0.076063</td>\n",
       "      <td>2.692379</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.099678</td>\n",
       "      <td>2.089733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               name                                         fold_score  \\\n",
       "11  RandomForestReg  [0.19047, 0.07148, 0.1206, 0.15337, 0.11154, 0...   \n",
       "10        LinearReg  [0.13652, 0.3541, 0.89001, 0.09658, 0.24001, 0...   \n",
       "9             Dummy  [0.06752, 0.08603, 0.11788, 0.13216, 0.14218, ...   \n",
       "8         LinearReg  [0.20636, 0.26691, 0.91792, 0.5793, 0.12272, 0...   \n",
       "7         LinearReg  [0.20636, 0.26691, 0.91792, 0.5793, 0.12272, 0...   \n",
       "6         LinearReg  [0.13652, 0.3541, 0.89001, 0.09658, 0.24001, 0...   \n",
       "5         LinearReg  [0.13652, 0.3541, 0.89001, 0.09658, 0.24001, 0...   \n",
       "4         LinearReg  [0.13652, 0.3541, 0.89001, 0.09658, 0.24001, 0...   \n",
       "3         LinearReg  [0.13652, 0.3541, 0.89001, 0.09658, 0.24001, 0...   \n",
       "2   RandomForestReg  [0.19037, 0.07132, 0.12205, 0.15436, 0.11077, ...   \n",
       "1   RandomForestReg  [0.07313, 0.07909, 0.10424, 0.12256, 0.11114, ...   \n",
       "0         LinearReg  [0.06979, 0.08286, 0.09448, 0.10667, 0.08963, ...   \n",
       "\n",
       "    mean_score  min_score  max_score                          hyperparams  \\\n",
       "11     0.13959    0.04774    0.35085                                 None   \n",
       "10     0.39088    0.07920    1.68089        {'alpha': 1, 'l1_ratio': 0.5}   \n",
       "9      0.11057    0.05455    0.19172                                  NaN   \n",
       "8      0.62972    0.07553    2.95176  {'alpha': 0.05, 'l1_ratio': 0.0001}   \n",
       "7      0.62972    0.07553    2.95176  {'alpha': 0.05, 'l1_ratio': 0.0001}   \n",
       "6      0.39088    0.07920    1.68089        {'alpha': 1, 'l1_ratio': 0.5}   \n",
       "5      0.39088    0.07920    1.68089        {'alpha': 1, 'l1_ratio': 0.5}   \n",
       "4      0.39088    0.07920    1.68089        {'alpha': 1, 'l1_ratio': 0.5}   \n",
       "3      0.39088    0.07920    1.68089        {'alpha': 1, 'l1_ratio': 0.5}   \n",
       "2      0.13984    0.04739    0.35404                                 None   \n",
       "1      0.10006    0.06343    0.17766                                 None   \n",
       "0      0.07873    0.03510    0.11721        {'alpha': 1, 'l1_ratio': 0.5}   \n",
       "\n",
       "              date  roi_hodler  sharpe_hodler  roi_trader  sharpe_trader  \\\n",
       "11  10-03 16:00:37    0.076063       2.692379   -0.023732      -0.631008   \n",
       "10  10-03 15:54:12    0.076063       2.692379    0.004387       0.530331   \n",
       "9   10-03 15:53:23    0.076063       2.692379    0.053090       0.637716   \n",
       "8   10-03 15:50:33    0.076063       2.692379    0.034135       1.414102   \n",
       "7   10-03 15:45:20    0.076063       2.692379    0.034135       1.414102   \n",
       "6   10-03 15:42:00    0.076063       2.692379    0.004387       0.530331   \n",
       "5   10-03 15:41:40    0.076063       2.692379    0.004387       0.530331   \n",
       "4   10-03 15:40:06    0.076063       2.692379    0.004387       0.530331   \n",
       "3   10-03 15:39:42    0.076063       2.692379    0.004387       0.530331   \n",
       "2   10-03 13:12:35    0.076063       2.692379   -0.022602      -0.603253   \n",
       "1   10-03 12:08:28    0.076063       2.692379    0.000000       0.000000   \n",
       "0   10-03 12:04:27    0.076063       2.692379    0.000000       0.000000   \n",
       "\n",
       "    roi_whale  sharpe_whale  roi_hodler_whale  sharpe_hodler_whale  \\\n",
       "11  -0.004575     -0.119665         -0.004575            -0.119665   \n",
       "10  -0.012604     -0.949174         -0.012604            -0.949174   \n",
       "9    0.055913      0.458252          0.056260             0.510347   \n",
       "8    0.025962      1.131473          0.044834             0.932677   \n",
       "7    0.025962      1.131473          0.044834             0.932677   \n",
       "6   -0.012604     -0.949174         -0.012604            -0.949174   \n",
       "5   -0.012604     -0.949174         -0.012604            -0.949174   \n",
       "4   -0.012604     -0.949174         -0.012604            -0.949174   \n",
       "3   -0.012604     -0.949174         -0.012604            -0.949174   \n",
       "2   -0.003665     -0.027767         -0.003665            -0.027767   \n",
       "1    0.000000      0.000000          0.000000             0.000000   \n",
       "0    0.000000      0.000000          0.000000             0.000000   \n",
       "\n",
       "    roi_charles  sharpe_charles  \n",
       "11     0.031312        0.773876  \n",
       "10     0.023209        0.649548  \n",
       "9      0.065704        1.186462  \n",
       "8      0.054169        1.510994  \n",
       "7      0.054169        1.510994  \n",
       "6      0.023209        0.649548  \n",
       "5      0.023209        0.649548  \n",
       "4      0.023209        0.649548  \n",
       "3      0.023209        0.649548  \n",
       "2      0.064577        1.047856  \n",
       "1      0.099678        2.089733  \n",
       "0      0.099678        2.089733  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestReg()\n",
    "cv_train(model,ApiCall().read_local(data=\"train\"))\n",
    "read_result().sort_values(by=\"date\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496b1eb4",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cdda283",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                | 0/32 [00:00<?, ?it/s]2022-03-10 16:03:14.849376: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 8s 522ms/step - loss: 0.1677 - mae: 0.1342 - val_loss: 0.0446 - val_mae: 0.0748\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 162ms/step - loss: 0.0523 - mae: 0.0731 - val_loss: 0.0436 - val_mae: 0.0738\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 168ms/step - loss: 0.0513 - mae: 0.0728 - val_loss: 0.0430 - val_mae: 0.0733\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 160ms/step - loss: 0.0504 - mae: 0.0732 - val_loss: 0.0428 - val_mae: 0.0732\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 1s 141ms/step - loss: 0.0497 - mae: 0.0742 - val_loss: 0.0429 - val_mae: 0.0735\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 140ms/step - loss: 0.0491 - mae: 0.0747 - val_loss: 0.0431 - val_mae: 0.0737\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 1s 133ms/step - loss: 0.0499 - mae: 0.0756 - val_loss: 0.0437 - val_mae: 0.0742\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 1s 135ms/step - loss: 0.0498 - mae: 0.0767 - val_loss: 0.0431 - val_mae: 0.0737\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 1s 133ms/step - loss: 0.0497 - mae: 0.0755 - val_loss: 0.0428 - val_mae: 0.0734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|███▊                                                                                                                    | 1/32 [00:14<07:22, 14.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 10s 1s/step - loss: 0.1487 - mae: 0.1296 - val_loss: 0.0180 - val_mae: 0.0422\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 265ms/step - loss: 0.0707 - mae: 0.0830 - val_loss: 0.0460 - val_mae: 0.0847\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.0552 - mae: 0.0820 - val_loss: 0.0242 - val_mae: 0.0555\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 284ms/step - loss: 0.0574 - mae: 0.0806 - val_loss: 0.0376 - val_mae: 0.0747\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 1s 213ms/step - loss: 0.0622 - mae: 0.0858 - val_loss: 0.0399 - val_mae: 0.0779\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.0594 - mae: 0.0832 - val_loss: 0.0180 - val_mae: 0.0438\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.0601 - mae: 0.0788 - val_loss: 0.0158 - val_mae: 0.0430\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 1s 207ms/step - loss: 0.0523 - mae: 0.0785 - val_loss: 0.0194 - val_mae: 0.0477\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 1s 206ms/step - loss: 0.0502 - mae: 0.0793 - val_loss: 0.0168 - val_mae: 0.0444\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 1s 200ms/step - loss: 0.0593 - mae: 0.0842 - val_loss: 0.0499 - val_mae: 0.0885\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 1s 190ms/step - loss: 0.0551 - mae: 0.0825 - val_loss: 0.0429 - val_mae: 0.0779\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 1s 151ms/step - loss: 0.0503 - mae: 0.0785 - val_loss: 0.0246 - val_mae: 0.0530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|███████▌                                                                                                                | 2/32 [00:41<10:52, 21.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 7s 444ms/step - loss: 0.2752 - mae: 0.1753 - val_loss: 0.0343 - val_mae: 0.0602\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 142ms/step - loss: 0.0634 - mae: 0.0786 - val_loss: 0.0263 - val_mae: 0.0506\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 134ms/step - loss: 0.0530 - mae: 0.0753 - val_loss: 0.0192 - val_mae: 0.0413\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 129ms/step - loss: 0.0467 - mae: 0.0715 - val_loss: 0.0666 - val_mae: 0.0904\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.0777 - mae: 0.0916 - val_loss: 0.0487 - val_mae: 0.0752\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 133ms/step - loss: 0.0503 - mae: 0.0775 - val_loss: 0.0132 - val_mae: 0.0331\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 1s 134ms/step - loss: 0.0555 - mae: 0.0765 - val_loss: 0.0335 - val_mae: 0.0592\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.0482 - mae: 0.0717 - val_loss: 0.0380 - val_mae: 0.0645\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 1s 128ms/step - loss: 0.0536 - mae: 0.0757 - val_loss: 0.0063 - val_mae: 0.0311\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.0487 - mae: 0.0724 - val_loss: 0.1296 - val_mae: 0.1315\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 1s 131ms/step - loss: 0.0843 - mae: 0.0946 - val_loss: 0.0075 - val_mae: 0.0312\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 1s 129ms/step - loss: 0.0605 - mae: 0.0780 - val_loss: 0.0252 - val_mae: 0.0491\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 1s 129ms/step - loss: 0.0504 - mae: 0.0750 - val_loss: 0.0158 - val_mae: 0.0370\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.0526 - mae: 0.0737 - val_loss: 0.0186 - val_mae: 0.0407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|███████████▎                                                                                                            | 3/32 [00:56<09:01, 18.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 7s 461ms/step - loss: 0.0604 - mae: 0.0802 - val_loss: 0.0126 - val_mae: 0.0413\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 137ms/step - loss: 0.0578 - mae: 0.0660 - val_loss: 0.0618 - val_mae: 0.0592\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 138ms/step - loss: 0.0455 - mae: 0.0654 - val_loss: 0.0602 - val_mae: 0.0577\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 138ms/step - loss: 0.0471 - mae: 0.0658 - val_loss: 0.0668 - val_mae: 0.0636\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 1s 141ms/step - loss: 0.0446 - mae: 0.0660 - val_loss: 0.0574 - val_mae: 0.0552\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.0463 - mae: 0.0666 - val_loss: 0.0543 - val_mae: 0.0523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|███████████████                                                                                                         | 4/32 [01:07<07:20, 15.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 7s 440ms/step - loss: 0.3069 - mae: 0.1980 - val_loss: 0.1049 - val_mae: 0.0882\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 123ms/step - loss: 0.0414 - mae: 0.0597 - val_loss: 0.1468 - val_mae: 0.1095\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.0507 - mae: 0.0655 - val_loss: 0.1465 - val_mae: 0.1093\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.0424 - mae: 0.0623 - val_loss: 0.0326 - val_mae: 0.0752\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 1s 127ms/step - loss: 0.0465 - mae: 0.0612 - val_loss: 0.1515 - val_mae: 0.1120\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.0405 - mae: 0.0621 - val_loss: 0.1528 - val_mae: 0.1128\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.0410 - mae: 0.0635 - val_loss: 0.0405 - val_mae: 0.0791\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 1s 126ms/step - loss: 0.0364 - mae: 0.0622 - val_loss: 0.0330 - val_mae: 0.0754\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 1s 137ms/step - loss: 0.0402 - mae: 0.0622 - val_loss: 0.1843 - val_mae: 0.1277\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x1569e0a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|██████████████████▊                                                                                                     | 5/32 [01:19<06:29, 14.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 8s 437ms/step - loss: 0.1737 - mae: 0.1225 - val_loss: 0.0987 - val_mae: 0.1607\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 129ms/step - loss: 0.1144 - mae: 0.1094 - val_loss: 0.1742 - val_mae: 0.1271\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 133ms/step - loss: 0.0536 - mae: 0.0684 - val_loss: 0.1663 - val_mae: 0.1239\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 132ms/step - loss: 0.0530 - mae: 0.0664 - val_loss: 0.1605 - val_mae: 0.1217\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 1s 131ms/step - loss: 0.0505 - mae: 0.0646 - val_loss: 0.1593 - val_mae: 0.1212\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 129ms/step - loss: 0.0522 - mae: 0.0646 - val_loss: 0.1538 - val_mae: 0.1189\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x1559723a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|██████████████████████▌                                                                                                 | 6/32 [01:31<05:48, 13.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 8s 438ms/step - loss: 0.0934 - mae: 0.0921 - val_loss: 0.0908 - val_mae: 0.1026\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 129ms/step - loss: 0.0855 - mae: 0.0906 - val_loss: 0.0732 - val_mae: 0.1005\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 131ms/step - loss: 0.0607 - mae: 0.0744 - val_loss: 0.0727 - val_mae: 0.0999\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 131ms/step - loss: 0.0582 - mae: 0.0732 - val_loss: 0.0728 - val_mae: 0.1003\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 1s 131ms/step - loss: 0.0576 - mae: 0.0726 - val_loss: 0.0726 - val_mae: 0.1000\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 136ms/step - loss: 0.0565 - mae: 0.0724 - val_loss: 0.0726 - val_mae: 0.1000\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 1s 141ms/step - loss: 0.0552 - mae: 0.0723 - val_loss: 0.0608 - val_mae: 0.1014\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 1s 141ms/step - loss: 0.0450 - mae: 0.0711 - val_loss: 0.0726 - val_mae: 0.0999\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 1s 133ms/step - loss: 0.0510 - mae: 0.0707 - val_loss: 0.2131 - val_mae: 0.1579\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 1s 135ms/step - loss: 0.0743 - mae: 0.0876 - val_loss: 0.0740 - val_mae: 0.1009\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 1s 142ms/step - loss: 0.0383 - mae: 0.0693 - val_loss: 0.0749 - val_mae: 0.1016\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 1s 142ms/step - loss: 0.0380 - mae: 0.0690 - val_loss: 0.0753 - val_mae: 0.1018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██████████████████████████▎                                                                                             | 7/32 [01:45<05:46, 13.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 7s 516ms/step - loss: 0.1742 - mae: 0.1399 - val_loss: 0.0805 - val_mae: 0.0938\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 128ms/step - loss: 0.0372 - mae: 0.0706 - val_loss: 0.1045 - val_mae: 0.1089\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 132ms/step - loss: 0.0345 - mae: 0.0674 - val_loss: 0.0959 - val_mae: 0.1030\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 128ms/step - loss: 0.0377 - mae: 0.0697 - val_loss: 0.0717 - val_mae: 0.0879\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 1s 152ms/step - loss: 0.0389 - mae: 0.0681 - val_loss: 0.0738 - val_mae: 0.0894\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 133ms/step - loss: 0.0324 - mae: 0.0644 - val_loss: 0.0841 - val_mae: 0.0963\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 1s 124ms/step - loss: 0.0328 - mae: 0.0660 - val_loss: 0.0812 - val_mae: 0.0943\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 127ms/step - loss: 0.0338 - mae: 0.0661 - val_loss: 0.2688 - val_mae: 0.1881\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 1s 128ms/step - loss: 0.0393 - mae: 0.0790 - val_loss: 0.0821 - val_mae: 0.0950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██████████████████████████████                                                                                          | 8/32 [01:58<05:24, 13.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 8s 443ms/step - loss: 0.1978 - mae: 0.1454 - val_loss: 0.0413 - val_mae: 0.0636\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 128ms/step - loss: 0.0527 - mae: 0.0752 - val_loss: 0.0454 - val_mae: 0.0703\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 128ms/step - loss: 0.0361 - mae: 0.0672 - val_loss: 0.0508 - val_mae: 0.0755\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 128ms/step - loss: 0.0343 - mae: 0.0668 - val_loss: 0.0837 - val_mae: 0.0986\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.0373 - mae: 0.0690 - val_loss: 0.0841 - val_mae: 0.0990\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 177ms/step - loss: 0.0381 - mae: 0.0716 - val_loss: 0.0455 - val_mae: 0.0701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|█████████████████████████████████▊                                                                                      | 9/32 [02:10<04:56, 12.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 9s 551ms/step - loss: 0.0423 - mae: 0.0770 - val_loss: 0.3376 - val_mae: 0.1990\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 150ms/step - loss: 0.0616 - mae: 0.0967 - val_loss: 0.0284 - val_mae: 0.0546\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.0444 - mae: 0.0721 - val_loss: 0.0284 - val_mae: 0.0547\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 230ms/step - loss: 0.0378 - mae: 0.0722 - val_loss: 0.0560 - val_mae: 0.0550\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 0.0393 - mae: 0.0704 - val_loss: 0.0703 - val_mae: 0.0670\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 204ms/step - loss: 0.0375 - mae: 0.0706 - val_loss: 0.0899 - val_mae: 0.0819\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 1s 206ms/step - loss: 0.0378 - mae: 0.0719 - val_loss: 0.0633 - val_mae: 0.0612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|█████████████████████████████████████▏                                                                                 | 10/32 [02:28<05:22, 14.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 7s 466ms/step - loss: 0.2235 - mae: 0.1720 - val_loss: 0.0371 - val_mae: 0.0572\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 152ms/step - loss: 0.0664 - mae: 0.0805 - val_loss: 0.0384 - val_mae: 0.0594\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 153ms/step - loss: 0.0497 - mae: 0.0774 - val_loss: 0.0353 - val_mae: 0.0544\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.0503 - mae: 0.0780 - val_loss: 0.0355 - val_mae: 0.0547\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.0480 - mae: 0.0766 - val_loss: 0.0485 - val_mae: 0.0725\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.0500 - mae: 0.0776 - val_loss: 0.0352 - val_mae: 0.0542\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 127ms/step - loss: 0.0479 - mae: 0.0755 - val_loss: 0.0395 - val_mae: 0.0613\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 0.0654 - mae: 0.0843 - val_loss: 0.0219 - val_mae: 0.0515\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.0567 - mae: 0.0812 - val_loss: 0.0358 - val_mae: 0.0553\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.0530 - mae: 0.0786 - val_loss: 0.0322 - val_mae: 0.0627\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.0517 - mae: 0.0793 - val_loss: 0.0356 - val_mae: 0.0552\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 127ms/step - loss: 0.0413 - mae: 0.0740 - val_loss: 0.0400 - val_mae: 0.0616\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 1s 177ms/step - loss: 0.0499 - mae: 0.0778 - val_loss: 0.0523 - val_mae: 0.0765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|████████████████████████████████████████▉                                                                              | 11/32 [02:43<05:05, 14.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 9s 518ms/step - loss: 0.3014 - mae: 0.1898 - val_loss: 0.0165 - val_mae: 0.0499\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 186ms/step - loss: 0.0565 - mae: 0.0827 - val_loss: 0.0529 - val_mae: 0.0652\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 0.0539 - mae: 0.0795 - val_loss: 0.0189 - val_mae: 0.0515\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.0460 - mae: 0.0777 - val_loss: 0.0165 - val_mae: 0.0499\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.0454 - mae: 0.0769 - val_loss: 0.0177 - val_mae: 0.0499\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 166ms/step - loss: 0.0422 - mae: 0.0752 - val_loss: 0.0271 - val_mae: 0.0531\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 1s 170ms/step - loss: 0.0438 - mae: 0.0758 - val_loss: 0.0181 - val_mae: 0.0503\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.0372 - mae: 0.0740 - val_loss: 0.0181 - val_mae: 0.0503\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 1s 160ms/step - loss: 0.0502 - mae: 0.0796 - val_loss: 0.0755 - val_mae: 0.0843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|████████████████████████████████████████████▋                                                                          | 12/32 [02:57<04:53, 14.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 7s 455ms/step - loss: 0.1444 - mae: 0.1228 - val_loss: 0.0223 - val_mae: 0.0445\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.0898 - mae: 0.1087 - val_loss: 0.0269 - val_mae: 0.0504\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 133ms/step - loss: 0.0767 - mae: 0.0966 - val_loss: 0.0125 - val_mae: 0.0447\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.0574 - mae: 0.0825 - val_loss: 0.0373 - val_mae: 0.0623\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 118ms/step - loss: 0.0701 - mae: 0.0886 - val_loss: 0.0263 - val_mae: 0.0495\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 120ms/step - loss: 0.0455 - mae: 0.0783 - val_loss: 0.0125 - val_mae: 0.0415\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.0597 - mae: 0.0824 - val_loss: 0.0445 - val_mae: 0.0700\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 1s 127ms/step - loss: 0.0655 - mae: 0.0861 - val_loss: 0.0265 - val_mae: 0.0499\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 1s 137ms/step - loss: 0.0392 - mae: 0.0758 - val_loss: 0.0128 - val_mae: 0.0412\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 1s 124ms/step - loss: 0.0435 - mae: 0.0759 - val_loss: 0.0121 - val_mae: 0.0424\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.0452 - mae: 0.0783 - val_loss: 0.0372 - val_mae: 0.0614\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 119ms/step - loss: 0.0533 - mae: 0.0768 - val_loss: 0.0110 - val_mae: 0.0396\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.0477 - mae: 0.0807 - val_loss: 0.0338 - val_mae: 0.0583\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.0534 - mae: 0.0814 - val_loss: 0.0243 - val_mae: 0.0473\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 1s 182ms/step - loss: 0.0383 - mae: 0.0729 - val_loss: 0.0301 - val_mae: 0.0544\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 1s 127ms/step - loss: 0.0440 - mae: 0.0781 - val_loss: 0.0321 - val_mae: 0.0568\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.0374 - mae: 0.0724 - val_loss: 0.0264 - val_mae: 0.0499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████████████████████████████████████████████████▎                                                                      | 13/32 [03:15<04:54, 15.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 7s 476ms/step - loss: 0.0902 - mae: 0.1042 - val_loss: 0.0112 - val_mae: 0.0468\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 142ms/step - loss: 0.0496 - mae: 0.0749 - val_loss: 0.0900 - val_mae: 0.0997\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 122ms/step - loss: 0.0433 - mae: 0.0723 - val_loss: 0.0516 - val_mae: 0.0726\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 127ms/step - loss: 0.0383 - mae: 0.0695 - val_loss: 0.1254 - val_mae: 0.1221\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 1s 133ms/step - loss: 0.0586 - mae: 0.0838 - val_loss: 0.0510 - val_mae: 0.0719\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 127ms/step - loss: 0.0582 - mae: 0.0747 - val_loss: 0.0426 - val_mae: 0.0646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████████████████████████████████████████████████████                                                                   | 14/32 [03:26<04:15, 14.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 7s 441ms/step - loss: 0.0545 - mae: 0.0763 - val_loss: 0.2815 - val_mae: 0.1407\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 131ms/step - loss: 0.0366 - mae: 0.0633 - val_loss: 0.2779 - val_mae: 0.1407\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 135ms/step - loss: 0.0362 - mae: 0.0635 - val_loss: 0.2771 - val_mae: 0.1408\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 141ms/step - loss: 0.0356 - mae: 0.0637 - val_loss: 0.2846 - val_mae: 0.1409\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.0367 - mae: 0.0642 - val_loss: 0.3609 - val_mae: 0.1420\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 128ms/step - loss: 0.0407 - mae: 0.0641 - val_loss: 0.2796 - val_mae: 0.1407\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 1s 134ms/step - loss: 0.0359 - mae: 0.0633 - val_loss: 0.2728 - val_mae: 0.1412\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.0360 - mae: 0.0643 - val_loss: 0.2841 - val_mae: 0.1408\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.0358 - mae: 0.0635 - val_loss: 0.2867 - val_mae: 0.1412\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.0364 - mae: 0.0634 - val_loss: 0.2826 - val_mae: 0.1407\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.0361 - mae: 0.0634 - val_loss: 0.2713 - val_mae: 0.1420\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 1s 127ms/step - loss: 0.0365 - mae: 0.0637 - val_loss: 0.3576 - val_mae: 0.1413\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 1s 132ms/step - loss: 0.0507 - mae: 0.0663 - val_loss: 0.2779 - val_mae: 0.1407\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 1s 133ms/step - loss: 0.0367 - mae: 0.0634 - val_loss: 0.2763 - val_mae: 0.1408\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 1s 131ms/step - loss: 0.0357 - mae: 0.0638 - val_loss: 0.2819 - val_mae: 0.1407\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 1s 133ms/step - loss: 0.0362 - mae: 0.0635 - val_loss: 0.2788 - val_mae: 0.1407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|███████████████████████████████████████████████████████▊                                                               | 15/32 [03:42<04:11, 14.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 7s 439ms/step - loss: 0.1826 - mae: 0.1377 - val_loss: 0.4037 - val_mae: 0.1772\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 145ms/step - loss: 0.0921 - mae: 0.1044 - val_loss: 0.3574 - val_mae: 0.1587\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 132ms/step - loss: 0.0469 - mae: 0.0680 - val_loss: 0.3578 - val_mae: 0.1493\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 127ms/step - loss: 0.0320 - mae: 0.0594 - val_loss: 0.3611 - val_mae: 0.1487\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.0336 - mae: 0.0597 - val_loss: 0.4129 - val_mae: 0.1487\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.0329 - mae: 0.0597 - val_loss: 0.3576 - val_mae: 0.1493\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 1s 132ms/step - loss: 0.0322 - mae: 0.0594 - val_loss: 0.3591 - val_mae: 0.1490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|███████████████████████████████████████████████████████████▌                                                           | 16/32 [03:54<03:41, 13.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 7s 435ms/step - loss: 0.2287 - mae: 0.1474 - val_loss: 0.0282 - val_mae: 0.0762\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.1485 - mae: 0.1028 - val_loss: 0.0701 - val_mae: 0.0775\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 131ms/step - loss: 0.0994 - mae: 0.0829 - val_loss: 0.0529 - val_mae: 0.0676\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 127ms/step - loss: 0.0951 - mae: 0.0805 - val_loss: 0.0260 - val_mae: 0.0662\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.0980 - mae: 0.0802 - val_loss: 0.1809 - val_mae: 0.1377\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 131ms/step - loss: 0.1039 - mae: 0.0926 - val_loss: 0.0737 - val_mae: 0.0794\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 1s 137ms/step - loss: 0.0964 - mae: 0.0818 - val_loss: 0.1006 - val_mae: 0.0958\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 1s 134ms/step - loss: 0.1003 - mae: 0.0855 - val_loss: 0.0918 - val_mae: 0.0907\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 1s 127ms/step - loss: 0.0975 - mae: 0.0830 - val_loss: 0.0728 - val_mae: 0.0789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|███████████████████████████████████████████████████████████████▏                                                       | 17/32 [04:06<03:20, 13.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 7s 446ms/step - loss: 0.5808 - mae: 0.2453 - val_loss: 0.1243 - val_mae: 0.1244\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 127ms/step - loss: 0.1283 - mae: 0.0998 - val_loss: 0.0293 - val_mae: 0.0669\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.1092 - mae: 0.0839 - val_loss: 0.0277 - val_mae: 0.0625\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 125ms/step - loss: 0.0974 - mae: 0.0762 - val_loss: 0.1308 - val_mae: 0.1272\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 1s 124ms/step - loss: 0.1275 - mae: 0.0963 - val_loss: 0.0422 - val_mae: 0.0643\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.0996 - mae: 0.0786 - val_loss: 0.0463 - val_mae: 0.0663\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.0982 - mae: 0.0778 - val_loss: 0.0638 - val_mae: 0.0802\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 1s 125ms/step - loss: 0.1055 - mae: 0.0869 - val_loss: 0.0435 - val_mae: 0.0646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|██████████████████████████████████████████████████████████████████▉                                                    | 18/32 [04:18<03:01, 12.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 15s 477ms/step - loss: 0.1267 - mae: 0.0975 - val_loss: 0.0068 - val_mae: 0.0266\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 133ms/step - loss: 0.1098 - mae: 0.0840 - val_loss: 0.0139 - val_mae: 0.0423\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 145ms/step - loss: 0.1042 - mae: 0.0846 - val_loss: 0.0262 - val_mae: 0.0600\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 127ms/step - loss: 0.1242 - mae: 0.0884 - val_loss: 0.0058 - val_mae: 0.0253\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 1s 150ms/step - loss: 0.0962 - mae: 0.0814 - val_loss: 0.0074 - val_mae: 0.0270\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 143ms/step - loss: 0.0715 - mae: 0.0758 - val_loss: 0.0254 - val_mae: 0.0585\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 1s 165ms/step - loss: 0.1048 - mae: 0.0893 - val_loss: 0.0121 - val_mae: 0.0392\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 1s 150ms/step - loss: 0.1043 - mae: 0.0861 - val_loss: 0.0151 - val_mae: 0.0436\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 1s 131ms/step - loss: 0.1002 - mae: 0.0817 - val_loss: 0.0079 - val_mae: 0.0285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|██████████████████████████████████████████████████████████████████████▋                                                | 19/32 [04:39<03:19, 15.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 8s 434ms/step - loss: 0.4280 - mae: 0.2171 - val_loss: 0.0165 - val_mae: 0.0560\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.1181 - mae: 0.0878 - val_loss: 0.0126 - val_mae: 0.0379\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 126ms/step - loss: 0.1130 - mae: 0.0825 - val_loss: 0.0147 - val_mae: 0.0517\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 137ms/step - loss: 0.1070 - mae: 0.0789 - val_loss: 0.0126 - val_mae: 0.0454\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 1s 138ms/step - loss: 0.0981 - mae: 0.0765 - val_loss: 0.0122 - val_mae: 0.0438\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 135ms/step - loss: 0.0991 - mae: 0.0775 - val_loss: 0.0142 - val_mae: 0.0398\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.0964 - mae: 0.0747 - val_loss: 0.0129 - val_mae: 0.0381\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 1s 140ms/step - loss: 0.0792 - mae: 0.0743 - val_loss: 0.0569 - val_mae: 0.0730\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 1s 143ms/step - loss: 0.0911 - mae: 0.0763 - val_loss: 0.0234 - val_mae: 0.0713\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 1s 150ms/step - loss: 0.1086 - mae: 0.0832 - val_loss: 0.0118 - val_mae: 0.0428\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 1s 140ms/step - loss: 0.1017 - mae: 0.0801 - val_loss: 0.0115 - val_mae: 0.0383\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 1s 155ms/step - loss: 0.1049 - mae: 0.0805 - val_loss: 0.0410 - val_mae: 0.0569\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.1164 - mae: 0.0789 - val_loss: 0.0184 - val_mae: 0.0404\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 1s 131ms/step - loss: 0.0913 - mae: 0.0744 - val_loss: 0.1419 - val_mae: 0.1310\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 1s 132ms/step - loss: 0.1190 - mae: 0.0925 - val_loss: 0.0200 - val_mae: 0.0406\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 1s 150ms/step - loss: 0.0957 - mae: 0.0751 - val_loss: 0.0297 - val_mae: 0.0443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████████████████████████████████████████████████████████████████████████▍                                            | 20/32 [04:56<03:11, 15.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 8s 432ms/step - loss: 1.8883 - mae: 0.4214 - val_loss: 0.0395 - val_mae: 0.0567\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 131ms/step - loss: 0.1095 - mae: 0.0763 - val_loss: 0.0330 - val_mae: 0.0653\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.0983 - mae: 0.0761 - val_loss: 0.0417 - val_mae: 0.0600\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 129ms/step - loss: 0.1019 - mae: 0.0758 - val_loss: 0.0590 - val_mae: 0.0783\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.1201 - mae: 0.0858 - val_loss: 0.0293 - val_mae: 0.0592\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 0.0902 - mae: 0.0736 - val_loss: 0.0413 - val_mae: 0.0598\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.0903 - mae: 0.0737 - val_loss: 0.0309 - val_mae: 0.0628\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.1038 - mae: 0.0810 - val_loss: 0.0280 - val_mae: 0.0578\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.0934 - mae: 0.0747 - val_loss: 0.0254 - val_mae: 0.0552\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 1s 132ms/step - loss: 0.0918 - mae: 0.0751 - val_loss: 0.0261 - val_mae: 0.0541\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 1s 196ms/step - loss: 0.0889 - mae: 0.0719 - val_loss: 0.0245 - val_mae: 0.0524\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 1s 172ms/step - loss: 0.1078 - mae: 0.0863 - val_loss: 0.0243 - val_mae: 0.0523\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 1s 160ms/step - loss: 0.0822 - mae: 0.0721 - val_loss: 0.0310 - val_mae: 0.0558\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 1s 147ms/step - loss: 0.0804 - mae: 0.0736 - val_loss: 0.0424 - val_mae: 0.0636\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 1s 159ms/step - loss: 0.0833 - mae: 0.0744 - val_loss: 0.0408 - val_mae: 0.0588\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.0790 - mae: 0.0707 - val_loss: 0.0412 - val_mae: 0.0591\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 0.0715 - mae: 0.0702 - val_loss: 0.0482 - val_mae: 0.0689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████████████████████████████████████████████████████████████████████████████                                         | 21/32 [05:15<03:02, 16.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 7s 534ms/step - loss: 0.2103 - mae: 0.1260 - val_loss: 0.0218 - val_mae: 0.0513\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 136ms/step - loss: 0.1114 - mae: 0.0847 - val_loss: 0.0264 - val_mae: 0.0505\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.0927 - mae: 0.0743 - val_loss: 0.0236 - val_mae: 0.0480\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 140ms/step - loss: 0.0961 - mae: 0.0733 - val_loss: 0.0204 - val_mae: 0.0450\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.1331 - mae: 0.0940 - val_loss: 0.0202 - val_mae: 0.0472\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 129ms/step - loss: 0.1165 - mae: 0.0813 - val_loss: 0.0201 - val_mae: 0.0449\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 128ms/step - loss: 0.1017 - mae: 0.0739 - val_loss: 0.0223 - val_mae: 0.0526\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 1s 128ms/step - loss: 0.1189 - mae: 0.0788 - val_loss: 0.0201 - val_mae: 0.0449\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 1s 131ms/step - loss: 0.0861 - mae: 0.0735 - val_loss: 0.0194 - val_mae: 0.0448\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 0.1027 - mae: 0.0743 - val_loss: 0.0237 - val_mae: 0.0481\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.1080 - mae: 0.0751 - val_loss: 0.0233 - val_mae: 0.0478\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.0890 - mae: 0.0731 - val_loss: 0.0194 - val_mae: 0.0451\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 1s 132ms/step - loss: 0.0993 - mae: 0.0741 - val_loss: 0.0228 - val_mae: 0.0474\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 1s 129ms/step - loss: 0.0944 - mae: 0.0767 - val_loss: 0.0245 - val_mae: 0.0487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|█████████████████████████████████████████████████████████████████████████████████▊                                     | 22/32 [05:30<02:41, 16.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 8s 533ms/step - loss: 0.5146 - mae: 0.2297 - val_loss: 0.1044 - val_mae: 0.1009\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 129ms/step - loss: 0.1160 - mae: 0.0881 - val_loss: 0.0053 - val_mae: 0.0372\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 128ms/step - loss: 0.1184 - mae: 0.0839 - val_loss: 0.0535 - val_mae: 0.0660\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 0.1055 - mae: 0.0757 - val_loss: 0.0090 - val_mae: 0.0485\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 120ms/step - loss: 0.1082 - mae: 0.0756 - val_loss: 0.0071 - val_mae: 0.0461\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.0945 - mae: 0.0803 - val_loss: 0.0097 - val_mae: 0.0500\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 1s 132ms/step - loss: 0.1064 - mae: 0.0773 - val_loss: 0.0250 - val_mae: 0.0564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|█████████████████████████████████████████████████████████████████████████████████████▌                                 | 23/32 [05:42<02:15, 15.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 8s 670ms/step - loss: 0.0499 - mae: 0.0789 - val_loss: 0.1580 - val_mae: 0.1281\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 181ms/step - loss: 0.0437 - mae: 0.0727 - val_loss: 0.0121 - val_mae: 0.0539\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 163ms/step - loss: 0.0187 - mae: 0.0486 - val_loss: 0.0125 - val_mae: 0.0552\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 168ms/step - loss: 0.0207 - mae: 0.0496 - val_loss: 0.0130 - val_mae: 0.0565\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 1s 134ms/step - loss: 0.0190 - mae: 0.0482 - val_loss: 0.0130 - val_mae: 0.0563\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 156ms/step - loss: 0.0191 - mae: 0.0486 - val_loss: 0.0626 - val_mae: 0.0764\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 1s 184ms/step - loss: 0.0220 - mae: 0.0490 - val_loss: 0.0943 - val_mae: 0.0947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|█████████████████████████████████████████████████████████████████████████████████████████▎                             | 24/32 [05:55<01:55, 14.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 7s 436ms/step - loss: 0.5291 - mae: 0.2410 - val_loss: 0.0492 - val_mae: 0.0970\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 127ms/step - loss: 0.0337 - mae: 0.0690 - val_loss: 0.0433 - val_mae: 0.0936\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 0.0181 - mae: 0.0500 - val_loss: 0.0444 - val_mae: 0.0945\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.0181 - mae: 0.0498 - val_loss: 0.0396 - val_mae: 0.0900\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 127ms/step - loss: 0.0180 - mae: 0.0501 - val_loss: 0.0381 - val_mae: 0.0884\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 126ms/step - loss: 0.0179 - mae: 0.0502 - val_loss: 0.0430 - val_mae: 0.0934\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 1s 127ms/step - loss: 0.0220 - mae: 0.0518 - val_loss: 0.0462 - val_mae: 0.0959\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 1s 133ms/step - loss: 0.0177 - mae: 0.0500 - val_loss: 0.0391 - val_mae: 0.0897\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 119ms/step - loss: 0.0187 - mae: 0.0521 - val_loss: 0.0382 - val_mae: 0.0886\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 1s 182ms/step - loss: 0.0183 - mae: 0.0517 - val_loss: 0.0466 - val_mae: 0.0963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|████████████████████████████████████████████████████████████████████████████████████████████▉                          | 25/32 [06:09<01:38, 14.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 9s 541ms/step - loss: 0.5210 - mae: 0.1989 - val_loss: 0.1186 - val_mae: 0.1262\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 162ms/step - loss: 0.0252 - mae: 0.0518 - val_loss: 0.0594 - val_mae: 0.1156\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 128ms/step - loss: 0.0190 - mae: 0.0502 - val_loss: 0.0602 - val_mae: 0.1164\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 132ms/step - loss: 0.0188 - mae: 0.0499 - val_loss: 0.0567 - val_mae: 0.1084\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.0181 - mae: 0.0501 - val_loss: 0.0610 - val_mae: 0.1172\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 0.0186 - mae: 0.0483 - val_loss: 0.0604 - val_mae: 0.1165\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 1s 254ms/step - loss: 0.0185 - mae: 0.0497 - val_loss: 0.0584 - val_mae: 0.1125\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.0163 - mae: 0.0472 - val_loss: 0.0614 - val_mae: 0.1174\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 0.0195 - mae: 0.0489 - val_loss: 0.0569 - val_mae: 0.1116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████████████████████████████████████████████████████████████████████████████████████████████▋                      | 26/32 [06:27<01:32, 15.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 9s 662ms/step - loss: 0.1161 - mae: 0.1085 - val_loss: 0.1557 - val_mae: 0.1242\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 193ms/step - loss: 0.0448 - mae: 0.0673 - val_loss: 0.0490 - val_mae: 0.0991\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 157ms/step - loss: 0.0273 - mae: 0.0621 - val_loss: 0.0492 - val_mae: 0.0995\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 125ms/step - loss: 0.0269 - mae: 0.0619 - val_loss: 0.0489 - val_mae: 0.0988\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 127ms/step - loss: 0.0255 - mae: 0.0615 - val_loss: 0.0477 - val_mae: 0.0955\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.0256 - mae: 0.0624 - val_loss: 0.0496 - val_mae: 0.1004\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.0260 - mae: 0.0611 - val_loss: 0.0512 - val_mae: 0.1038\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.0273 - mae: 0.0609 - val_loss: 0.0481 - val_mae: 0.0965\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.0256 - mae: 0.0615 - val_loss: 0.0506 - val_mae: 0.1027\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 1s 126ms/step - loss: 0.0253 - mae: 0.0604 - val_loss: 0.0483 - val_mae: 0.0953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████████████████████████████████████████████████████████████████████████████████████████████████▍                  | 27/32 [06:42<01:16, 15.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 7s 435ms/step - loss: 0.0805 - mae: 0.0897 - val_loss: 0.0433 - val_mae: 0.0715\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 126ms/step - loss: 0.0298 - mae: 0.0710 - val_loss: 0.0481 - val_mae: 0.0762\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 126ms/step - loss: 0.0298 - mae: 0.0711 - val_loss: 0.0413 - val_mae: 0.0706\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 131ms/step - loss: 0.0298 - mae: 0.0715 - val_loss: 0.0526 - val_mae: 0.0805\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 1s 128ms/step - loss: 0.0307 - mae: 0.0713 - val_loss: 0.0448 - val_mae: 0.0733\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 0.0285 - mae: 0.0698 - val_loss: 0.0396 - val_mae: 0.0698\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 0.0315 - mae: 0.0725 - val_loss: 0.0525 - val_mae: 0.0804\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.0303 - mae: 0.0712 - val_loss: 0.0426 - val_mae: 0.0719\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.0297 - mae: 0.0711 - val_loss: 0.0545 - val_mae: 0.0823\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 1s 127ms/step - loss: 0.0285 - mae: 0.0685 - val_loss: 0.0464 - val_mae: 0.0749\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.0297 - mae: 0.0709 - val_loss: 0.0433 - val_mae: 0.0723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████▏              | 28/32 [06:55<00:58, 14.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 8s 441ms/step - loss: 0.1624 - mae: 0.1303 - val_loss: 0.0667 - val_mae: 0.0823\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 127ms/step - loss: 0.1484 - mae: 0.1268 - val_loss: 0.0947 - val_mae: 0.1005\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 127ms/step - loss: 0.0371 - mae: 0.0764 - val_loss: 0.0933 - val_mae: 0.0994\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 136ms/step - loss: 0.0367 - mae: 0.0757 - val_loss: 0.0736 - val_mae: 0.0859\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.0367 - mae: 0.0759 - val_loss: 0.0776 - val_mae: 0.0884\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 130ms/step - loss: 0.0361 - mae: 0.0758 - val_loss: 0.0803 - val_mae: 0.0902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▊           | 29/32 [07:06<00:40, 13.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 7s 466ms/step - loss: 0.1851 - mae: 0.1688 - val_loss: 0.0817 - val_mae: 0.1160\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.0869 - mae: 0.0959 - val_loss: 0.1290 - val_mae: 0.1070\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.0438 - mae: 0.0800 - val_loss: 0.1577 - val_mae: 0.1114\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.0373 - mae: 0.0788 - val_loss: 0.1944 - val_mae: 0.1279\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 1s 144ms/step - loss: 0.0354 - mae: 0.0765 - val_loss: 0.1670 - val_mae: 0.1153\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 137ms/step - loss: 0.0328 - mae: 0.0750 - val_loss: 0.1609 - val_mae: 0.1134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▌       | 30/32 [07:17<00:25, 12.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 8s 438ms/step - loss: 0.1214 - mae: 0.1234 - val_loss: 0.3358 - val_mae: 0.2018\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 128ms/step - loss: 0.1158 - mae: 0.1213 - val_loss: 0.0881 - val_mae: 0.0861\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 127ms/step - loss: 0.0595 - mae: 0.0919 - val_loss: 0.0735 - val_mae: 0.0757\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.0571 - mae: 0.0891 - val_loss: 0.0749 - val_mae: 0.0767\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 1s 140ms/step - loss: 0.0544 - mae: 0.0885 - val_loss: 0.0664 - val_mae: 0.0701\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 0.0779 - mae: 0.0975 - val_loss: 0.0732 - val_mae: 0.0756\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.0608 - mae: 0.0960 - val_loss: 0.0901 - val_mae: 0.0876\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 0.0605 - mae: 0.0938 - val_loss: 0.0842 - val_mae: 0.0834\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.0584 - mae: 0.0902 - val_loss: 0.0691 - val_mae: 0.0730\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.0681 - mae: 0.0935 - val_loss: 0.0701 - val_mae: 0.0738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎   | 31/32 [07:30<00:12, 12.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 7s 593ms/step - loss: 0.2202 - mae: 0.1583 - val_loss: 0.0671 - val_mae: 0.0843\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.1004 - mae: 0.1017 - val_loss: 0.0641 - val_mae: 0.0834\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 127ms/step - loss: 0.0948 - mae: 0.1014 - val_loss: 0.0548 - val_mae: 0.0821\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.0751 - mae: 0.0975 - val_loss: 0.0552 - val_mae: 0.0822\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.0664 - mae: 0.0953 - val_loss: 0.0819 - val_mae: 0.1016\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.1414 - mae: 0.1271 - val_loss: 0.0546 - val_mae: 0.0819\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 0.0721 - mae: 0.0972 - val_loss: 0.0648 - val_mae: 0.0835\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.0746 - mae: 0.0985 - val_loss: 0.0554 - val_mae: 0.0819\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.0748 - mae: 0.0979 - val_loss: 0.0564 - val_mae: 0.0820\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 1s 128ms/step - loss: 0.0643 - mae: 0.0952 - val_loss: 0.0550 - val_mae: 0.0817\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.0662 - mae: 0.0954 - val_loss: 0.0633 - val_mae: 0.0832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [07:44<00:00, 14.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 7s 437ms/step - loss: 0.1298 - mae: 0.1330 - val_loss: 0.0663 - val_mae: 0.0799\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.0530 - mae: 0.0779 - val_loss: 0.0442 - val_mae: 0.0743\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 129ms/step - loss: 0.0514 - mae: 0.0767 - val_loss: 0.0619 - val_mae: 0.0767\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 131ms/step - loss: 0.0517 - mae: 0.0751 - val_loss: 0.0431 - val_mae: 0.0734\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.0490 - mae: 0.0752 - val_loss: 0.0479 - val_mae: 0.0788\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.0490 - mae: 0.0775 - val_loss: 0.0486 - val_mae: 0.0753\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.0503 - mae: 0.0754 - val_loss: 0.0526 - val_mae: 0.0838\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.0477 - mae: 0.0764 - val_loss: 0.0420 - val_mae: 0.0746\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 129ms/step - loss: 0.0642 - mae: 0.0870 - val_loss: 0.0791 - val_mae: 0.1058\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 127ms/step - loss: 0.0646 - mae: 0.0880 - val_loss: 0.0678 - val_mae: 0.0847\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 1s 129ms/step - loss: 0.1161 - mae: 0.1098 - val_loss: 0.0679 - val_mae: 0.0817\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 128ms/step - loss: 0.0758 - mae: 0.0770 - val_loss: 0.0597 - val_mae: 0.0753\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 1s 129ms/step - loss: 0.0601 - mae: 0.0732 - val_loss: 0.0435 - val_mae: 0.0738\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 8s 457ms/step - loss: 0.3393 - mae: 0.2037 - val_loss: 0.2157 - val_mae: 0.2016\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 135ms/step - loss: 0.0923 - mae: 0.1064 - val_loss: 0.0201 - val_mae: 0.0488\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 147ms/step - loss: 0.0567 - mae: 0.0814 - val_loss: 0.0197 - val_mae: 0.0482\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 128ms/step - loss: 0.0553 - mae: 0.0796 - val_loss: 0.0651 - val_mae: 0.1031\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 1s 135ms/step - loss: 0.0626 - mae: 0.0874 - val_loss: 0.0195 - val_mae: 0.0479\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 124ms/step - loss: 0.0559 - mae: 0.0799 - val_loss: 0.0370 - val_mae: 0.0723\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 1s 123ms/step - loss: 0.0488 - mae: 0.0802 - val_loss: 0.0206 - val_mae: 0.0489\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.0824 - mae: 0.0933 - val_loss: 0.0312 - val_mae: 0.0590\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 1s 123ms/step - loss: 0.0923 - mae: 0.0928 - val_loss: 0.0178 - val_mae: 0.0459\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.0526 - mae: 0.0784 - val_loss: 0.0498 - val_mae: 0.0840\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 1s 138ms/step - loss: 0.0651 - mae: 0.0868 - val_loss: 0.0210 - val_mae: 0.0494\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 1s 147ms/step - loss: 0.0557 - mae: 0.0821 - val_loss: 0.0349 - val_mae: 0.0679\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 1s 127ms/step - loss: 0.0457 - mae: 0.0773 - val_loss: 0.0420 - val_mae: 0.0776\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 1s 132ms/step - loss: 0.0446 - mae: 0.0744 - val_loss: 0.0169 - val_mae: 0.0453\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 1s 134ms/step - loss: 0.0625 - mae: 0.0851 - val_loss: 0.0172 - val_mae: 0.0447\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 1s 133ms/step - loss: 0.0498 - mae: 0.0769 - val_loss: 0.0151 - val_mae: 0.0432\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 0.0450 - mae: 0.0718 - val_loss: 0.0598 - val_mae: 0.0868\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 0.0841 - mae: 0.0921 - val_loss: 0.0222 - val_mae: 0.0517\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.0651 - mae: 0.0822 - val_loss: 0.0280 - val_mae: 0.0495\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.0540 - mae: 0.0792 - val_loss: 0.0483 - val_mae: 0.0743\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 13s 625ms/step - loss: 0.0840 - mae: 0.0898 - val_loss: 0.0149 - val_mae: 0.0355\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 133ms/step - loss: 0.0534 - mae: 0.0750 - val_loss: 0.0067 - val_mae: 0.0309\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 153ms/step - loss: 0.0500 - mae: 0.0718 - val_loss: 0.0387 - val_mae: 0.0650\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 127ms/step - loss: 0.0538 - mae: 0.0742 - val_loss: 0.0573 - val_mae: 0.0827\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 1s 123ms/step - loss: 0.0542 - mae: 0.0787 - val_loss: 0.0402 - val_mae: 0.0668\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 141ms/step - loss: 0.0497 - mae: 0.0756 - val_loss: 0.0068 - val_mae: 0.0311\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 1s 152ms/step - loss: 0.0501 - mae: 0.0714 - val_loss: 0.0847 - val_mae: 0.1039\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 8s 444ms/step - loss: 0.2438 - mae: 0.1636 - val_loss: 0.0556 - val_mae: 0.0534\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 126ms/step - loss: 0.0423 - mae: 0.0668 - val_loss: 0.0101 - val_mae: 0.0405\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.0626 - mae: 0.0684 - val_loss: 0.0514 - val_mae: 0.0494\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.0450 - mae: 0.0647 - val_loss: 0.0633 - val_mae: 0.0604\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 1s 128ms/step - loss: 0.0462 - mae: 0.0678 - val_loss: 0.0529 - val_mae: 0.0511\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.0617 - mae: 0.0694 - val_loss: 0.0899 - val_mae: 0.0818\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 1s 134ms/step - loss: 0.0448 - mae: 0.0696 - val_loss: 0.0687 - val_mae: 0.0652\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 7s 437ms/step - loss: 0.1123 - mae: 0.1062 - val_loss: 0.0252 - val_mae: 0.0683\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 129ms/step - loss: 0.2438 - mae: 0.1566 - val_loss: 0.1867 - val_mae: 0.1293\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 135ms/step - loss: 0.0452 - mae: 0.0693 - val_loss: 0.1104 - val_mae: 0.0890\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 133ms/step - loss: 0.0421 - mae: 0.0615 - val_loss: 0.0363 - val_mae: 0.0785\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 1s 127ms/step - loss: 0.0513 - mae: 0.0598 - val_loss: 0.1601 - val_mae: 0.1162\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.0451 - mae: 0.0635 - val_loss: 0.0308 - val_mae: 0.0733\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 7s 432ms/step - loss: 0.1687 - mae: 0.1487 - val_loss: 0.1311 - val_mae: 0.1086\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.0527 - mae: 0.0683 - val_loss: 0.1661 - val_mae: 0.1239\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 128ms/step - loss: 0.0556 - mae: 0.0646 - val_loss: 0.2342 - val_mae: 0.1478\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.0506 - mae: 0.0685 - val_loss: 0.0399 - val_mae: 0.1001\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 1s 127ms/step - loss: 0.0361 - mae: 0.0583 - val_loss: 0.1444 - val_mae: 0.1148\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.0404 - mae: 0.0606 - val_loss: 0.0254 - val_mae: 0.0728\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 1s 126ms/step - loss: 0.0514 - mae: 0.0742 - val_loss: 0.1717 - val_mae: 0.1259\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.0368 - mae: 0.0624 - val_loss: 0.0341 - val_mae: 0.0955\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.0375 - mae: 0.0647 - val_loss: 0.2022 - val_mae: 0.1367\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 1s 256ms/step - loss: 0.0402 - mae: 0.0648 - val_loss: 0.0331 - val_mae: 0.0941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n",
      "4/4 [==============================] - 1s 136ms/step - loss: 0.0436 - mae: 0.0683 - val_loss: 0.0321 - val_mae: 0.0894\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 8s 440ms/step - loss: 0.2045 - mae: 0.1571 - val_loss: 0.1217 - val_mae: 0.1129\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.0625 - mae: 0.0766 - val_loss: 0.0760 - val_mae: 0.1026\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.0598 - mae: 0.0752 - val_loss: 0.0764 - val_mae: 0.1027\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 132ms/step - loss: 0.0501 - mae: 0.0712 - val_loss: 0.0941 - val_mae: 0.1031\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 1s 144ms/step - loss: 0.0692 - mae: 0.0787 - val_loss: 0.1150 - val_mae: 0.1105\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 133ms/step - loss: 0.1208 - mae: 0.1079 - val_loss: 0.1014 - val_mae: 0.1024\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 1s 133ms/step - loss: 0.0506 - mae: 0.0707 - val_loss: 0.0734 - val_mae: 0.1008\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 1s 129ms/step - loss: 0.0411 - mae: 0.0694 - val_loss: 0.0865 - val_mae: 0.1096\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 1s 129ms/step - loss: 0.0360 - mae: 0.0674 - val_loss: 0.1101 - val_mae: 0.1100\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 1s 128ms/step - loss: 0.0855 - mae: 0.0945 - val_loss: 0.0718 - val_mae: 0.0995\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.0379 - mae: 0.0671 - val_loss: 0.0806 - val_mae: 0.1021\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.0389 - mae: 0.0699 - val_loss: 0.0766 - val_mae: 0.1029\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 127ms/step - loss: 0.0347 - mae: 0.0663 - val_loss: 0.0809 - val_mae: 0.1058\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 1s 133ms/step - loss: 0.0305 - mae: 0.0652 - val_loss: 0.0661 - val_mae: 0.1003\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.0338 - mae: 0.0675 - val_loss: 0.0961 - val_mae: 0.1151\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.0309 - mae: 0.0668 - val_loss: 0.0893 - val_mae: 0.1111\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.0289 - mae: 0.0660 - val_loss: 0.0849 - val_mae: 0.1078\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.0304 - mae: 0.0656 - val_loss: 0.0682 - val_mae: 0.0983\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 1s 133ms/step - loss: 0.0414 - mae: 0.0712 - val_loss: 0.1394 - val_mae: 0.1335\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 7s 434ms/step - loss: 0.3901 - mae: 0.2022 - val_loss: 0.1029 - val_mae: 0.1086\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 132ms/step - loss: 0.0351 - mae: 0.0679 - val_loss: 0.0844 - val_mae: 0.0967\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 127ms/step - loss: 0.0360 - mae: 0.0682 - val_loss: 0.1022 - val_mae: 0.1081\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 131ms/step - loss: 0.0308 - mae: 0.0670 - val_loss: 0.0865 - val_mae: 0.0981\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.0348 - mae: 0.0687 - val_loss: 0.0933 - val_mae: 0.1024\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 128ms/step - loss: 0.0311 - mae: 0.0661 - val_loss: 0.0706 - val_mae: 0.0888\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.0400 - mae: 0.0681 - val_loss: 0.1576 - val_mae: 0.1386\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.0377 - mae: 0.0719 - val_loss: 0.0740 - val_mae: 0.0874\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.0456 - mae: 0.0687 - val_loss: 0.0758 - val_mae: 0.0919\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.0314 - mae: 0.0650 - val_loss: 0.2561 - val_mae: 0.1825\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 119ms/step - loss: 0.0636 - mae: 0.0841 - val_loss: 0.0791 - val_mae: 0.0926\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 7s 437ms/step - loss: 0.0557 - mae: 0.0750 - val_loss: 0.0423 - val_mae: 0.0647\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 133ms/step - loss: 0.0354 - mae: 0.0661 - val_loss: 0.0422 - val_mae: 0.0642\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.0361 - mae: 0.0655 - val_loss: 0.0456 - val_mae: 0.0702\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 129ms/step - loss: 0.0351 - mae: 0.0661 - val_loss: 0.0459 - val_mae: 0.0705\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 116ms/step - loss: 0.0349 - mae: 0.0656 - val_loss: 0.0421 - val_mae: 0.0637\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 132ms/step - loss: 0.0409 - mae: 0.0671 - val_loss: 0.0477 - val_mae: 0.0725\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 1s 138ms/step - loss: 0.0355 - mae: 0.0665 - val_loss: 0.0443 - val_mae: 0.0685\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.0480 - mae: 0.0739 - val_loss: 0.0480 - val_mae: 0.0729\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.0428 - mae: 0.0705 - val_loss: 0.0502 - val_mae: 0.0748\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 1s 127ms/step - loss: 0.0326 - mae: 0.0655 - val_loss: 0.0496 - val_mae: 0.0743\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 7s 441ms/step - loss: 0.1255 - mae: 0.1260 - val_loss: 0.0975 - val_mae: 0.0869\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 131ms/step - loss: 0.0395 - mae: 0.0726 - val_loss: 0.0875 - val_mae: 0.0802\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 133ms/step - loss: 0.0374 - mae: 0.0731 - val_loss: 0.0702 - val_mae: 0.0667\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 127ms/step - loss: 0.0385 - mae: 0.0713 - val_loss: 0.1656 - val_mae: 0.1266\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 1s 129ms/step - loss: 0.0426 - mae: 0.0760 - val_loss: 0.0692 - val_mae: 0.0660\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 204ms/step - loss: 0.0378 - mae: 0.0712 - val_loss: 0.0733 - val_mae: 0.0695\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 128ms/step - loss: 0.0372 - mae: 0.0712 - val_loss: 0.0740 - val_mae: 0.0701\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 1s 131ms/step - loss: 0.0397 - mae: 0.0713 - val_loss: 0.0738 - val_mae: 0.0699\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 1s 162ms/step - loss: 0.0380 - mae: 0.0714 - val_loss: 0.0734 - val_mae: 0.0696\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 1s 143ms/step - loss: 0.0375 - mae: 0.0712 - val_loss: 0.0788 - val_mae: 0.0738\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 8s 459ms/step - loss: 0.1332 - mae: 0.1242 - val_loss: 0.0562 - val_mae: 0.0803\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 127ms/step - loss: 0.0508 - mae: 0.0819 - val_loss: 0.0558 - val_mae: 0.0799\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 125ms/step - loss: 0.0701 - mae: 0.0860 - val_loss: 0.0788 - val_mae: 0.0978\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 131ms/step - loss: 0.0548 - mae: 0.0827 - val_loss: 0.0411 - val_mae: 0.0636\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 1s 129ms/step - loss: 0.0475 - mae: 0.0770 - val_loss: 0.0370 - val_mae: 0.0572\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 127ms/step - loss: 0.0470 - mae: 0.0758 - val_loss: 0.0368 - val_mae: 0.0571\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 1s 136ms/step - loss: 0.0486 - mae: 0.0781 - val_loss: 0.0368 - val_mae: 0.0569\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 0.0473 - mae: 0.0770 - val_loss: 0.0358 - val_mae: 0.0555\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 0.0453 - mae: 0.0744 - val_loss: 0.0380 - val_mae: 0.0592\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 0.0500 - mae: 0.0779 - val_loss: 0.0361 - val_mae: 0.0557\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 1s 225ms/step - loss: 0.1440 - mae: 0.1152 - val_loss: 0.0607 - val_mae: 0.0843\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 1s 301ms/step - loss: 0.0567 - mae: 0.0870 - val_loss: 0.0354 - val_mae: 0.0544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.0410 - mae: 0.0739 - val_loss: 0.0219 - val_mae: 0.0536\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 0.0341 - mae: 0.0745 - val_loss: 0.0218 - val_mae: 0.0524\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 1s 211ms/step - loss: 0.0345 - mae: 0.0740 - val_loss: 0.0218 - val_mae: 0.0519\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 1s 197ms/step - loss: 0.0392 - mae: 0.0765 - val_loss: 0.0217 - val_mae: 0.0516\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 1s 196ms/step - loss: 0.0335 - mae: 0.0729 - val_loss: 0.0221 - val_mae: 0.0517\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 0.0345 - mae: 0.0736 - val_loss: 0.0226 - val_mae: 0.0521\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 1s 215ms/step - loss: 0.0358 - mae: 0.0740 - val_loss: 0.0216 - val_mae: 0.0518\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 1s 226ms/step - loss: 0.0364 - mae: 0.0757 - val_loss: 0.0220 - val_mae: 0.0516\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 9s 540ms/step - loss: 0.5039 - mae: 0.2153 - val_loss: 0.0516 - val_mae: 0.0634\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 159ms/step - loss: 0.0545 - mae: 0.0817 - val_loss: 0.0179 - val_mae: 0.0512\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 157ms/step - loss: 0.0745 - mae: 0.0863 - val_loss: 0.0569 - val_mae: 0.0687\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 152ms/step - loss: 0.0547 - mae: 0.0803 - val_loss: 0.0172 - val_mae: 0.0495\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 1s 149ms/step - loss: 0.0566 - mae: 0.0810 - val_loss: 0.0687 - val_mae: 0.0790\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 148ms/step - loss: 0.0615 - mae: 0.0831 - val_loss: 0.0428 - val_mae: 0.0564\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 1s 148ms/step - loss: 0.0445 - mae: 0.0770 - val_loss: 0.0188 - val_mae: 0.0550\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 1s 140ms/step - loss: 0.0523 - mae: 0.0838 - val_loss: 0.0671 - val_mae: 0.0776\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 1s 142ms/step - loss: 0.0453 - mae: 0.0785 - val_loss: 0.1033 - val_mae: 0.1035\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 8s 431ms/step - loss: 0.1225 - mae: 0.1235 - val_loss: 0.0130 - val_mae: 0.0458\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 0.1118 - mae: 0.1174 - val_loss: 0.0229 - val_mae: 0.0459\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 126ms/step - loss: 0.0416 - mae: 0.0788 - val_loss: 0.0111 - val_mae: 0.0415\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.0561 - mae: 0.0814 - val_loss: 0.0264 - val_mae: 0.0501\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 0.0383 - mae: 0.0755 - val_loss: 0.0228 - val_mae: 0.0460\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 117ms/step - loss: 0.0369 - mae: 0.0736 - val_loss: 0.0407 - val_mae: 0.0655\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.0384 - mae: 0.0744 - val_loss: 0.0427 - val_mae: 0.0679\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.0524 - mae: 0.0825 - val_loss: 0.0211 - val_mae: 0.0438\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 7s 471ms/step - loss: 0.1944 - mae: 0.1462 - val_loss: 0.0298 - val_mae: 0.0695\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 162ms/step - loss: 0.0870 - mae: 0.0946 - val_loss: 0.0624 - val_mae: 0.0807\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 118ms/step - loss: 0.0480 - mae: 0.0747 - val_loss: 0.0131 - val_mae: 0.0507\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 127ms/step - loss: 0.0468 - mae: 0.0727 - val_loss: 0.0457 - val_mae: 0.0673\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 1s 129ms/step - loss: 0.0437 - mae: 0.0730 - val_loss: 0.0137 - val_mae: 0.0515\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 129ms/step - loss: 0.0464 - mae: 0.0726 - val_loss: 0.0468 - val_mae: 0.0684\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 127ms/step - loss: 0.0440 - mae: 0.0722 - val_loss: 0.0346 - val_mae: 0.0581\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.0572 - mae: 0.0777 - val_loss: 0.0219 - val_mae: 0.0553\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 8s 437ms/step - loss: 0.9599 - mae: 0.2810 - val_loss: 0.3774 - val_mae: 0.1445\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.0470 - mae: 0.0663 - val_loss: 0.2845 - val_mae: 0.1408\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.0352 - mae: 0.0636 - val_loss: 0.2773 - val_mae: 0.1407\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 0.0357 - mae: 0.0635 - val_loss: 0.2755 - val_mae: 0.1407\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 1s 129ms/step - loss: 0.0365 - mae: 0.0637 - val_loss: 0.2751 - val_mae: 0.1408\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.0361 - mae: 0.0639 - val_loss: 0.2753 - val_mae: 0.1407\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.0359 - mae: 0.0637 - val_loss: 0.2761 - val_mae: 0.1407\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 1s 127ms/step - loss: 0.0356 - mae: 0.0636 - val_loss: 0.2773 - val_mae: 0.1407\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.0357 - mae: 0.0635 - val_loss: 0.2813 - val_mae: 0.1406\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 1s 129ms/step - loss: 0.0359 - mae: 0.0633 - val_loss: 0.2784 - val_mae: 0.1406\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 8s 698ms/step - loss: 0.0455 - mae: 0.0731 - val_loss: 0.3594 - val_mae: 0.1488\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 155ms/step - loss: 0.0386 - mae: 0.0598 - val_loss: 0.3574 - val_mae: 0.1492\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 125ms/step - loss: 0.0330 - mae: 0.0595 - val_loss: 0.3585 - val_mae: 0.1490\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 139ms/step - loss: 0.0326 - mae: 0.0595 - val_loss: 0.3600 - val_mae: 0.1487\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.0331 - mae: 0.0597 - val_loss: 0.3560 - val_mae: 0.1495\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 213ms/step - loss: 0.0329 - mae: 0.0596 - val_loss: 0.3557 - val_mae: 0.1495\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 1s 125ms/step - loss: 0.0335 - mae: 0.0607 - val_loss: 0.3576 - val_mae: 0.1492\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 1s 148ms/step - loss: 0.0327 - mae: 0.0594 - val_loss: 0.3589 - val_mae: 0.1489\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 1s 156ms/step - loss: 0.0328 - mae: 0.0595 - val_loss: 0.3565 - val_mae: 0.1494\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 1s 132ms/step - loss: 0.0331 - mae: 0.0597 - val_loss: 0.3106 - val_mae: 0.1483\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 1s 145ms/step - loss: 0.0351 - mae: 0.0597 - val_loss: 0.3132 - val_mae: 0.1481\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.0342 - mae: 0.0600 - val_loss: 0.3577 - val_mae: 0.1491\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 1s 133ms/step - loss: 0.0370 - mae: 0.0597 - val_loss: 0.3573 - val_mae: 0.1492\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 1s 137ms/step - loss: 0.0324 - mae: 0.0595 - val_loss: 0.3597 - val_mae: 0.1487\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 120ms/step - loss: 0.0325 - mae: 0.0593 - val_loss: 0.3117 - val_mae: 0.1482\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 8s 459ms/step - loss: 0.4088 - mae: 0.1892 - val_loss: 0.0157 - val_mae: 0.0578\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 128ms/step - loss: 0.1300 - mae: 0.0845 - val_loss: 0.0194 - val_mae: 0.0632\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.1166 - mae: 0.0811 - val_loss: 0.0211 - val_mae: 0.0656\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 127ms/step - loss: 0.1165 - mae: 0.0804 - val_loss: 0.0557 - val_mae: 0.0686\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.1023 - mae: 0.0799 - val_loss: 0.0611 - val_mae: 0.0720\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 129ms/step - loss: 0.0971 - mae: 0.0803 - val_loss: 0.0628 - val_mae: 0.0731\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 9s 437ms/step - loss: 0.1433 - mae: 0.1053 - val_loss: 0.0477 - val_mae: 0.0667\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 133ms/step - loss: 0.1735 - mae: 0.1205 - val_loss: 0.0263 - val_mae: 0.0610\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 127ms/step - loss: 0.1013 - mae: 0.0782 - val_loss: 0.0381 - val_mae: 0.0629\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 126ms/step - loss: 0.1044 - mae: 0.0778 - val_loss: 0.0279 - val_mae: 0.0617\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 1s 125ms/step - loss: 0.1008 - mae: 0.0768 - val_loss: 0.0269 - val_mae: 0.0626\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.0990 - mae: 0.0773 - val_loss: 0.0270 - val_mae: 0.0613\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.1083 - mae: 0.0785 - val_loss: 0.0259 - val_mae: 0.0608\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.0925 - mae: 0.0774 - val_loss: 0.0271 - val_mae: 0.0613\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.0868 - mae: 0.0759 - val_loss: 0.0265 - val_mae: 0.0632\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 1s 129ms/step - loss: 0.1095 - mae: 0.0821 - val_loss: 0.0419 - val_mae: 0.0641\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 1s 127ms/step - loss: 0.1021 - mae: 0.0782 - val_loss: 0.0612 - val_mae: 0.0783\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.1048 - mae: 0.0832 - val_loss: 0.0259 - val_mae: 0.0606\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 8s 593ms/step - loss: 0.1071 - mae: 0.0840 - val_loss: 0.0350 - val_mae: 0.0776\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 133ms/step - loss: 0.1237 - mae: 0.0955 - val_loss: 0.0059 - val_mae: 0.0255\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.1175 - mae: 0.0816 - val_loss: 0.0063 - val_mae: 0.0258\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.1150 - mae: 0.0822 - val_loss: 0.0089 - val_mae: 0.0318\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 1s 274ms/step - loss: 0.1095 - mae: 0.0841 - val_loss: 0.0277 - val_mae: 0.0621\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 239ms/step - loss: 0.1169 - mae: 0.0824 - val_loss: 0.0075 - val_mae: 0.0282\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 0.1098 - mae: 0.0823 - val_loss: 0.0055 - val_mae: 0.0254\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 1s 221ms/step - loss: 0.0962 - mae: 0.0808 - val_loss: 0.0069 - val_mae: 0.0267\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 0.1151 - mae: 0.0815 - val_loss: 0.0056 - val_mae: 0.0257\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 1s 252ms/step - loss: 0.1120 - mae: 0.0816 - val_loss: 0.0057 - val_mae: 0.0255\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 1s 224ms/step - loss: 0.1139 - mae: 0.0817 - val_loss: 0.0061 - val_mae: 0.0255\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 1s 213ms/step - loss: 0.1085 - mae: 0.0820 - val_loss: 0.0061 - val_mae: 0.0255\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 7s 447ms/step - loss: 0.2764 - mae: 0.1783 - val_loss: 0.0286 - val_mae: 0.0432\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 129ms/step - loss: 0.1304 - mae: 0.0978 - val_loss: 0.0117 - val_mae: 0.0373\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 129ms/step - loss: 0.1060 - mae: 0.0759 - val_loss: 0.0115 - val_mae: 0.0403\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 129ms/step - loss: 0.0880 - mae: 0.0739 - val_loss: 0.0290 - val_mae: 0.0439\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 1s 137ms/step - loss: 0.0836 - mae: 0.0739 - val_loss: 0.0121 - val_mae: 0.0381\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 131ms/step - loss: 0.0728 - mae: 0.0715 - val_loss: 0.0328 - val_mae: 0.0480\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 1s 129ms/step - loss: 0.0841 - mae: 0.0723 - val_loss: 0.0770 - val_mae: 0.0906\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 1s 129ms/step - loss: 0.1046 - mae: 0.0812 - val_loss: 0.0123 - val_mae: 0.0391\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 8s 439ms/step - loss: 0.2219 - mae: 0.1450 - val_loss: 0.0404 - val_mae: 0.0598\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 128ms/step - loss: 0.1041 - mae: 0.0748 - val_loss: 0.0434 - val_mae: 0.0629\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 128ms/step - loss: 0.1056 - mae: 0.0779 - val_loss: 0.0282 - val_mae: 0.0572\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 138ms/step - loss: 0.0922 - mae: 0.0742 - val_loss: 0.0267 - val_mae: 0.0549\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.0896 - mae: 0.0726 - val_loss: 0.0430 - val_mae: 0.0619\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 142ms/step - loss: 0.0994 - mae: 0.0769 - val_loss: 0.0617 - val_mae: 0.0826\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 1s 141ms/step - loss: 0.0975 - mae: 0.0791 - val_loss: 0.0568 - val_mae: 0.0784\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 1s 136ms/step - loss: 0.1025 - mae: 0.0825 - val_loss: 0.0286 - val_mae: 0.0580\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 1s 148ms/step - loss: 0.0950 - mae: 0.0735 - val_loss: 0.0482 - val_mae: 0.0695\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 7s 440ms/step - loss: 0.1180 - mae: 0.0900 - val_loss: 0.0281 - val_mae: 0.0524\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 136ms/step - loss: 0.1084 - mae: 0.0755 - val_loss: 0.0209 - val_mae: 0.0491\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.1017 - mae: 0.0776 - val_loss: 0.0369 - val_mae: 0.0601\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 127ms/step - loss: 0.1360 - mae: 0.1105 - val_loss: 0.0197 - val_mae: 0.0453\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 1s 128ms/step - loss: 0.1160 - mae: 0.0766 - val_loss: 0.0209 - val_mae: 0.0456\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.0885 - mae: 0.0735 - val_loss: 0.0204 - val_mae: 0.0450\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 1s 126ms/step - loss: 0.0908 - mae: 0.0737 - val_loss: 0.0236 - val_mae: 0.0480\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 1s 127ms/step - loss: 0.0960 - mae: 0.0756 - val_loss: 0.0231 - val_mae: 0.0476\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.0900 - mae: 0.0736 - val_loss: 0.0205 - val_mae: 0.0451\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 8s 429ms/step - loss: 0.1266 - mae: 0.0982 - val_loss: 0.0056 - val_mae: 0.0382\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 127ms/step - loss: 0.1209 - mae: 0.1012 - val_loss: 0.0064 - val_mae: 0.0406\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 0.0931 - mae: 0.0751 - val_loss: 0.2350 - val_mae: 0.1598\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.1186 - mae: 0.0942 - val_loss: 0.0527 - val_mae: 0.0655\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.0995 - mae: 0.0750 - val_loss: 0.0081 - val_mae: 0.0459\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 128ms/step - loss: 0.0874 - mae: 0.0742 - val_loss: 0.0521 - val_mae: 0.0650\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 7s 589ms/step - loss: 0.5365 - mae: 0.2234 - val_loss: 0.0108 - val_mae: 0.0501\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 0.0247 - mae: 0.0538 - val_loss: 0.0131 - val_mae: 0.0564\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 128ms/step - loss: 0.0181 - mae: 0.0479 - val_loss: 0.0242 - val_mae: 0.0684\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.0187 - mae: 0.0483 - val_loss: 0.0158 - val_mae: 0.0628\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.0179 - mae: 0.0470 - val_loss: 0.0148 - val_mae: 0.0606\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.0173 - mae: 0.0469 - val_loss: 0.0473 - val_mae: 0.0713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 7s 437ms/step - loss: 0.2612 - mae: 0.1600 - val_loss: 0.2332 - val_mae: 0.1499\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.1111 - mae: 0.1177 - val_loss: 0.0471 - val_mae: 0.0966\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.0191 - mae: 0.0515 - val_loss: 0.0420 - val_mae: 0.0923\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 127ms/step - loss: 0.0184 - mae: 0.0517 - val_loss: 0.0567 - val_mae: 0.1036\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 127ms/step - loss: 0.0194 - mae: 0.0515 - val_loss: 0.0489 - val_mae: 0.0980\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 0.0178 - mae: 0.0500 - val_loss: 0.0371 - val_mae: 0.0872\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.0179 - mae: 0.0508 - val_loss: 0.1333 - val_mae: 0.1075\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 127ms/step - loss: 0.0193 - mae: 0.0512 - val_loss: 0.0410 - val_mae: 0.0912\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 120ms/step - loss: 0.0189 - mae: 0.0508 - val_loss: 0.0387 - val_mae: 0.0889\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.0178 - mae: 0.0496 - val_loss: 0.0401 - val_mae: 0.0905\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 0.0280 - mae: 0.0597 - val_loss: 0.0390 - val_mae: 0.0893\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 8s 432ms/step - loss: 0.1216 - mae: 0.1199 - val_loss: 0.0565 - val_mae: 0.1058\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 127ms/step - loss: 0.0303 - mae: 0.0577 - val_loss: 0.0585 - val_mae: 0.1155\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 129ms/step - loss: 0.0177 - mae: 0.0483 - val_loss: 0.0544 - val_mae: 0.1090\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.0195 - mae: 0.0524 - val_loss: 0.0588 - val_mae: 0.1158\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 127ms/step - loss: 0.0168 - mae: 0.0482 - val_loss: 0.0666 - val_mae: 0.1254\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 0.0199 - mae: 0.0519 - val_loss: 0.1025 - val_mae: 0.1313\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 1s 131ms/step - loss: 0.0324 - mae: 0.0608 - val_loss: 0.0538 - val_mae: 0.1071\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.0198 - mae: 0.0526 - val_loss: 0.0671 - val_mae: 0.1260\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 1s 128ms/step - loss: 0.0185 - mae: 0.0494 - val_loss: 0.0573 - val_mae: 0.1137\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 127ms/step - loss: 0.0181 - mae: 0.0502 - val_loss: 0.0565 - val_mae: 0.1126\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 1s 129ms/step - loss: 0.0180 - mae: 0.0486 - val_loss: 0.0667 - val_mae: 0.1252\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 1s 127ms/step - loss: 0.0220 - mae: 0.0491 - val_loss: 0.0567 - val_mae: 0.1131\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 7s 439ms/step - loss: 0.1715 - mae: 0.1569 - val_loss: 0.1586 - val_mae: 0.1258\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 139ms/step - loss: 0.0379 - mae: 0.0660 - val_loss: 0.0507 - val_mae: 0.1017\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 125ms/step - loss: 0.0274 - mae: 0.0619 - val_loss: 0.0495 - val_mae: 0.0981\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.0281 - mae: 0.0620 - val_loss: 0.0572 - val_mae: 0.1145\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 0.0338 - mae: 0.0641 - val_loss: 0.0543 - val_mae: 0.1096\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.0280 - mae: 0.0619 - val_loss: 0.0491 - val_mae: 0.0967\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 120ms/step - loss: 0.0247 - mae: 0.0596 - val_loss: 0.0510 - val_mae: 0.0958\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.0324 - mae: 0.0664 - val_loss: 0.0489 - val_mae: 0.0964\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 1s 126ms/step - loss: 0.0257 - mae: 0.0604 - val_loss: 0.0490 - val_mae: 0.0955\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 1s 128ms/step - loss: 0.0254 - mae: 0.0596 - val_loss: 0.0515 - val_mae: 0.0959\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 1s 129ms/step - loss: 0.0251 - mae: 0.0609 - val_loss: 0.0502 - val_mae: 0.0956\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.0329 - mae: 0.0651 - val_loss: 0.0640 - val_mae: 0.1037\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 1s 137ms/step - loss: 0.0265 - mae: 0.0636 - val_loss: 0.0488 - val_mae: 0.0968\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.0243 - mae: 0.0568 - val_loss: 0.0500 - val_mae: 0.0955\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.0243 - mae: 0.0577 - val_loss: 0.0572 - val_mae: 0.0985\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.0251 - mae: 0.0593 - val_loss: 0.1591 - val_mae: 0.1251\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 1s 246ms/step - loss: 0.0380 - mae: 0.0656 - val_loss: 0.0518 - val_mae: 0.1038\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 1s 223ms/step - loss: 0.0243 - mae: 0.0589 - val_loss: 0.0542 - val_mae: 0.1094\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 9s 473ms/step - loss: 0.7060 - mae: 0.2948 - val_loss: 0.0932 - val_mae: 0.1140\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 175ms/step - loss: 0.0763 - mae: 0.0997 - val_loss: 0.0783 - val_mae: 0.1022\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 1s 120ms/step - loss: 0.0317 - mae: 0.0741 - val_loss: 0.0481 - val_mae: 0.0762\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 167ms/step - loss: 0.0299 - mae: 0.0708 - val_loss: 0.0628 - val_mae: 0.0900\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 1s 134ms/step - loss: 0.0288 - mae: 0.0693 - val_loss: 0.1055 - val_mae: 0.1240\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 123ms/step - loss: 0.0301 - mae: 0.0712 - val_loss: 0.0915 - val_mae: 0.1129\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 118ms/step - loss: 0.0315 - mae: 0.0723 - val_loss: 0.0535 - val_mae: 0.0812\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 127ms/step - loss: 0.0289 - mae: 0.0703 - val_loss: 0.0876 - val_mae: 0.1104\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 7s 435ms/step - loss: 0.1371 - mae: 0.1474 - val_loss: 0.0561 - val_mae: 0.0780\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.0812 - mae: 0.1068 - val_loss: 0.0908 - val_mae: 0.0979\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 117ms/step - loss: 0.0405 - mae: 0.0779 - val_loss: 0.0478 - val_mae: 0.0778\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.0522 - mae: 0.0822 - val_loss: 0.0764 - val_mae: 0.0880\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 127ms/step - loss: 0.0369 - mae: 0.0773 - val_loss: 0.0608 - val_mae: 0.0788\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 0.0379 - mae: 0.0783 - val_loss: 0.0591 - val_mae: 0.0781\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 0.0379 - mae: 0.0780 - val_loss: 0.0780 - val_mae: 0.0891\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 1s 129ms/step - loss: 0.0358 - mae: 0.0749 - val_loss: 0.1024 - val_mae: 0.1060\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 7s 429ms/step - loss: 0.1693 - mae: 0.1292 - val_loss: 2.4682 - val_mae: 0.5917\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.2989 - mae: 0.2153 - val_loss: 0.2307 - val_mae: 0.1436\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 116ms/step - loss: 0.0350 - mae: 0.0759 - val_loss: 0.1837 - val_mae: 0.1229\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.0339 - mae: 0.0743 - val_loss: 0.0891 - val_mae: 0.1057\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.0458 - mae: 0.0799 - val_loss: 0.3043 - val_mae: 0.1748\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.0379 - mae: 0.0788 - val_loss: 0.1670 - val_mae: 0.1165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 120ms/step - loss: 0.0332 - mae: 0.0741 - val_loss: 0.2719 - val_mae: 0.1594\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 120ms/step - loss: 0.0343 - mae: 0.0759 - val_loss: 0.1161 - val_mae: 0.1084\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 126ms/step - loss: 0.0327 - mae: 0.0760 - val_loss: 0.1917 - val_mae: 0.1293\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 7s 430ms/step - loss: 0.2538 - mae: 0.1538 - val_loss: 0.3317 - val_mae: 0.2004\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.3390 - mae: 0.1801 - val_loss: 0.0767 - val_mae: 0.0781\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 121ms/step - loss: 0.0586 - mae: 0.0941 - val_loss: 0.0959 - val_mae: 0.0916\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 119ms/step - loss: 0.0629 - mae: 0.0922 - val_loss: 0.0362 - val_mae: 0.0657\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.0701 - mae: 0.0952 - val_loss: 0.0658 - val_mae: 0.0704\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 1s 128ms/step - loss: 0.0581 - mae: 0.0905 - val_loss: 0.0752 - val_mae: 0.0767\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 1s 128ms/step - loss: 0.0595 - mae: 0.0902 - val_loss: 0.0693 - val_mae: 0.0730\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.0641 - mae: 0.0918 - val_loss: 0.1165 - val_mae: 0.1045\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.0791 - mae: 0.0982 - val_loss: 0.0705 - val_mae: 0.0739\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 7s 425ms/step - loss: 0.3087 - mae: 0.2072 - val_loss: 0.0547 - val_mae: 0.0822\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 1s 124ms/step - loss: 0.0771 - mae: 0.0988 - val_loss: 0.0644 - val_mae: 0.0824\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.0787 - mae: 0.0994 - val_loss: 0.0547 - val_mae: 0.0821\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.0773 - mae: 0.0994 - val_loss: 0.0551 - val_mae: 0.0840\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.0737 - mae: 0.0965 - val_loss: 0.1519 - val_mae: 0.1382\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 124ms/step - loss: 0.1272 - mae: 0.1208 - val_loss: 0.0828 - val_mae: 0.1027\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m RnnDlModel_test(epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mcv_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mApiCall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_local\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m read_result()\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/code/AlexandreLaizet/bitcoin_deep_learning/bitcoin_deep_learning/trainer.py:66\u001b[0m, in \u001b[0;36mcv_train\u001b[0;34m(model, df, metric, save, precision, with_trader)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# Append a new line with current CV results\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_path , \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m, newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m csvfile:\n\u001b[1;32m     64\u001b[0m     (roi_hodler, roi_trader, roi_whale, roi_hodler_whale, roi_charles,\n\u001b[1;32m     65\u001b[0m      sharpe_hodler, sharpe_trader, sharpe_whale, sharpe_hodler_whale,\n\u001b[0;32m---> 66\u001b[0m      sharpe_charles) \u001b[38;5;241m=\u001b[39m \u001b[43miterate_cross_val_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m     writer \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mDictWriter(csvfile, fieldnames\u001b[38;5;241m=\u001b[39mfieldnames)\n\u001b[1;32m     69\u001b[0m     writer\u001b[38;5;241m.\u001b[39mwriterow({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m:model\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfold_score\u001b[39m\u001b[38;5;124m\"\u001b[39m:fold_score,\n\u001b[1;32m     70\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean_score\u001b[39m\u001b[38;5;124m\"\u001b[39m:score,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin_score\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;28mmin\u001b[39m(fold_score),\n\u001b[1;32m     71\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_score\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;28mmax\u001b[39m(fold_score),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     82\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroi_charles\u001b[39m\u001b[38;5;124m\"\u001b[39m: roi_charles,\n\u001b[1;32m     83\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msharpe_charles\u001b[39m\u001b[38;5;124m\"\u001b[39m:sharpe_charles})\n",
      "File \u001b[0;32m~/code/AlexandreLaizet/bitcoin_deep_learning/bitcoin_deep_learning/metrics.py:711\u001b[0m, in \u001b[0;36miterate_cross_val_results\u001b[0;34m(model, df)\u001b[0m\n\u001b[1;32m    708\u001b[0m y_true, y_pred \u001b[38;5;241m=\u001b[39m reality, prediction\n\u001b[1;32m    710\u001b[0m roi_hodler\u001b[38;5;241m.\u001b[39mappend(compute_roi(play_hodler_strategy(y_true, y_pred)))\n\u001b[0;32m--> 711\u001b[0m roi_trader\u001b[38;5;241m.\u001b[39mappend(compute_roi(\u001b[43mplay_trader_strategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[1;32m    712\u001b[0m roi_whale\u001b[38;5;241m.\u001b[39mappend(compute_roi(play_whale_strategy(y_true, y_pred)))\n\u001b[1;32m    713\u001b[0m roi_hodler_whale\u001b[38;5;241m.\u001b[39mappend(compute_roi(play_hodler_whale_strategy(y_true, y_pred)))\n",
      "File \u001b[0;32m~/code/AlexandreLaizet/bitcoin_deep_learning/bitcoin_deep_learning/metrics.py:188\u001b[0m, in \u001b[0;36mplay_trader_strategy\u001b[0;34m(y_true, y_pred, total_investment, investment_horizon, buy_threshold, sell_threshold, exchange_fee, tax_rate)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(y_true):\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mlist\u001b[39m(y_pred)) \u001b[38;5;241m>\u001b[39m counter \u001b[38;5;241m+\u001b[39m investment_horizon:\n\u001b[0;32m--> 188\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlist\u001b[39m(y_pred)[counter \u001b[38;5;241m+\u001b[39m investment_horizon] \u001b[38;5;241m/\u001b[39m value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m>\u001b[39m buy_threshold:\n\u001b[1;32m    189\u001b[0m         \u001b[38;5;66;03m#if list(y_pred)[counter + investment_horizon] > buy_threshold:\u001b[39;00m\n\u001b[1;32m    191\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m usd_balance \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    193\u001b[0m                 investment \u001b[38;5;241m=\u001b[39m usd_balance \u001b[38;5;241m-\u001b[39m (usd_balance \u001b[38;5;241m*\u001b[39m exchange_fee)\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "model = RnnDlModel_test(epochs=20, patience=5)\n",
    "cv_train(model,ApiCall().read_local(data=\"train\"))\n",
    "read_result().sort_values(by=\"date\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a361f53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
